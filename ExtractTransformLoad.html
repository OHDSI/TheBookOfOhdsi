<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Extract Transform Load | The Book of OHDSI</title>
  <meta name="description" content="A book about the Observational Health Data Science and Informatics (OHDS). It described the OHDSI community, open standards and open source software." />
  <meta name="generator" content="bookdown 0.12.2 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Extract Transform Load | The Book of OHDSI" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://ohdsi.github.io/TheBookOfOhdsi/" />
  <meta property="og:image" content="https://ohdsi.github.io/TheBookOfOhdsi/images/Cover/Cover.png" />
  <meta property="og:description" content="A book about the Observational Health Data Science and Informatics (OHDS). It described the OHDSI community, open standards and open source software." />
  <meta name="github-repo" content="OHDSI/TheBookOfOhdsi" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Extract Transform Load | The Book of OHDSI" />
  
  <meta name="twitter:description" content="A book about the Observational Health Data Science and Informatics (OHDS). It described the OHDSI community, open standards and open source software." />
  <meta name="twitter:image" content="https://ohdsi.github.io/TheBookOfOhdsi/images/Cover/Cover.png" />

<meta name="author" content="Observational Health Data Science and Informatics" />


<meta name="date" content="2019-08-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon" />
<link rel="prev" href="StandardizedVocabularies.html"/>
<link rel="next" href="DataAnalyticsUseCases.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-104086677-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-104086677-2');
</script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The Book of OHDSI</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#goals-of-this-book"><i class="fa fa-check"></i>Goals of this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure-of-the-book"><i class="fa fa-check"></i>Structure of the book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contributors"><i class="fa fa-check"></i>Contributors</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-versions"><i class="fa fa-check"></i>Software versions</a></li>
</ul></li>
<li class="part"><span><b>I The OHDSI Community</b></span></li>
<li class="chapter" data-level="1" data-path="MissionVisionValues.html"><a href="MissionVisionValues.html"><i class="fa fa-check"></i><b>1</b> Mission, vision, values</a><ul>
<li class="chapter" data-level="1.1" data-path="MissionVisionValues.html"><a href="MissionVisionValues.html#our-mission"><i class="fa fa-check"></i><b>1.1</b> Our Mission</a></li>
<li class="chapter" data-level="1.2" data-path="MissionVisionValues.html"><a href="MissionVisionValues.html#our-vision"><i class="fa fa-check"></i><b>1.2</b> Our Vision</a></li>
<li class="chapter" data-level="1.3" data-path="MissionVisionValues.html"><a href="MissionVisionValues.html#our-objectives"><i class="fa fa-check"></i><b>1.3</b> Our Objectives</a></li>
<li class="chapter" data-level="1.4" data-path="MissionVisionValues.html"><a href="MissionVisionValues.html#summary"><i class="fa fa-check"></i><b>1.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Collaborators.html"><a href="Collaborators.html"><i class="fa fa-check"></i><b>2</b> Collaborators</a></li>
<li class="chapter" data-level="3" data-path="OpenScience.html"><a href="OpenScience.html"><i class="fa fa-check"></i><b>3</b> Open Science</a><ul>
<li class="chapter" data-level="3.1" data-path="OpenScience.html"><a href="OpenScience.html#open-science"><i class="fa fa-check"></i><b>3.1</b> Open Science</a></li>
<li class="chapter" data-level="3.2" data-path="OpenScience.html"><a href="OpenScience.html#open-science-in-action-the-study-a-thon"><i class="fa fa-check"></i><b>3.2</b> Open-Science in Action: the Study-a-thon</a></li>
<li class="chapter" data-level="3.3" data-path="OpenScience.html"><a href="OpenScience.html#open-standards"><i class="fa fa-check"></i><b>3.3</b> Open Standards</a></li>
<li class="chapter" data-level="3.4" data-path="OpenScience.html"><a href="OpenScience.html#open-source"><i class="fa fa-check"></i><b>3.4</b> Open Source</a></li>
<li class="chapter" data-level="3.5" data-path="OpenScience.html"><a href="OpenScience.html#open-data"><i class="fa fa-check"></i><b>3.5</b> Open Data</a></li>
<li class="chapter" data-level="3.6" data-path="OpenScience.html"><a href="OpenScience.html#open-discourse"><i class="fa fa-check"></i><b>3.6</b> Open Discourse</a></li>
<li class="chapter" data-level="3.7" data-path="OpenScience.html"><a href="OpenScience.html#ohdsi-and-the-fair-guiding-principles"><i class="fa fa-check"></i><b>3.7</b> OHDSI and the FAIR Guiding Principles</a><ul>
<li class="chapter" data-level="3.7.1" data-path="OpenScience.html"><a href="OpenScience.html#introduction"><i class="fa fa-check"></i><b>3.7.1</b> Introduction</a></li>
<li class="chapter" data-level="3.7.2" data-path="OpenScience.html"><a href="OpenScience.html#findability"><i class="fa fa-check"></i><b>3.7.2</b> Findability</a></li>
<li class="chapter" data-level="3.7.3" data-path="OpenScience.html"><a href="OpenScience.html#accessibility"><i class="fa fa-check"></i><b>3.7.3</b> Accessibility</a></li>
<li class="chapter" data-level="3.7.4" data-path="OpenScience.html"><a href="OpenScience.html#interoperability"><i class="fa fa-check"></i><b>3.7.4</b> Interoperability</a></li>
<li class="chapter" data-level="3.7.5" data-path="OpenScience.html"><a href="OpenScience.html#reusability"><i class="fa fa-check"></i><b>3.7.5</b> Reusability</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="OpenScience.html"><a href="OpenScience.html#conclusions"><i class="fa fa-check"></i><b>3.8</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="WhereToBegin.html"><a href="WhereToBegin.html"><i class="fa fa-check"></i><b>4</b> Where to begin</a><ul>
<li class="chapter" data-level="4.1" data-path="WhereToBegin.html"><a href="WhereToBegin.html#join-the-journey"><i class="fa fa-check"></i><b>4.1</b> Join the Journey</a><ul>
<li class="chapter" data-level="4.1.1" data-path="WhereToBegin.html"><a href="WhereToBegin.html#ohdsi-forum"><i class="fa fa-check"></i><b>4.1.1</b> OHDSI Forum</a></li>
<li class="chapter" data-level="4.1.2" data-path="WhereToBegin.html"><a href="WhereToBegin.html#ohdsi-educational-materials"><i class="fa fa-check"></i><b>4.1.2</b> OHDSI Educational Materials</a></li>
<li class="chapter" data-level="4.1.3" data-path="WhereToBegin.html"><a href="WhereToBegin.html#ohdsi-community-calls"><i class="fa fa-check"></i><b>4.1.3</b> OHDSI Community Calls</a></li>
<li class="chapter" data-level="4.1.4" data-path="WhereToBegin.html"><a href="WhereToBegin.html#ohdsi-workgroups"><i class="fa fa-check"></i><b>4.1.4</b> OHDSI Workgroups</a></li>
<li class="chapter" data-level="4.1.5" data-path="WhereToBegin.html"><a href="WhereToBegin.html#ohdsi-regional-chapters"><i class="fa fa-check"></i><b>4.1.5</b> OHDSI Regional Chapters</a></li>
<li class="chapter" data-level="4.1.6" data-path="WhereToBegin.html"><a href="WhereToBegin.html#ohdsi-research-network"><i class="fa fa-check"></i><b>4.1.6</b> OHDSI Research Network</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="WhereToBegin.html"><a href="WhereToBegin.html#where-you-fit-in"><i class="fa fa-check"></i><b>4.2</b> Where You Fit In</a></li>
<li class="chapter" data-level="4.3" data-path="WhereToBegin.html"><a href="WhereToBegin.html#summary-1"><i class="fa fa-check"></i><b>4.3</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>II Uniform Data Representation</b></span></li>
<li class="chapter" data-level="5" data-path="CommonDataModel.html"><a href="CommonDataModel.html"><i class="fa fa-check"></i><b>5</b> The Common Data Model</a><ul>
<li class="chapter" data-level="5.1" data-path="CommonDataModel.html"><a href="CommonDataModel.html#design-principles"><i class="fa fa-check"></i><b>5.1</b> Design Principles</a></li>
<li class="chapter" data-level="5.2" data-path="CommonDataModel.html"><a href="CommonDataModel.html#data-model-conventions"><i class="fa fa-check"></i><b>5.2</b> Data Model Conventions</a><ul>
<li class="chapter" data-level="5.2.1" data-path="CommonDataModel.html"><a href="CommonDataModel.html#model-conv"><i class="fa fa-check"></i><b>5.2.1</b> General conventions of the model</a></li>
<li class="chapter" data-level="5.2.2" data-path="CommonDataModel.html"><a href="CommonDataModel.html#general-conventions-of-schemas"><i class="fa fa-check"></i><b>5.2.2</b> General conventions of schemas</a></li>
<li class="chapter" data-level="5.2.3" data-path="CommonDataModel.html"><a href="CommonDataModel.html#general-conventions-of-data-tables"><i class="fa fa-check"></i><b>5.2.3</b> General conventions of data tables</a></li>
<li class="chapter" data-level="5.2.4" data-path="CommonDataModel.html"><a href="CommonDataModel.html#general-conventions-of-domains"><i class="fa fa-check"></i><b>5.2.4</b> General conventions of Domains</a></li>
<li class="chapter" data-level="5.2.5" data-path="CommonDataModel.html"><a href="CommonDataModel.html#representation-of-content-through-concepts"><i class="fa fa-check"></i><b>5.2.5</b> Representation of content through Concepts</a></li>
<li class="chapter" data-level="5.2.6" data-path="CommonDataModel.html"><a href="CommonDataModel.html#general-naming-conventions-of-fields"><i class="fa fa-check"></i><b>5.2.6</b> General naming conventions of fields</a></li>
<li class="chapter" data-level="5.2.7" data-path="CommonDataModel.html"><a href="CommonDataModel.html#concepts-sources"><i class="fa fa-check"></i><b>5.2.7</b> Difference between Concepts and Source Values</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="CommonDataModel.html"><a href="CommonDataModel.html#omop-cdm-standardized-tables"><i class="fa fa-check"></i><b>5.3</b> OMOP CDM Standardized Tables</a><ul>
<li class="chapter" data-level="5.3.1" data-path="CommonDataModel.html"><a href="CommonDataModel.html#running-example-endometriosis"><i class="fa fa-check"></i><b>5.3.1</b> Running Example: Endometriosis</a></li>
<li class="chapter" data-level="5.3.2" data-path="CommonDataModel.html"><a href="CommonDataModel.html#person"><i class="fa fa-check"></i><b>5.3.2</b> PERSON table</a></li>
<li class="chapter" data-level="5.3.3" data-path="CommonDataModel.html"><a href="CommonDataModel.html#observationPeriod"><i class="fa fa-check"></i><b>5.3.3</b> OBSERVATION_PERIOD table</a></li>
<li class="chapter" data-level="5.3.4" data-path="CommonDataModel.html"><a href="CommonDataModel.html#visitOccurrence"><i class="fa fa-check"></i><b>5.3.4</b> VISIT_OCCURRENCE</a></li>
<li class="chapter" data-level="5.3.5" data-path="CommonDataModel.html"><a href="CommonDataModel.html#conditionOccurrence"><i class="fa fa-check"></i><b>5.3.5</b> CONDITION_OCCURRENCE</a></li>
<li class="chapter" data-level="5.3.6" data-path="CommonDataModel.html"><a href="CommonDataModel.html#drugExposure"><i class="fa fa-check"></i><b>5.3.6</b> DRUG_EXPOSURE</a></li>
<li class="chapter" data-level="5.3.7" data-path="CommonDataModel.html"><a href="CommonDataModel.html#procedureOccurrence"><i class="fa fa-check"></i><b>5.3.7</b> PROCEDURE_OCCURRENCE</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="CommonDataModel.html"><a href="CommonDataModel.html#additional-information"><i class="fa fa-check"></i><b>5.4</b> Additional Information</a></li>
<li class="chapter" data-level="5.5" data-path="CommonDataModel.html"><a href="CommonDataModel.html#summary-2"><i class="fa fa-check"></i><b>5.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="StandardizedVocabularies.html"><a href="StandardizedVocabularies.html"><i class="fa fa-check"></i><b>6</b> Standardized Vocabularies</a></li>
<li class="chapter" data-level="7" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html"><i class="fa fa-check"></i><b>7</b> Extract Transform Load</a><ul>
<li class="chapter" data-level="7.1" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#introduction-1"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#step-1-design-the-etl"><i class="fa fa-check"></i><b>7.2</b> Step 1: Design the ETL</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#white-rabbit"><i class="fa fa-check"></i><b>7.2.1</b> White Rabbit</a></li>
<li class="chapter" data-level="7.2.2" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#rabbit-in-a-hat"><i class="fa fa-check"></i><b>7.2.2</b> Rabbit-In-a-Hat</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#step-2-create-the-code-mappings"><i class="fa fa-check"></i><b>7.3</b> Step 2: Create the code mappings</a><ul>
<li class="chapter" data-level="7.3.1" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#usagi"><i class="fa fa-check"></i><b>7.3.1</b> Usagi</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#step-3-implement-the-etl"><i class="fa fa-check"></i><b>7.4</b> Step 3: Implement the ETL</a></li>
<li class="chapter" data-level="7.5" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#step-4-quality-control"><i class="fa fa-check"></i><b>7.5</b> Step 4: Quality control</a></li>
<li class="chapter" data-level="7.6" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#etl-conventions-and-themis"><i class="fa fa-check"></i><b>7.6</b> ETL Conventions and THEMIS</a></li>
<li class="chapter" data-level="7.7" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#CDMandETLMaintenance"><i class="fa fa-check"></i><b>7.7</b> CDM and ETL maintenance</a></li>
<li class="chapter" data-level="7.8" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#final-thoughts-on-etl"><i class="fa fa-check"></i><b>7.8</b> Final thoughts on ETL</a></li>
<li class="chapter" data-level="7.9" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#summary-3"><i class="fa fa-check"></i><b>7.9</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>III Data Analytics</b></span></li>
<li class="chapter" data-level="8" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html"><i class="fa fa-check"></i><b>8</b> Data Analytics Use Cases</a><ul>
<li class="chapter" data-level="8.1" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#characterization"><i class="fa fa-check"></i><b>8.1</b> Characterization</a></li>
<li class="chapter" data-level="8.2" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#population-level-estimation"><i class="fa fa-check"></i><b>8.2</b> Population-level estimation</a></li>
<li class="chapter" data-level="8.3" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#patient-level-prediction"><i class="fa fa-check"></i><b>8.3</b> Patient-Level prediction</a></li>
<li class="chapter" data-level="8.4" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#a-typical-application"><i class="fa fa-check"></i><b>8.4</b> A Typical Application</a><ul>
<li class="chapter" data-level="8.4.1" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#characterization-questions"><i class="fa fa-check"></i><b>8.4.1</b> Characterization Questions</a></li>
<li class="chapter" data-level="8.4.2" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#population-level-estimation-question"><i class="fa fa-check"></i><b>8.4.2</b> Population-Level Estimation Question</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#limitations-of-observational-research"><i class="fa fa-check"></i><b>8.5</b> Limitations of observational research</a><ul>
<li class="chapter" data-level="8.5.1" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#erroneous-data"><i class="fa fa-check"></i><b>8.5.1</b> Erroneous data</a></li>
<li class="chapter" data-level="8.5.2" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#missing-data"><i class="fa fa-check"></i><b>8.5.2</b> Missing data</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#summary-4"><i class="fa fa-check"></i><b>8.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html"><i class="fa fa-check"></i><b>9</b> OHDSI Analytics Tools</a><ul>
<li class="chapter" data-level="9.1" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#analysisImplementation"><i class="fa fa-check"></i><b>9.1</b> Analysis implementation</a></li>
<li class="chapter" data-level="9.2" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#analysis-strategy"><i class="fa fa-check"></i><b>9.2</b> Analysis strategy</a></li>
<li class="chapter" data-level="9.3" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#atlas"><i class="fa fa-check"></i><b>9.3</b> ATLAS</a><ul>
<li class="chapter" data-level="9.3.1" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#security"><i class="fa fa-check"></i><b>9.3.1</b> Security</a></li>
<li class="chapter" data-level="9.3.2" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#documentation"><i class="fa fa-check"></i><b>9.3.2</b> Documentation</a></li>
<li class="chapter" data-level="9.3.3" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#how-to-install"><i class="fa fa-check"></i><b>9.3.3</b> How to install</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#methods-library"><i class="fa fa-check"></i><b>9.4</b> Methods Library</a><ul>
<li class="chapter" data-level="9.4.1" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#support-for-large-scale-analytics"><i class="fa fa-check"></i><b>9.4.1</b> Support for large-scale analytics</a></li>
<li class="chapter" data-level="9.4.2" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#BigDataSupport"><i class="fa fa-check"></i><b>9.4.2</b> Support for big data</a></li>
<li class="chapter" data-level="9.4.3" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#documentation-1"><i class="fa fa-check"></i><b>9.4.3</b> Documentation</a></li>
<li class="chapter" data-level="9.4.4" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#system-requirements"><i class="fa fa-check"></i><b>9.4.4</b> System requirements</a></li>
<li class="chapter" data-level="9.4.5" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#installR"><i class="fa fa-check"></i><b>9.4.5</b> How to install</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#deployment-strategies"><i class="fa fa-check"></i><b>9.5</b> Deployment strategies</a><ul>
<li class="chapter" data-level="9.5.1" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#broadsea"><i class="fa fa-check"></i><b>9.5.1</b> Broadsea</a></li>
<li class="chapter" data-level="9.5.2" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#amazon-aws"><i class="fa fa-check"></i><b>9.5.2</b> Amazon AWS</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#summary-5"><i class="fa fa-check"></i><b>9.6</b> Summary</a></li>
<li class="chapter" data-level="9.7" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#exercises"><i class="fa fa-check"></i><b>9.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="SqlAndR.html"><a href="SqlAndR.html"><i class="fa fa-check"></i><b>10</b> SQL and R</a><ul>
<li class="chapter" data-level="10.1" data-path="SqlAndR.html"><a href="SqlAndR.html#SqlRender"><i class="fa fa-check"></i><b>10.1</b> SqlRender</a><ul>
<li class="chapter" data-level="10.1.1" data-path="SqlAndR.html"><a href="SqlAndR.html#sql-parameterization"><i class="fa fa-check"></i><b>10.1.1</b> SQL parameterization</a></li>
<li class="chapter" data-level="10.1.2" data-path="SqlAndR.html"><a href="SqlAndR.html#translation-to-other-sql-dialects"><i class="fa fa-check"></i><b>10.1.2</b> Translation to other SQL dialects</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="SqlAndR.html"><a href="SqlAndR.html#DatabaseConnector"><i class="fa fa-check"></i><b>10.2</b> DatabaseConnector</a><ul>
<li class="chapter" data-level="10.2.1" data-path="SqlAndR.html"><a href="SqlAndR.html#creating-a-connection"><i class="fa fa-check"></i><b>10.2.1</b> Creating a connection</a></li>
<li class="chapter" data-level="10.2.2" data-path="SqlAndR.html"><a href="SqlAndR.html#querying"><i class="fa fa-check"></i><b>10.2.2</b> Querying</a></li>
<li class="chapter" data-level="10.2.3" data-path="SqlAndR.html"><a href="SqlAndR.html#querying-using-ffdf-objects"><i class="fa fa-check"></i><b>10.2.3</b> Querying using ffdf objects</a></li>
<li class="chapter" data-level="10.2.4" data-path="SqlAndR.html"><a href="SqlAndR.html#querying-different-platforms-using-the-same-sql"><i class="fa fa-check"></i><b>10.2.4</b> Querying different platforms using the same SQL</a></li>
<li class="chapter" data-level="10.2.5" data-path="SqlAndR.html"><a href="SqlAndR.html#inserting-tables"><i class="fa fa-check"></i><b>10.2.5</b> Inserting tables</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="SqlAndR.html"><a href="SqlAndR.html#QueryTheCdm"><i class="fa fa-check"></i><b>10.3</b> Querying the CDM</a></li>
<li class="chapter" data-level="10.4" data-path="SqlAndR.html"><a href="SqlAndR.html#using-the-vocabulary-when-querying"><i class="fa fa-check"></i><b>10.4</b> Using the vocabulary when querying</a></li>
<li class="chapter" data-level="10.5" data-path="SqlAndR.html"><a href="SqlAndR.html#querylibrary"><i class="fa fa-check"></i><b>10.5</b> QueryLibrary</a></li>
<li class="chapter" data-level="10.6" data-path="SqlAndR.html"><a href="SqlAndR.html#designing-a-simple-study"><i class="fa fa-check"></i><b>10.6</b> Designing a simple study</a><ul>
<li class="chapter" data-level="10.6.1" data-path="SqlAndR.html"><a href="SqlAndR.html#problem-definition"><i class="fa fa-check"></i><b>10.6.1</b> Problem definition</a></li>
<li class="chapter" data-level="10.6.2" data-path="SqlAndR.html"><a href="SqlAndR.html#exposure"><i class="fa fa-check"></i><b>10.6.2</b> Exposure</a></li>
<li class="chapter" data-level="10.6.3" data-path="SqlAndR.html"><a href="SqlAndR.html#outcome"><i class="fa fa-check"></i><b>10.6.3</b> Outcome</a></li>
<li class="chapter" data-level="10.6.4" data-path="SqlAndR.html"><a href="SqlAndR.html#time-at-risk"><i class="fa fa-check"></i><b>10.6.4</b> Time-at-risk</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="SqlAndR.html"><a href="SqlAndR.html#implementing-the-study-using-sql-and-r"><i class="fa fa-check"></i><b>10.7</b> Implementing the study using SQL and R</a><ul>
<li class="chapter" data-level="10.7.1" data-path="SqlAndR.html"><a href="SqlAndR.html#exposure-cohort"><i class="fa fa-check"></i><b>10.7.1</b> Exposure cohort</a></li>
<li class="chapter" data-level="10.7.2" data-path="SqlAndR.html"><a href="SqlAndR.html#outcome-cohort"><i class="fa fa-check"></i><b>10.7.2</b> Outcome cohort</a></li>
<li class="chapter" data-level="10.7.3" data-path="SqlAndR.html"><a href="SqlAndR.html#incidence-rate-calculation"><i class="fa fa-check"></i><b>10.7.3</b> Incidence rate calculation</a></li>
<li class="chapter" data-level="10.7.4" data-path="SqlAndR.html"><a href="SqlAndR.html#clean-up"><i class="fa fa-check"></i><b>10.7.4</b> Clean up</a></li>
<li class="chapter" data-level="10.7.5" data-path="SqlAndR.html"><a href="SqlAndR.html#compatibility"><i class="fa fa-check"></i><b>10.7.5</b> Compatibility</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="SqlAndR.html"><a href="SqlAndR.html#summary-6"><i class="fa fa-check"></i><b>10.8</b> Summary</a></li>
<li class="chapter" data-level="10.9" data-path="SqlAndR.html"><a href="SqlAndR.html#exercises-1"><i class="fa fa-check"></i><b>10.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Cohorts.html"><a href="Cohorts.html"><i class="fa fa-check"></i><b>11</b> Defining cohorts</a><ul>
<li class="chapter" data-level="11.1" data-path="Cohorts.html"><a href="Cohorts.html#cohort-definitions"><i class="fa fa-check"></i><b>11.1</b> Cohort definitions</a><ul>
<li class="chapter" data-level="11.1.1" data-path="Cohorts.html"><a href="Cohorts.html#rule-based-cohort-definitions"><i class="fa fa-check"></i><b>11.1.1</b> Rule-based cohort definitions</a></li>
<li class="chapter" data-level="11.1.2" data-path="Cohorts.html"><a href="Cohorts.html#probabilistic-cohort-definitions"><i class="fa fa-check"></i><b>11.1.2</b> Probabilistic cohort definitions</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="Cohorts.html"><a href="Cohorts.html#cohort-definition-validity"><i class="fa fa-check"></i><b>11.2</b> Cohort definition validity</a></li>
<li class="chapter" data-level="11.3" data-path="Cohorts.html"><a href="Cohorts.html#ohdsi-gold-standard-phenotype-library"><i class="fa fa-check"></i><b>11.3</b> OHDSI Gold Standard Phenotype Library</a></li>
<li class="chapter" data-level="11.4" data-path="Cohorts.html"><a href="Cohorts.html#defining-a-cohort-for-hypertension"><i class="fa fa-check"></i><b>11.4</b> Defining a cohort for hypertension</a><ul>
<li class="chapter" data-level="11.4.1" data-path="Cohorts.html"><a href="Cohorts.html#implementing-a-cohort-using-atlas"><i class="fa fa-check"></i><b>11.4.1</b> Implementing a Cohort using ATLAS</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="Cohorts.html"><a href="Cohorts.html#implementing-the-cohort-using-sql"><i class="fa fa-check"></i><b>11.5</b> Implementing the cohort using SQL</a><ul>
<li class="chapter" data-level="11.5.1" data-path="Cohorts.html"><a href="Cohorts.html#connecting-to-the-database"><i class="fa fa-check"></i><b>11.5.1</b> Connecting to the database</a></li>
<li class="chapter" data-level="11.5.2" data-path="Cohorts.html"><a href="Cohorts.html#specifying-the-concepts"><i class="fa fa-check"></i><b>11.5.2</b> Specifying the concepts</a></li>
<li class="chapter" data-level="11.5.3" data-path="Cohorts.html"><a href="Cohorts.html#finding-first-use"><i class="fa fa-check"></i><b>11.5.3</b> Finding first use</a></li>
<li class="chapter" data-level="11.5.4" data-path="Cohorts.html"><a href="Cohorts.html#require-365-days-of-prior-observation"><i class="fa fa-check"></i><b>11.5.4</b> Require 365 days of prior observation</a></li>
<li class="chapter" data-level="11.5.5" data-path="Cohorts.html"><a href="Cohorts.html#require-prior-hypertension"><i class="fa fa-check"></i><b>11.5.5</b> Require prior hypertension</a></li>
<li class="chapter" data-level="11.5.6" data-path="Cohorts.html"><a href="Cohorts.html#no-prior-treatment"><i class="fa fa-check"></i><b>11.5.6</b> No prior treatment</a></li>
<li class="chapter" data-level="11.5.7" data-path="Cohorts.html"><a href="Cohorts.html#monotherapy"><i class="fa fa-check"></i><b>11.5.7</b> Monotherapy</a></li>
<li class="chapter" data-level="11.5.8" data-path="Cohorts.html"><a href="Cohorts.html#cohort-exit"><i class="fa fa-check"></i><b>11.5.8</b> Cohort exit</a></li>
<li class="chapter" data-level="11.5.9" data-path="Cohorts.html"><a href="Cohorts.html#cleanup"><i class="fa fa-check"></i><b>11.5.9</b> Cleanup</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="Cohorts.html"><a href="Cohorts.html#summary-7"><i class="fa fa-check"></i><b>11.6</b> Summary</a><ul>
<li class="chapter" data-level="11.6.1" data-path="Cohorts.html"><a href="Cohorts.html#exercises-2"><i class="fa fa-check"></i><b>11.6.1</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Characterization.html"><a href="Characterization.html"><i class="fa fa-check"></i><b>12</b> Characterization</a><ul>
<li class="chapter" data-level="12.1" data-path="Characterization.html"><a href="Characterization.html#database-level-characterization"><i class="fa fa-check"></i><b>12.1</b> Database Level Characterization</a></li>
<li class="chapter" data-level="12.2" data-path="Characterization.html"><a href="Characterization.html#cohort-characterization"><i class="fa fa-check"></i><b>12.2</b> Cohort characterization</a></li>
<li class="chapter" data-level="12.3" data-path="Characterization.html"><a href="Characterization.html#treatment-pathways"><i class="fa fa-check"></i><b>12.3</b> Treatment Pathways</a></li>
<li class="chapter" data-level="12.4" data-path="Characterization.html"><a href="Characterization.html#incidence"><i class="fa fa-check"></i><b>12.4</b> Incidence</a></li>
<li class="chapter" data-level="12.5" data-path="Characterization.html"><a href="Characterization.html#characterizing-hypertensive-persons"><i class="fa fa-check"></i><b>12.5</b> Characterizing hypertensive persons</a></li>
<li class="chapter" data-level="12.6" data-path="Characterization.html"><a href="Characterization.html#database-characterization-in-atlas"><i class="fa fa-check"></i><b>12.6</b> Database characterization in ATLAS</a></li>
<li class="chapter" data-level="12.7" data-path="Characterization.html"><a href="Characterization.html#cohort-characterization-in-atlas"><i class="fa fa-check"></i><b>12.7</b> Cohort characterization in ATLAS</a><ul>
<li class="chapter" data-level="12.7.1" data-path="Characterization.html"><a href="Characterization.html#design"><i class="fa fa-check"></i><b>12.7.1</b> Design</a></li>
<li class="chapter" data-level="12.7.2" data-path="Characterization.html"><a href="Characterization.html#executions"><i class="fa fa-check"></i><b>12.7.2</b> Executions</a></li>
<li class="chapter" data-level="12.7.3" data-path="Characterization.html"><a href="Characterization.html#results"><i class="fa fa-check"></i><b>12.7.3</b> Results</a></li>
<li class="chapter" data-level="12.7.4" data-path="Characterization.html"><a href="Characterization.html#defining-custom-features"><i class="fa fa-check"></i><b>12.7.4</b> Defining custom features</a></li>
</ul></li>
<li class="chapter" data-level="12.8" data-path="Characterization.html"><a href="Characterization.html#cohort-characterization-in-r"><i class="fa fa-check"></i><b>12.8</b> Cohort characterization in R</a><ul>
<li class="chapter" data-level="12.8.1" data-path="Characterization.html"><a href="Characterization.html#cohort-instantiation"><i class="fa fa-check"></i><b>12.8.1</b> Cohort instantiation</a></li>
<li class="chapter" data-level="12.8.2" data-path="Characterization.html"><a href="Characterization.html#data-extraction"><i class="fa fa-check"></i><b>12.8.2</b> Data extraction</a></li>
<li class="chapter" data-level="12.8.3" data-path="Characterization.html"><a href="Characterization.html#using-prespecified-analyses"><i class="fa fa-check"></i><b>12.8.3</b> Using prespecified analyses</a></li>
<li class="chapter" data-level="12.8.4" data-path="Characterization.html"><a href="Characterization.html#creating-aggregated-covariates"><i class="fa fa-check"></i><b>12.8.4</b> Creating aggregated covariates</a></li>
<li class="chapter" data-level="12.8.5" data-path="Characterization.html"><a href="Characterization.html#output-format"><i class="fa fa-check"></i><b>12.8.5</b> Output format</a></li>
<li class="chapter" data-level="12.8.6" data-path="Characterization.html"><a href="Characterization.html#custom-covariates"><i class="fa fa-check"></i><b>12.8.6</b> Custom covariates</a></li>
</ul></li>
<li class="chapter" data-level="12.9" data-path="Characterization.html"><a href="Characterization.html#cohort-pathways-in-atlas"><i class="fa fa-check"></i><b>12.9</b> Cohort pathways in ATLAS</a><ul>
<li class="chapter" data-level="12.9.1" data-path="Characterization.html"><a href="Characterization.html#design-1"><i class="fa fa-check"></i><b>12.9.1</b> Design</a></li>
<li class="chapter" data-level="12.9.2" data-path="Characterization.html"><a href="Characterization.html#executions-1"><i class="fa fa-check"></i><b>12.9.2</b> Executions</a></li>
<li class="chapter" data-level="12.9.3" data-path="Characterization.html"><a href="Characterization.html#viewing-results"><i class="fa fa-check"></i><b>12.9.3</b> Viewing Results</a></li>
</ul></li>
<li class="chapter" data-level="12.10" data-path="Characterization.html"><a href="Characterization.html#incidence-analysis-in-atlas"><i class="fa fa-check"></i><b>12.10</b> Incidence analysis in ATLAS</a><ul>
<li class="chapter" data-level="12.10.1" data-path="Characterization.html"><a href="Characterization.html#design-2"><i class="fa fa-check"></i><b>12.10.1</b> Design</a></li>
<li class="chapter" data-level="12.10.2" data-path="Characterization.html"><a href="Characterization.html#executions-2"><i class="fa fa-check"></i><b>12.10.2</b> Executions</a></li>
<li class="chapter" data-level="12.10.3" data-path="Characterization.html"><a href="Characterization.html#viewing-results-1"><i class="fa fa-check"></i><b>12.10.3</b> Viewing Results</a></li>
</ul></li>
<li class="chapter" data-level="12.11" data-path="Characterization.html"><a href="Characterization.html#summary-8"><i class="fa fa-check"></i><b>12.11</b> Summary</a></li>
<li class="chapter" data-level="12.12" data-path="Characterization.html"><a href="Characterization.html#exercises-3"><i class="fa fa-check"></i><b>12.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html"><i class="fa fa-check"></i><b>13</b> Population-Level Estimation</a><ul>
<li class="chapter" data-level="13.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#CohortMethod"><i class="fa fa-check"></i><b>13.1</b> The cohort method design</a><ul>
<li class="chapter" data-level="13.1.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#propensity-scores"><i class="fa fa-check"></i><b>13.1.1</b> Propensity scores</a></li>
<li class="chapter" data-level="13.1.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#VariableSelection"><i class="fa fa-check"></i><b>13.1.2</b> Variable selection</a></li>
<li class="chapter" data-level="13.1.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#caliper"><i class="fa fa-check"></i><b>13.1.3</b> Caliper</a></li>
<li class="chapter" data-level="13.1.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#overlap-preference-scores"><i class="fa fa-check"></i><b>13.1.4</b> Overlap: preference scores</a></li>
<li class="chapter" data-level="13.1.5" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#balance"><i class="fa fa-check"></i><b>13.1.5</b> Balance</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#the-self-controlled-cohort-design"><i class="fa fa-check"></i><b>13.2</b> The self-controlled cohort design</a></li>
<li class="chapter" data-level="13.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#the-case-control-design"><i class="fa fa-check"></i><b>13.3</b> The case-control design</a></li>
<li class="chapter" data-level="13.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#the-case-crossover-design"><i class="fa fa-check"></i><b>13.4</b> The case-crossover design</a></li>
<li class="chapter" data-level="13.5" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#the-self-controlled-case-series-design"><i class="fa fa-check"></i><b>13.5</b> The self-controlled case series design</a></li>
<li class="chapter" data-level="13.6" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#designing-a-hypertension-study"><i class="fa fa-check"></i><b>13.6</b> Designing a hypertension study</a><ul>
<li class="chapter" data-level="13.6.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#problem-definition-1"><i class="fa fa-check"></i><b>13.6.1</b> Problem definition</a></li>
<li class="chapter" data-level="13.6.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#target-and-comparator"><i class="fa fa-check"></i><b>13.6.2</b> Target and comparator</a></li>
<li class="chapter" data-level="13.6.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#outcome-1"><i class="fa fa-check"></i><b>13.6.3</b> Outcome</a></li>
<li class="chapter" data-level="13.6.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#time-at-risk-1"><i class="fa fa-check"></i><b>13.6.4</b> Time-at-risk</a></li>
<li class="chapter" data-level="13.6.5" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#model"><i class="fa fa-check"></i><b>13.6.5</b> Model</a></li>
<li class="chapter" data-level="13.6.6" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#study-summary"><i class="fa fa-check"></i><b>13.6.6</b> Study summary</a></li>
<li class="chapter" data-level="13.6.7" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#control-questions"><i class="fa fa-check"></i><b>13.6.7</b> Control questions</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#PleAtlas"><i class="fa fa-check"></i><b>13.7</b> Implementing the study using ATLAS</a><ul>
<li class="chapter" data-level="13.7.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#ComparisonSettings"><i class="fa fa-check"></i><b>13.7.1</b> Comparative cohort settings</a></li>
<li class="chapter" data-level="13.7.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#effect-estimation-analysis-settings"><i class="fa fa-check"></i><b>13.7.2</b> Effect estimation analysis settings</a></li>
<li class="chapter" data-level="13.7.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#evaluationSettings"><i class="fa fa-check"></i><b>13.7.3</b> Evaluation settings</a></li>
<li class="chapter" data-level="13.7.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#running-the-study-package"><i class="fa fa-check"></i><b>13.7.4</b> Running the study package</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#pleR"><i class="fa fa-check"></i><b>13.8</b> Implementing the study using R</a><ul>
<li class="chapter" data-level="13.8.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#cohort-instantiation-1"><i class="fa fa-check"></i><b>13.8.1</b> Cohort instantiation</a></li>
<li class="chapter" data-level="13.8.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#data-extraction-1"><i class="fa fa-check"></i><b>13.8.2</b> Data extraction</a></li>
<li class="chapter" data-level="13.8.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#defining-the-study-population"><i class="fa fa-check"></i><b>13.8.3</b> Defining the study population</a></li>
<li class="chapter" data-level="13.8.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#propensity-scores-1"><i class="fa fa-check"></i><b>13.8.4</b> Propensity scores</a></li>
<li class="chapter" data-level="13.8.5" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#outcome-models"><i class="fa fa-check"></i><b>13.8.5</b> Outcome models</a></li>
<li class="chapter" data-level="13.8.6" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#MultipleAnalyses"><i class="fa fa-check"></i><b>13.8.6</b> Running multiple analyses</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#studyOutputs"><i class="fa fa-check"></i><b>13.9</b> Study outputs</a><ul>
<li class="chapter" data-level="13.9.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#propensity-scores-and-model"><i class="fa fa-check"></i><b>13.9.1</b> Propensity scores and model</a></li>
<li class="chapter" data-level="13.9.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#covariate-balance"><i class="fa fa-check"></i><b>13.9.2</b> Covariate balance</a></li>
<li class="chapter" data-level="13.9.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#follow-up-and-power"><i class="fa fa-check"></i><b>13.9.3</b> Follow up and power</a></li>
<li class="chapter" data-level="13.9.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#kaplan-meier"><i class="fa fa-check"></i><b>13.9.4</b> Kaplan-Meier</a></li>
<li class="chapter" data-level="13.9.5" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#effect-size-estimate"><i class="fa fa-check"></i><b>13.9.5</b> Effect size estimate</a></li>
</ul></li>
<li class="chapter" data-level="13.10" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#summary-9"><i class="fa fa-check"></i><b>13.10</b> Summary</a></li>
<li class="chapter" data-level="13.11" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#excercises"><i class="fa fa-check"></i><b>13.11</b> Excercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html"><i class="fa fa-check"></i><b>14</b> Patient Level Prediction</a><ul>
<li class="chapter" data-level="14.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#the-prediction-problem"><i class="fa fa-check"></i><b>14.1</b> The prediction problem</a></li>
<li class="chapter" data-level="14.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#data-extraction-2"><i class="fa fa-check"></i><b>14.2</b> Data extraction</a><ul>
<li class="chapter" data-level="14.2.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#data-extraction-example"><i class="fa fa-check"></i><b>14.2.1</b> Data extraction example</a></li>
<li class="chapter" data-level="14.2.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#missingness"><i class="fa fa-check"></i><b>14.2.2</b> Missingness</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#modelFitting"><i class="fa fa-check"></i><b>14.3</b> Fitting the model</a><ul>
<li class="chapter" data-level="14.3.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#regularized-logistic-regression"><i class="fa fa-check"></i><b>14.3.1</b> Regularized logistic regression</a></li>
<li class="chapter" data-level="14.3.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#gradient-boosting-machines"><i class="fa fa-check"></i><b>14.3.2</b> Gradient boosting machines</a></li>
<li class="chapter" data-level="14.3.3" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#random-forest"><i class="fa fa-check"></i><b>14.3.3</b> Random forest</a></li>
<li class="chapter" data-level="14.3.4" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>14.3.4</b> K-nearest neighbors</a></li>
<li class="chapter" data-level="14.3.5" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#naive-bayes"><i class="fa fa-check"></i><b>14.3.5</b> Naive Bayes</a></li>
<li class="chapter" data-level="14.3.6" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#adaboost"><i class="fa fa-check"></i><b>14.3.6</b> AdaBoost</a></li>
<li class="chapter" data-level="14.3.7" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#decision-tree"><i class="fa fa-check"></i><b>14.3.7</b> Decision Tree</a></li>
<li class="chapter" data-level="14.3.8" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#multilayer-perceptron"><i class="fa fa-check"></i><b>14.3.8</b> Multilayer Perceptron</a></li>
<li class="chapter" data-level="14.3.9" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#deep-learning"><i class="fa fa-check"></i><b>14.3.9</b> Deep Learning</a></li>
<li class="chapter" data-level="14.3.10" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#other-algorithms"><i class="fa fa-check"></i><b>14.3.10</b> Other algorithms</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#evaluating-prediction-models"><i class="fa fa-check"></i><b>14.4</b> Evaluating prediction models</a><ul>
<li class="chapter" data-level="14.4.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#evaluation-types"><i class="fa fa-check"></i><b>14.4.1</b> Evaluation Types</a></li>
<li class="chapter" data-level="14.4.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#performance"><i class="fa fa-check"></i><b>14.4.2</b> Performance Metrics</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#designing-a-patient-level-prediction-study"><i class="fa fa-check"></i><b>14.5</b> Designing a patient-level prediction Study</a><ul>
<li class="chapter" data-level="14.5.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#problem-definition-2"><i class="fa fa-check"></i><b>14.5.1</b> Problem definition</a></li>
<li class="chapter" data-level="14.5.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#study-population-definition"><i class="fa fa-check"></i><b>14.5.2</b> Study population definition</a></li>
<li class="chapter" data-level="14.5.3" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#model-development-settings"><i class="fa fa-check"></i><b>14.5.3</b> Model development settings</a></li>
<li class="chapter" data-level="14.5.4" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#model-evaluation"><i class="fa fa-check"></i><b>14.5.4</b> Model evaluation</a></li>
<li class="chapter" data-level="14.5.5" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#study-summary-1"><i class="fa fa-check"></i><b>14.5.5</b> Study summary</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#implementing-the-study-in-atlas"><i class="fa fa-check"></i><b>14.6</b> Implementing the study in ATLAS</a><ul>
<li class="chapter" data-level="14.6.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#prediction-problem-settings"><i class="fa fa-check"></i><b>14.6.1</b> Prediction Problem Settings</a></li>
<li class="chapter" data-level="14.6.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#analysis-settings"><i class="fa fa-check"></i><b>14.6.2</b> Analysis Settings</a></li>
<li class="chapter" data-level="14.6.3" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#execution-settings"><i class="fa fa-check"></i><b>14.6.3</b> Execution settings</a></li>
<li class="chapter" data-level="14.6.4" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#training-settings"><i class="fa fa-check"></i><b>14.6.4</b> Training settings</a></li>
<li class="chapter" data-level="14.6.5" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#importing-and-exporting-a-study"><i class="fa fa-check"></i><b>14.6.5</b> Importing and exporting a study</a></li>
<li class="chapter" data-level="14.6.6" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#downloading-the-study-package"><i class="fa fa-check"></i><b>14.6.6</b> Downloading the study package</a></li>
<li class="chapter" data-level="14.6.7" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#running-the-study"><i class="fa fa-check"></i><b>14.6.7</b> Running the study</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#implementing-the-study-in-r"><i class="fa fa-check"></i><b>14.7</b> Implementing the study in R</a><ul>
<li class="chapter" data-level="14.7.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#cohort-instantiation-2"><i class="fa fa-check"></i><b>14.7.1</b> Cohort instantiation</a></li>
<li class="chapter" data-level="14.7.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#data-extraction-3"><i class="fa fa-check"></i><b>14.7.2</b> Data extraction</a></li>
<li class="chapter" data-level="14.7.3" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#additional-inclusion-criteria"><i class="fa fa-check"></i><b>14.7.3</b> Additional inclusion criteria</a></li>
<li class="chapter" data-level="14.7.4" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#model-development"><i class="fa fa-check"></i><b>14.7.4</b> Model Development</a></li>
<li class="chapter" data-level="14.7.5" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#internal-validation"><i class="fa fa-check"></i><b>14.7.5</b> Internal Validation</a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#single-model-viewer-app"><i class="fa fa-check"></i><b>14.8</b> Single model viewer app</a></li>
<li class="chapter" data-level="14.9" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#multiple-model-viewer-app"><i class="fa fa-check"></i><b>14.9</b> Multiple model viewer app</a><ul>
<li class="chapter" data-level="14.9.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#viewing-the-model-summary-and-settings"><i class="fa fa-check"></i><b>14.9.1</b> Viewing the model summary and settings</a></li>
<li class="chapter" data-level="14.9.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#viewing-model-performance"><i class="fa fa-check"></i><b>14.9.2</b> Viewing model performance</a></li>
<li class="chapter" data-level="14.9.3" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#viewing-the-model"><i class="fa fa-check"></i><b>14.9.3</b> Viewing the model</a></li>
</ul></li>
<li class="chapter" data-level="14.10" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#additional-patient-level-prediction-features"><i class="fa fa-check"></i><b>14.10</b> Additional Patient-level Prediction Features</a><ul>
<li class="chapter" data-level="14.10.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#journal-paper-generation"><i class="fa fa-check"></i><b>14.10.1</b> Journal paper generation</a></li>
</ul></li>
<li class="chapter" data-level="14.11" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#summary-10"><i class="fa fa-check"></i><b>14.11</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>IV Evidence Quality</b></span></li>
<li class="chapter" data-level="15" data-path="EvidenceQuality.html"><a href="EvidenceQuality.html"><i class="fa fa-check"></i><b>15</b> Evidence Quality</a><ul>
<li class="chapter" data-level="15.1" data-path="EvidenceQuality.html"><a href="EvidenceQuality.html#understanding-evidence-quality"><i class="fa fa-check"></i><b>15.1</b> Understanding Evidence Quality</a></li>
<li class="chapter" data-level="15.2" data-path="EvidenceQuality.html"><a href="EvidenceQuality.html#communicating-evidence-quality"><i class="fa fa-check"></i><b>15.2</b> Communicating Evidence Quality</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="DataQuality.html"><a href="DataQuality.html"><i class="fa fa-check"></i><b>16</b> Data Quality</a><ul>
<li class="chapter" data-level="16.1" data-path="DataQuality.html"><a href="DataQuality.html#sources-of-data-quality-problems"><i class="fa fa-check"></i><b>16.1</b> Sources of data quality problems</a></li>
<li class="chapter" data-level="16.2" data-path="DataQuality.html"><a href="DataQuality.html#data-quality-in-general"><i class="fa fa-check"></i><b>16.2</b> Data quality in general</a><ul>
<li class="chapter" data-level="16.2.1" data-path="DataQuality.html"><a href="DataQuality.html#data-quality-checks"><i class="fa fa-check"></i><b>16.2.1</b> Data quality checks</a></li>
<li class="chapter" data-level="16.2.2" data-path="DataQuality.html"><a href="DataQuality.html#etl-unit-tests"><i class="fa fa-check"></i><b>16.2.2</b> ETL unit tests</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="DataQuality.html"><a href="DataQuality.html#study-specific-checks"><i class="fa fa-check"></i><b>16.3</b> Study-specific checks</a><ul>
<li class="chapter" data-level="16.3.1" data-path="DataQuality.html"><a href="DataQuality.html#checking-mappings"><i class="fa fa-check"></i><b>16.3.1</b> Checking mappings</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="DataQuality.html"><a href="DataQuality.html#achillesInPractice"><i class="fa fa-check"></i><b>16.4</b> ACHILLES in practice</a></li>
<li class="chapter" data-level="16.5" data-path="DataQuality.html"><a href="DataQuality.html#study-specific-checks-in-practice"><i class="fa fa-check"></i><b>16.5</b> Study-specific checks in practice</a></li>
<li class="chapter" data-level="16.6" data-path="DataQuality.html"><a href="DataQuality.html#summary-11"><i class="fa fa-check"></i><b>16.6</b> Summary</a></li>
<li class="chapter" data-level="16.7" data-path="DataQuality.html"><a href="DataQuality.html#exercises-4"><i class="fa fa-check"></i><b>16.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="ClinicalValidity.html"><a href="ClinicalValidity.html"><i class="fa fa-check"></i><b>17</b> Clinical Validity</a></li>
<li class="chapter" data-level="18" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html"><i class="fa fa-check"></i><b>18</b> Software Validity</a><ul>
<li class="chapter" data-level="18.1" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#study-code-validity"><i class="fa fa-check"></i><b>18.1</b> Study code validity</a><ul>
<li class="chapter" data-level="18.1.1" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#automation"><i class="fa fa-check"></i><b>18.1.1</b> Automation as a requirement for reproducibility</a></li>
<li class="chapter" data-level="18.1.2" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#programming-best-practices"><i class="fa fa-check"></i><b>18.1.2</b> Programming best practices</a></li>
<li class="chapter" data-level="18.1.3" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#code-validation"><i class="fa fa-check"></i><b>18.1.3</b> Code validation</a></li>
<li class="chapter" data-level="18.1.4" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#using-the-methods-library"><i class="fa fa-check"></i><b>18.1.4</b> Using the Methods Library</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#methods-library-software-development-process"><i class="fa fa-check"></i><b>18.2</b> Methods Library software development process</a><ul>
<li class="chapter" data-level="18.2.1" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#source-code-management"><i class="fa fa-check"></i><b>18.2.1</b> Source Code Management</a></li>
<li class="chapter" data-level="18.2.2" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#documentation-2"><i class="fa fa-check"></i><b>18.2.2</b> Documentation</a></li>
<li class="chapter" data-level="18.2.3" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#availability-of-current-and-historical-archive-versions"><i class="fa fa-check"></i><b>18.2.3</b> Availability of Current and Historical Archive Versions</a></li>
<li class="chapter" data-level="18.2.4" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#maintenance-support-and-retirement"><i class="fa fa-check"></i><b>18.2.4</b> Maintenance, Support and Retirement</a></li>
<li class="chapter" data-level="18.2.5" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#qualified-personnel"><i class="fa fa-check"></i><b>18.2.5</b> Qualified Personnel</a></li>
<li class="chapter" data-level="18.2.6" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#physical-and-logical-security"><i class="fa fa-check"></i><b>18.2.6</b> Physical and Logical Security</a></li>
<li class="chapter" data-level="18.2.7" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#disaster-recovery"><i class="fa fa-check"></i><b>18.2.7</b> Disaster Recovery</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#methods-library-testing"><i class="fa fa-check"></i><b>18.3</b> Methods Library testing</a><ul>
<li class="chapter" data-level="18.3.1" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#unit-test"><i class="fa fa-check"></i><b>18.3.1</b> Unit test</a></li>
<li class="chapter" data-level="18.3.2" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#simulation"><i class="fa fa-check"></i><b>18.3.2</b> Simulation</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#summary-12"><i class="fa fa-check"></i><b>18.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="MethodValidity.html"><a href="MethodValidity.html"><i class="fa fa-check"></i><b>19</b> Method Validity</a><ul>
<li class="chapter" data-level="19.1" data-path="MethodValidity.html"><a href="MethodValidity.html#design-specific-diagnostics"><i class="fa fa-check"></i><b>19.1</b> Design-specific diagnostics</a></li>
<li class="chapter" data-level="19.2" data-path="MethodValidity.html"><a href="MethodValidity.html#diagnostics-for-all-estimation"><i class="fa fa-check"></i><b>19.2</b> Diagnostics for all estimation</a><ul>
<li class="chapter" data-level="19.2.1" data-path="MethodValidity.html"><a href="MethodValidity.html#NegativeControls"><i class="fa fa-check"></i><b>19.2.1</b> Negative controls</a></li>
<li class="chapter" data-level="19.2.2" data-path="MethodValidity.html"><a href="MethodValidity.html#PositiveControls"><i class="fa fa-check"></i><b>19.2.2</b> Positive controls</a></li>
<li class="chapter" data-level="19.2.3" data-path="MethodValidity.html"><a href="MethodValidity.html#metrics"><i class="fa fa-check"></i><b>19.2.3</b> Empirical evaluation</a></li>
<li class="chapter" data-level="19.2.4" data-path="MethodValidity.html"><a href="MethodValidity.html#p-value-calibration"><i class="fa fa-check"></i><b>19.2.4</b> P-value calibration</a></li>
<li class="chapter" data-level="19.2.5" data-path="MethodValidity.html"><a href="MethodValidity.html#confidence-interval-calibration"><i class="fa fa-check"></i><b>19.2.5</b> Confidence interval calibration</a></li>
<li class="chapter" data-level="19.2.6" data-path="MethodValidity.html"><a href="MethodValidity.html#replication-across-sites"><i class="fa fa-check"></i><b>19.2.6</b> Replication across sites</a></li>
<li class="chapter" data-level="19.2.7" data-path="MethodValidity.html"><a href="MethodValidity.html#sensitivity-analyses"><i class="fa fa-check"></i><b>19.2.7</b> Sensitivity analyses</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="MethodValidity.html"><a href="MethodValidity.html#method-validation-in-practice"><i class="fa fa-check"></i><b>19.3</b> Method validation in practice</a><ul>
<li class="chapter" data-level="19.3.1" data-path="MethodValidity.html"><a href="MethodValidity.html#selecting-negative-controls"><i class="fa fa-check"></i><b>19.3.1</b> Selecting negative controls</a></li>
<li class="chapter" data-level="19.3.2" data-path="MethodValidity.html"><a href="MethodValidity.html#including-controls"><i class="fa fa-check"></i><b>19.3.2</b> Including controls</a></li>
<li class="chapter" data-level="19.3.3" data-path="MethodValidity.html"><a href="MethodValidity.html#empirical-performance"><i class="fa fa-check"></i><b>19.3.3</b> Empirical performance</a></li>
<li class="chapter" data-level="19.3.4" data-path="MethodValidity.html"><a href="MethodValidity.html#p-value-calibration-1"><i class="fa fa-check"></i><b>19.3.4</b> P-value calibration</a></li>
<li class="chapter" data-level="19.3.5" data-path="MethodValidity.html"><a href="MethodValidity.html#confidence-interval-calibration-1"><i class="fa fa-check"></i><b>19.3.5</b> Confidence interval calibration</a></li>
<li class="chapter" data-level="19.3.6" data-path="MethodValidity.html"><a href="MethodValidity.html#between-database-heterogeneity"><i class="fa fa-check"></i><b>19.3.6</b> Between-database heterogeneity</a></li>
<li class="chapter" data-level="19.3.7" data-path="MethodValidity.html"><a href="MethodValidity.html#sensitivity-analyses-1"><i class="fa fa-check"></i><b>19.3.7</b> Sensitivity analyses</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="MethodValidity.html"><a href="MethodValidity.html#ohdsi-methods-benchmark"><i class="fa fa-check"></i><b>19.4</b> OHDSI Methods Benchmark</a></li>
<li class="chapter" data-level="19.5" data-path="MethodValidity.html"><a href="MethodValidity.html#summary-13"><i class="fa fa-check"></i><b>19.5</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>V OHDSI Studies</b></span></li>
<li class="chapter" data-level="20" data-path="StudySteps.html"><a href="StudySteps.html"><i class="fa fa-check"></i><b>20</b> Study steps</a><ul>
<li class="chapter" data-level="20.1" data-path="StudySteps.html"><a href="StudySteps.html#general-best-practice-guidelines"><i class="fa fa-check"></i><b>20.1</b> General Best Practice Guidelines</a><ul>
<li class="chapter" data-level="20.1.1" data-path="StudySteps.html"><a href="StudySteps.html#observational-study-definition"><i class="fa fa-check"></i><b>20.1.1</b> Observational Study Definition</a></li>
<li class="chapter" data-level="20.1.2" data-path="StudySteps.html"><a href="StudySteps.html#pre-specification-of-study-design"><i class="fa fa-check"></i><b>20.1.2</b> Pre-specification of Study Design</a></li>
<li class="chapter" data-level="20.1.3" data-path="StudySteps.html"><a href="StudySteps.html#protocol"><i class="fa fa-check"></i><b>20.1.3</b> Protocol</a></li>
<li class="chapter" data-level="20.1.4" data-path="StudySteps.html"><a href="StudySteps.html#standardized-analyses"><i class="fa fa-check"></i><b>20.1.4</b> Standardized analyses</a></li>
<li class="chapter" data-level="20.1.5" data-path="StudySteps.html"><a href="StudySteps.html#study-packages"><i class="fa fa-check"></i><b>20.1.5</b> Study packages</a></li>
<li class="chapter" data-level="20.1.6" data-path="StudySteps.html"><a href="StudySteps.html#the-data-underlying-the-cdm"><i class="fa fa-check"></i><b>20.1.6</b> The data underlying the CDM</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="StudySteps.html"><a href="StudySteps.html#study-steps-in-detail"><i class="fa fa-check"></i><b>20.2</b> Study Steps in detail</a><ul>
<li class="chapter" data-level="20.2.1" data-path="StudySteps.html"><a href="StudySteps.html#define-question"><i class="fa fa-check"></i><b>20.2.1</b> Define question</a></li>
<li class="chapter" data-level="20.2.2" data-path="StudySteps.html"><a href="StudySteps.html#review-data-availability-and-quality"><i class="fa fa-check"></i><b>20.2.2</b> Review data availability and quality</a></li>
<li class="chapter" data-level="20.2.3" data-path="StudySteps.html"><a href="StudySteps.html#study-populations"><i class="fa fa-check"></i><b>20.2.3</b> Study Populations</a></li>
<li class="chapter" data-level="20.2.4" data-path="StudySteps.html"><a href="StudySteps.html#Feasibility"><i class="fa fa-check"></i><b>20.2.4</b> Feasibility and Diagnostics</a></li>
<li class="chapter" data-level="20.2.5" data-path="StudySteps.html"><a href="StudySteps.html#finalize-protocol-and-study-package"><i class="fa fa-check"></i><b>20.2.5</b> Finalize protocol and study package</a></li>
<li class="chapter" data-level="20.2.6" data-path="StudySteps.html"><a href="StudySteps.html#execute-study"><i class="fa fa-check"></i><b>20.2.6</b> Execute Study</a></li>
<li class="chapter" data-level="20.2.7" data-path="StudySteps.html"><a href="StudySteps.html#interpretation-and-write-up"><i class="fa fa-check"></i><b>20.2.7</b> Interpretation and write-up</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="StudySteps.html"><a href="StudySteps.html#summary-14"><i class="fa fa-check"></i><b>20.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="NetworkResearch.html"><a href="NetworkResearch.html"><i class="fa fa-check"></i><b>21</b> OHDSI Network Research</a><ul>
<li class="chapter" data-level="21.1" data-path="NetworkResearch.html"><a href="NetworkResearch.html#what-is-the-ohdsi-research-network"><i class="fa fa-check"></i><b>21.1</b> What is the OHDSI Research Network?</a></li>
<li class="chapter" data-level="21.2" data-path="NetworkResearch.html"><a href="NetworkResearch.html#what-is-an-ohdsi-network-study"><i class="fa fa-check"></i><b>21.2</b> What is an OHDSI Network Study?</a></li>
<li class="chapter" data-level="21.3" data-path="NetworkResearch.html"><a href="NetworkResearch.html#executing-an-ohdsi-network-study"><i class="fa fa-check"></i><b>21.3</b> Executing an OHDSI Network Study</a><ul>
<li class="chapter" data-level="21.3.1" data-path="NetworkResearch.html"><a href="NetworkResearch.html#study-feasibility-and-design"><i class="fa fa-check"></i><b>21.3.1</b> Study Feasibility and Design</a></li>
<li class="chapter" data-level="21.3.2" data-path="NetworkResearch.html"><a href="NetworkResearch.html#study-execution"><i class="fa fa-check"></i><b>21.3.2</b> Study Execution</a></li>
<li class="chapter" data-level="21.3.3" data-path="NetworkResearch.html"><a href="NetworkResearch.html#results-dissemination-and-publication"><i class="fa fa-check"></i><b>21.3.3</b> Results Dissemination and Publication</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="NetworkResearch.html"><a href="NetworkResearch.html#types-of-network-studies"><i class="fa fa-check"></i><b>21.4</b> Types of Network Studies</a></li>
<li class="chapter" data-level="21.5" data-path="NetworkResearch.html"><a href="NetworkResearch.html#forward-looking-using-network-study-automation"><i class="fa fa-check"></i><b>21.5</b> Forward Looking: Using Network Study Automation</a></li>
<li class="chapter" data-level="21.6" data-path="NetworkResearch.html"><a href="NetworkResearch.html#best-practices-for-network-research"><i class="fa fa-check"></i><b>21.6</b> Best Practices for Network Research</a></li>
<li class="chapter" data-level="21.7" data-path="NetworkResearch.html"><a href="NetworkResearch.html#example-legend---hypertension"><i class="fa fa-check"></i><b>21.7</b> Example: LEGEND - Hypertension</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="Glossary.html"><a href="Glossary.html"><i class="fa fa-check"></i><b>A</b> Glossary</a></li>
<li class="chapter" data-level="B" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html"><i class="fa fa-check"></i><b>B</b> Cohort definitions</a><ul>
<li class="chapter" data-level="B.1" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#AceInhibitors"><i class="fa fa-check"></i><b>B.1</b> ACE inhibitors</a></li>
<li class="chapter" data-level="B.2" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#AceInhibitorsMono"><i class="fa fa-check"></i><b>B.2</b> New users of ACE inhibitors monotherapy</a></li>
<li class="chapter" data-level="B.3" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#Ami"><i class="fa fa-check"></i><b>B.3</b> Acute myocardial infarction (AMI)</a></li>
<li class="chapter" data-level="B.4" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#Angioedema"><i class="fa fa-check"></i><b>B.4</b> Angioedema</a></li>
<li class="chapter" data-level="B.5" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#ThiazidesMono"><i class="fa fa-check"></i><b>B.5</b> New users of Thiazide-like diuretics monotherapy</a></li>
<li class="chapter" data-level="B.6" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#HTN1yrFO"><i class="fa fa-check"></i><b>B.6</b> Patients initiating first-line therapy for hypertension</a></li>
<li class="chapter" data-level="B.7" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#HTN3yrFO"><i class="fa fa-check"></i><b>B.7</b> Patients initiating first-line therapy for hypertension with &gt;3 yr follow-up</a></li>
<li class="chapter" data-level="B.8" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#ACEiUse"><i class="fa fa-check"></i><b>B.8</b> ACE inhibitor use</a></li>
<li class="chapter" data-level="B.9" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#ARBUse"><i class="fa fa-check"></i><b>B.9</b> Angiotensin receptor blocker (ARB) use</a></li>
<li class="chapter" data-level="B.10" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#THZUse"><i class="fa fa-check"></i><b>B.10</b> Thiazide or thiazide-like diuretic use</a></li>
<li class="chapter" data-level="B.11" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#dCCBUse"><i class="fa fa-check"></i><b>B.11</b> dihydropyridine Calcium Channel Blocker (dCCB) use</a></li>
<li class="chapter" data-level="B.12" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#ndCCBUse"><i class="fa fa-check"></i><b>B.12</b> non-dihydropyridine Calcium Channel Blocker (ndCCB) use</a></li>
<li class="chapter" data-level="B.13" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#BBUse"><i class="fa fa-check"></i><b>B.13</b> beta blocker use</a></li>
<li class="chapter" data-level="B.14" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#DLoopUse"><i class="fa fa-check"></i><b>B.14</b> Diuretic-loop use</a></li>
<li class="chapter" data-level="B.15" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#DPUse"><i class="fa fa-check"></i><b>B.15</b> Diuretic-potassium sparing use</a></li>
<li class="chapter" data-level="B.16" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#A1BUse"><i class="fa fa-check"></i><b>B.16</b> alpha-1 blocker use</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="NegativeControlsAppendix.html"><a href="NegativeControlsAppendix.html"><i class="fa fa-check"></i><b>C</b> Negative controls</a><ul>
<li class="chapter" data-level="C.1" data-path="NegativeControlsAppendix.html"><a href="NegativeControlsAppendix.html#AceiThzNsc"><i class="fa fa-check"></i><b>C.1</b> ACEi and THZ</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="ProtocolTemplate.html"><a href="ProtocolTemplate.html"><i class="fa fa-check"></i><b>D</b> Protocol template</a></li>
<li class="chapter" data-level="E" data-path="SuggestedAnswers.html"><a href="SuggestedAnswers.html"><i class="fa fa-check"></i><b>E</b> Suggested Answers</a><ul>
<li class="chapter" data-level="E.1" data-path="SuggestedAnswers.html"><a href="SuggestedAnswers.html#SqlAndRanswers"><i class="fa fa-check"></i><b>E.1</b> SQL and R</a></li>
<li class="chapter" data-level="E.2" data-path="SuggestedAnswers.html"><a href="SuggestedAnswers.html#DataQualityanswers"><i class="fa fa-check"></i><b>E.2</b> Data Quality</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Book of OHDSI</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ExtractTransformLoad" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Extract Transform Load</h1>
<p><em>Chapter leads: Clair Blacketer &amp; Erica A. Voss</em></p>
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">7.1</span> Introduction</h2>
<p>In order to get from the native/raw data to the OMOP Common Data Model (CDM) we have to create an extract, transform, and load (ETL) process. This process should restructure the data to the CDM, and add mappings to the Standardized Vocabularies, and is typically implemented as a set of automated scripts, for example SQL scripts. It is important that this ETL process is repeatable, so that it can be rerun whenever the source data is refreshed.    </p>
<p>Creating an ETL is usually a large undertaking. Over the years, we have developed best practices, consisting of of four major steps:</p>
<ol style="list-style-type: decimal">
<li>Data experts and CDM experts together design the ETL.</li>
<li>People with medical knowledge create the code mappings.</li>
<li>A technical person implements the ETL.</li>
<li>All are involved in quality control.</li>
</ol>
<p>In this chapter we will discuss each of these steps in detail. Several tools have been developed by the OHDSI community to support some of these steps, and these will be discussed as well. We close this chapter with a discussion of CDM and ETL maintenance.</p>
</div>
<div id="step-1-design-the-etl" class="section level2">
<h2><span class="header-section-number">7.2</span> Step 1: Design the ETL</h2>
<p>It is important to clearly separate the design of the ETL from the implementation of the ETL. Designing the ETL requires extensive knowledge of both the source data, as well as the CDM. Implementing the ETL on the other hand typically relies mostly on technical expertise on how to make the ETL computationally efficient. If we try to do both at once, we are likely to get stuck in nitty-gritty details, while we should be focusing on the overall picture.</p>
<p>Two closely-integrated tools have been developed to support the ETL design process: White Rabbit, and Rabbit-in-a-Hat.</p>
<div id="white-rabbit" class="section level3">
<h3><span class="header-section-number">7.2.1</span> White Rabbit</h3>
<p>To initiate an ETL process on a database you need to understand your data, including the tables, fields, and content. This is where the <a href="https://github.com/OHDSI/WhiteRabbit">White Rabbit</a> tool comes in. White Rabbit is a software tool to help prepare for ETLs of longitudinal healthcare databases into the <a href="https://github.com/OHDSI/CommonDataModel">OMOP CDM</a>. White Rabbit scans your data and creates a report containing all the information necessary to begin designing the ETL. All source code and installation instructions, as well as a link to the manual, are available on GitHub.<a href="references.html#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a>  </p>
<p><strong>Scope and Purpose</strong></p>
<p>White Rabbits main function is to perform a scan of the source data, providing detailed information on the tables, fields, and values that appear in a field. The source data can be in comma-separated text files, or in a database (MySQL, SQL Server, Oracle, PostgreSQL, Microsoft APS, Microsoft Access, Amazon RedShift). The scan will generate a report that can be used as a reference when designing the ETL, for instance by using it in conjunction with the Rabbit-In-a-Hat tool. White Rabbit differs from standard data profiling tools in that it attempts to prevent the display of personally identifiable information (PII) data values in the generated output data file.</p>
<p><strong>Process Overview</strong></p>
<p>The typical sequence for using the software to scan source data:</p>
<ol style="list-style-type: decimal">
<li>Set working folder, the location on the local desktop computer where results will be exported.</li>
<li>Connect to the source database or CSV text file and test connection.</li>
<li>Select the tables of interest for the scan and scan the tables.</li>
<li>White Rabbit creates an export of information about the source data.</li>
</ol>
<p><strong>Setting a Working Folder</strong></p>
<p>After downloading and installing the White Rabbit application, the first thing you need to do is set a working folder. Any files that White Rabbit creates will be exported to this local folder. Use the Pick Folder button shown in Figure <a href="ExtractTransformLoad.html#fig:WhiteRabbitLocation">7.1</a> to navigate in your local environment where you would like the scan document to go.</p>
<div class="figure"><span id="fig:WhiteRabbitLocation"></span>
<img src="images/ExtractTransformLoad/WhiteRabbitLocation.png" alt="The &quot;Pick Folder&quot; button allows the specification of a working folder for the White Rabbit application." width="100%" />
<p class="caption">
Figure 7.1: The Pick Folder button allows the specification of a working folder for the White Rabbit application.
</p>
</div>
<p><strong>Connection to a Database</strong></p>
<p>White Rabbit supports delimited text files and various database platforms. Hover the mouse over the various fields to get a description of what is required. More detailed information can be found in the manual.</p>
<p><strong>Scanning the Tables in a Database</strong></p>
<p>After connecting to a database, you can scan the tables contained therein. A scan generates a report containing information on the source data that can be used to help design the ETL. Using the Scan tab shown in Figure <a href="ExtractTransformLoad.html#fig:WhiteRabbitAddTables">7.2</a> you can either select individual tables in the selected source database by clicking on Add (Ctrl + mouse click), or automatically select all tables in the database by clicking on Add all in DB.</p>
<div class="figure"><span id="fig:WhiteRabbitAddTables"></span>
<img src="images/ExtractTransformLoad/WhiteRabbitAddTables.png" alt="White Rabbit Scan tab." width="100%" />
<p class="caption">
Figure 7.2: White Rabbit Scan tab.
</p>
</div>
<p>There are a few setting options as well with the scan:</p>
<ul>
<li>Checking the Scan field values tells WhiteRabbit that you would like to investigate which values appear in the columns.</li>
<li>Min cell count is an option when scanning field values. By default, this is set to 5, meaning values in the source data that appear less than 5 times will not appear in the report. Individual data sets may have their own rules about what this minimum cell count can be.</li>
<li>Rows per table is an option when scanning field values. By default, White Rabbit will scan 100,000 randomly selected rows in the table.</li>
</ul>
<p>Once all settings are completed, press the Scan tables button. After the scan is completed the report will be written to the working folder.</p>
<p><strong>Interpreting the Scan Report</strong></p>
<p>Once the scan is complete, an Excel file is generated in the selected folder with one tab present for each table scanned as well as an overview tab. The overview tab lists all tables scanned, each field in each table, the data type of each field, the maximum length of the field, the number of rows in the table, the number of rows scanned, and how often each field was found to be empty. Figure <a href="ExtractTransformLoad.html#fig:ScanOverviewTab">7.3</a>. shows an example overview tab.</p>
<div class="figure"><span id="fig:ScanOverviewTab"></span>
<img src="images/ExtractTransformLoad/ScanOverviewTab.png" alt="Example overview tab from a scan report." width="100%" />
<p class="caption">
Figure 7.3: Example overview tab from a scan report.
</p>
</div>
<p>The tabs for each of the tables show each field, the values in each field, and the frequency of each value. Each source table column will generate two columns in the Excel. One column will list all distinct values that have a Min cell count greater than what was set at time of the scan. If a list of unique values was truncated, the last value in the list will be List truncated; this indicates that there are one or more additional unique source values that appear less than the number entered in the Min cell count. Next to each distinct value will be a second column that contains the frequency (the number of times that value occurs in the sample). These two columns (distinct values and frequency) will repeat for all the source columns in the table profiled in the workbook.</p>
<div class="figure"><span id="fig:scanSex"></span>
<img src="images/ExtractTransformLoad/ScanSex.png" alt="Example values for a single column." width="30%" />
<p class="caption">
Figure 7.4: Example values for a single column.
</p>
</div>
<p>The report is powerful in understanding your source data by highlighting what exists. For example, if the results shown in Figure <a href="ExtractTransformLoad.html#fig:scanSex">7.4</a> were given back on the Sex column within one of the tables scanned, we can see that there were two common values (1 and 2) that appeared 61,491 and 35,401 times respectively. White Rabbit will not define 1 as male and 2 as female; the data holder will typically need to define source codes unique to the source system. However, these two values (1 &amp; 2) are not the only values present in the data because we see this list was truncated. These other values appear with very low frequency (defined by Min cell count) and often represent incorrect or highly suspicious values. When generating an ETL we should not only plan to handle the high-frequency gender concepts 1 and 2 but the other low-frequency values that exist within this column. For example, if those lower frequency genders were NULL we want to make sure the ETL can handle processing that data and knows what to do in that situation.</p>
</div>
<div id="rabbit-in-a-hat" class="section level3">
<h3><span class="header-section-number">7.2.2</span> Rabbit-In-a-Hat</h3>
<p>With the White Rabbit scan in hand, we have a clear picture of the source data. We also know the full specification of the CDM. Now we need to define the logic to go from one to the other. This design activity requires thorough knowledge of both the source data and the CDM. The Rabbit-in-a-Hat tools that comes with the White Rabbit software is specifically designed to support a team of experts in these areas. In a typical setting, the ETL design team sits together in a room, while Rabbit-in-a-Hat is projected on a screen. In a first round, the table-to-table mappings can be collaboratively decided, after which field-to-field mappings can be designed, while defining the logic by which values will be transformed.  </p>
<p><strong>Scope and purpose</strong></p>
<p>Rabbit-In-a-Hat is designed to read and display a White Rabbit scan document. White Rabbit generates information about the source data while Rabbit-In-a-Hat uses that information and through a graphical user interface to allow a user to connect source data to tables and columns within the CDM. Rabbit-In-a-Hat generates documentation for the ETL process, it does not generate code to create an ETL.</p>
<p><strong>Process Overview</strong></p>
<p>The typical sequence for using this software to generate documentation of an ETL:</p>
<ol style="list-style-type: decimal">
<li>Scanned results from WhiteRabbit completed.</li>
<li>Open scanned results; interface displays source tables and CDM tables.</li>
<li>Connect source tables to CDM tables where the source table provides information for that corresponding CDM table.</li>
<li>For each source table to CDM table connection, further define the connection with source column to CDM column detail.</li>
<li>Save Rabbit-In-a-Hat work and export to a MS Word document.</li>
</ol>
<p><strong>Writing ETL Logic</strong></p>
<p>Once you have opened your White Rabbit scan report in Rabbit-In-a-Hat you are ready to begin designing and writing the logic for how to convert the source data to the OMOP CDM. As an example, the next few sections will depict how some of the tables in the Synthea<a href="references.html#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a> database might look during conversion.</p>
<p><strong>General Flow of an ETL</strong></p>
<p>Since the CDM is a person-centric model it is always a good idea to start mapping the PERSON table first. Every clinical event table (CONDITION_OCCURRENCE, DRUG_EXPOSURE, PROCEDURE_OCCURRENCE, etc.) refers to the PERSON table by way of the person_id so working out the logic for the PERSON table first makes it easier later on. After the PERSON table a good rule of thumb is to convert the OBSERVATION_PERIOD table next. Each person in a CDM database should have at least one OBSERVATION_PERIOD and, generally, most events for a person fall within this timeframe. Once the PERSON and OBSERVATION_PERIOD tables are done the dimensional tables like PROVIDER, CARE_SITE, and LOCATION are typically next. The final table logic that should be worked out prior to the clinical tables is VISIT_OCCURRENCE. Often this is the most complicated logic in the entire ETL and it is some of the most crucial since most events that occur during the course of a persons patient journey will happen during visits. Once those tables are finished it is your choice which CDM tables to map and in which order.</p>
<div class="figure"><span id="fig:etlFlow"></span>
<img src="images/ExtractTransformLoad/flowOfEtl.png" alt="General flow of an ETL and which tables to map first." width="100%" />
<p class="caption">
Figure 7.5: General flow of an ETL and which tables to map first.
</p>
</div>
<p>It is often the case that, during CDM conversion, you will need to make provisions for intermediate tables. This could be for assigning the correct VISIT_OCCURRENCE_IDs to events, or for mapping source codes to standard concepts (doing this step on the fly is often very slow). Intermediate tables are 100% allowed and encouraged. What is discouraged is the persistence and reliance on these intermediate tables once the conversion is complete.</p>
<div id="mapping-example-person-table" class="section level4">
<h4><span class="header-section-number">7.2.2.1</span> Mapping Example: Person table</h4>
<p>The Synthea data structure contains 20 columns in the patients table but not all were needed to populate the PERSON table, as seen in Figure <a href="ExtractTransformLoad.html#fig:syntheaPerson">7.6</a>. This is very common and should not be cause for alarm. In this example many of the data points in the Synthea patients table that were not used in the CDM PERSON table were additional identifiers like patient name, drivers license number, and passport number.</p>
<div class="figure"><span id="fig:syntheaPerson"></span>
<img src="images/ExtractTransformLoad/syntheaPersonTable.png" alt="Mapping of Synthea Patients table to CDM PERSON table." width="100%" />
<p class="caption">
Figure 7.6: Mapping of Synthea Patients table to CDM PERSON table.
</p>
</div>
<p>Table <a href="ExtractTransformLoad.html#tab:syntheaEtlPerson">7.1</a> below shows the logic that was imposed on the Synthea patients table to convert it to the CDM PERSON table. The Destination Field discusses where in the CDM data is being mapped to. The Source field highlights the column from the source table (in this case patients) that will be used to populate the CDM column. Finally, the Logic &amp; comments column gives explanations for the logic.</p>
<table>
<caption><span id="tab:syntheaEtlPerson">Table 7.1: </span> ETL logic to convert the Synthea Patients table to CDM PERSON table.</caption>
<colgroup>
<col width="31%" />
<col width="13%" />
<col width="55%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Destination Field</th>
<th align="left">Source field</th>
<th align="left">Logic &amp; comments</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PERSON_ID</td>
<td align="left"></td>
<td align="left">Autogenerate. The PERSON_ID will be generated at the time of implementation. This is because the id value from the source is a varchar value while the PERSON_ID is an integer. The id field from the source is set as the person_source_value to preserve that value and allow for error-checking if necessary.</td>
</tr>
<tr class="even">
<td align="left">GENDER_CONCEPT_ID</td>
<td align="left">gender</td>
<td align="left">When gender = M then set GENDER_CONCEPT_ID to 8507, when gender = F then set to 8532. Drop any rows with missing/unknown gender. These two concepts were chosen as they are the only two standard concepts in the gender domain. The choice to drop patients with unknown genders tends to be site-based, though it is recommended they are removed as people without a gender are excluded from analyses.</td>
</tr>
<tr class="odd">
<td align="left">YEAR_OF_BIRTH</td>
<td align="left">birthdate</td>
<td align="left">Take year from birthdate</td>
</tr>
<tr class="even">
<td align="left">MONTH_OF_BIRTH</td>
<td align="left">birthdate</td>
<td align="left">Take month from birthdate</td>
</tr>
<tr class="odd">
<td align="left">DAY_OF_BIRTH</td>
<td align="left">birthdate</td>
<td align="left">Take day from birthdate</td>
</tr>
<tr class="even">
<td align="left">BIRTH_DATETIME</td>
<td align="left">birthdate</td>
<td align="left">With midnight as time 00:00:00. Here, the source did not supply a time of birth so the choice was made to set it at midnight.</td>
</tr>
<tr class="odd">
<td align="left">RACE_CONCEPT_ID</td>
<td align="left">race</td>
<td align="left">When race = WHITE then set as 8527, when race = BLACK then set as 8516, when race = ASIAN then set as 8515, otherwise set as 0. These concepts were chosen because they are the standard concepts belonging to the race domain that most closely align with the race categories in the source.</td>
</tr>
<tr class="even">
<td align="left">ETHNICITY_CONCEPT_ID</td>
<td align="left">race ethnicity</td>
<td align="left">When race = HISPANIC, or when ethnicity in (CENTRAL_AMERICAN, DOMINICAN, MEXICAN, PUERTO_RICAN, SOUTH_AMERICAN) then set as 38003563, otherwise set as 0. This is a good example of how multiple source columns can contribute to one CDM column. In the CDM ethnicity is represented as either Hispanic or not Hispanic so values from both the source column race and source column ethnicity will determine this value.</td>
</tr>
<tr class="odd">
<td align="left">LOCATION_ID</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">PROVIDER_ID</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">CARE_SITE_ID</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">PERSON_SOURCE_VALUE</td>
<td align="left">id</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">GENDER_SOURCE_VALUE</td>
<td align="left">gender</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">GENDER_SOURCE_CONCEPT_ID</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">RACE_SOURCE_VALUE</td>
<td align="left">race</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">RACE_SOURCE_CONCEPT_ID</td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">ETHNICITY_SOURCE_VALUE</td>
<td align="left">ethnicity</td>
<td align="left">In this case the ETHNICITY_SOURCE_VALUE will have more granularity than the ETHNICITY_CONCEPT_ID.</td>
</tr>
<tr class="even">
<td align="left">ETHNICITY_SOURCE_CONCEPT_ID</td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>For more examples on how the Synthea dataset was mapped to the CDM please see the full specification document.<a href="references.html#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a></p>
</div>
</div>
</div>
<div id="step-2-create-the-code-mappings" class="section level2">
<h2><span class="header-section-number">7.3</span> Step 2: Create the code mappings</h2>
<p>More and more source codes are being added to the OMOP Vocabulary all the time. This means that the coding systems in the data being transformed to the CDM may already be included and mapped. Check the VOCABULARY table in the OMOP Vocabulary to see which vocabularies are included. To extract the mapping from non-standard source codes (e.g.ICD-10CM codes) to standard concepts (e.g.SNOMED codes), we can use the records in the CONCEPT_RELATIONSHIP table having relationship_id = Maps to. For example, to find the standard concept ID for the ICD-10CM code I21 (Acute Myocardial Infarction), we can use the following SQL:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode sql"><code class="sourceCode sql"><span id="cb1-1"><a href="ExtractTransformLoad.html#cb1-1"></a><span class="kw">SELECT</span> concept_id_2 standard_concept_id</span>
<span id="cb1-2"><a href="ExtractTransformLoad.html#cb1-2"></a><span class="kw">FROM</span> concept_relationship</span>
<span id="cb1-3"><a href="ExtractTransformLoad.html#cb1-3"></a><span class="kw">INNER</span> <span class="kw">JOIN</span> concept source_concept</span>
<span id="cb1-4"><a href="ExtractTransformLoad.html#cb1-4"></a>  <span class="kw">ON</span> concept_id <span class="op">=</span> concept_id_1</span>
<span id="cb1-5"><a href="ExtractTransformLoad.html#cb1-5"></a><span class="kw">WHERE</span> concept_code <span class="op">=</span> <span class="st">&#39;I21&#39;</span></span>
<span id="cb1-6"><a href="ExtractTransformLoad.html#cb1-6"></a>  <span class="kw">AND</span> vocabulary_id <span class="op">=</span> <span class="st">&#39;ICD10CM&#39;</span></span>
<span id="cb1-7"><a href="ExtractTransformLoad.html#cb1-7"></a>  <span class="kw">AND</span> relationship_id <span class="op">=</span> <span class="st">&#39;Maps to&#39;</span>; </span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">STANDARD_CONCEPT_ID</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">312327</td>
</tr>
</tbody>
</table>
<p>Unfortunately, sometimes the source data uses coding systems that are not in the Vocabulary. In this case, a mapping must be created from the source coding system to the Standard Concepts. Code mapping can be a daunting task, especially when there are many codes in the source coding system. There are several things that can be done to make the task easier:</p>
<ul>
<li>Focus on the most frequently used codes. A code that is never used or infrequently used is not worth the effort of mapping, since it will never be used in a real study.</li>
<li>Make use of existing information whenever possible. For example, many national drug coding systems have been mapped to ATC. Although ATC is not detailed enough for many purposes, the concept relationships between ATC and RxNorm can be used to make good guesses of what the right RxNorm codes are.</li>
<li>Use Usagi.</li>
</ul>
<div id="usagi" class="section level3">
<h3><span class="header-section-number">7.3.1</span> Usagi</h3>
<p>Usagi is a tool to aid the manual process of creating a code mapping. It can make suggested mappings based on textual similarity of code descriptions. If the source codes are only available in a foreign language, we have found that Google Translate<a href="references.html#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a> often gives surprisingly good translation of the terms into English. Usagi allows the user to search for the appropriate target concepts if the automated suggestion is not correct. Finally, the user can indicate which mappings are approved to be used in the ETL. Usagi is available on GitHub.<a href="references.html#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a>  </p>
<p><strong>Scope and purpose</strong></p>
<p>Source codes that need mapping are loaded into the Usagi (if the codes are not in English additional translations columns are needed). A term similarity approach is used to connect source codes to Vocabulary concepts. However, these code connections need to be manually reviewed and Usagi provides an interface to facilitate that. Usagi will only propose concepts that are marked as Standard concepts in the Vocabulary.</p>
<p><strong>Process Overview</strong></p>
<p>The typical sequence for using this software is:</p>
<ol style="list-style-type: decimal">
<li>Load codes from your sources system (source codes) that you would like to map to Vocabulary concepts.</li>
<li>Usagi will run term similarity approach to map source codes to Vocabulary concepts.</li>
<li>Leverage Usagi interface to check, and where needed, improve suggested mappings. Preferably an individual who has experience with the coding system and medical terminology should be used for this review.</li>
<li>Export final map generated by Usagi into the Vocabularys SOURCE_TO_CONCEPT_MAP.</li>
</ol>
<p><strong>Importing Source Codes into Usagi</strong></p>
<p>Export source codes from source system into a CSV or Excel (.xlsx) file. This should at least have columns containing the source code and an English source code description, however additional information about codes can be brought over as well (e.g.dose unit, or the description in the original language if translated). In addition to information about the source codes, the frequency of the code should preferably also be brought over, since this can help prioritize which codes should receive the most effort in mapping (e.g.you can have 1,000 source codes but only 100 are truly used within the system). If any source code information needs translating to English, use Google Translate to do that.</p>
<p>Note: source code extracts should be broken out by domain (i.e.drugs, procedures, conditions, observations) and not lumped into one large file.</p>
<p>Source codes are loaded into Usagi from the File &gt; Import codes menu. From here an Import codes  will display as seen in Figure <a href="ExtractTransformLoad.html#fig:usagiImport">7.7</a>. In this figure, the source code terms were in Dutch and were also translated into English. Usagi will leverage the English translations to map to the standard vocabulary.</p>
<div class="figure"><span id="fig:usagiImport"></span>
<img src="images/ExtractTransformLoad/usagiImport.png" alt="Usagi source code input screen." width="100%" />
<p class="caption">
Figure 7.7: Usagi source code input screen.
</p>
</div>
<p>The Column mapping section (bottom left) is where you define for Usagi how to use the imported table. If you mouse hover over the drop downs, a pop-up will appear defining each column. Usagi will not use the Additional info column(s) as information to associate source codes to Vocabulary concept codes; however, this additional information may help the individual reviewing the source code mapping and should be included.</p>
<p>Finally, in the Filters section (bottom right) you can set some restrictions for Usagi when mapping. For example, in Figure <a href="ExtractTransformLoad.html#fig:usagiImport">7.7</a>, the user is mapping the source codes only to concepts in the Condition domain. By default, Usagi only maps to Standard Concepts, but if the option Filter standard concepts is turned off, Usagi will also consider Classification Concepts. Hover your mouse over the different filters for additional information about the filter.</p>
<p>One special filter is Filter by automatically selected concepts / ATC code. If there is information that you can use to restrict the search, you can do so by providing a list of CONCEPT_IDs or an ATC code in the column indicated in the Auto concept ID column (semicolon-delimited). For example, in the case of drugs there might already be ATC codes assigned to each drug. Even though an ATC code does not uniquely identify a single RxNorm drug code, it does help limit the search space to only those concepts that fall under the ATC code in the Vocabulary. To use the ATC code, follow these steps:</p>
<ol style="list-style-type: decimal">
<li>In the Column mapping section, switch from Auto concept ID column to ATC column</li>
<li>In the Column mapping section, select the column containing the ATC code as ATC column.</li>
<li>Turnon the Filter by user selected concepts / ATC code on in the Filters section.</li>
</ol>
<p>You can also use other sources of information than the ATC code to restrict as well. In the example shown in the figure above, we used a partial mapping derived from UMLS to restrict the Usagi search. In that case we will need to use Auto concept ID column.</p>
<p>Once all your settings are finalized, click the Import button to import the file. The file import will take a few minutes as it is running the term similarity algorithm to map source codes.</p>
<p><strong>Reviewing Source Code to Vocabulary Concept Maps</strong></p>
<p>Once you have imported your input file of source codes, the mapping process begins. In Figure <a href="ExtractTransformLoad.html#fig:usagiOverview">7.8</a>, you see the Usagi screen is made up of 3 main sections: an overview table, the selected mapping section, and place to perform searches. Note that in any of the tables, you can right-click to select the columns that are shown or hidden to reduce the visual complexity.</p>
<div class="figure"><span id="fig:usagiOverview"></span>
<img src="images/ExtractTransformLoad/usagiOverview.png" alt="Usagi source code input screen." width="100%" />
<p class="caption">
Figure 7.8: Usagi source code input screen.
</p>
</div>
<p><strong>Approving a Suggested Mapping</strong></p>
<p>The Overview Table shows the current mapping of source codes to concepts. Right after importing source codes, this mapping contains the automatically generated suggested mappings based on term similarity and any search options. In the example in Figure <a href="ExtractTransformLoad.html#fig:usagiOverview">7.8</a>, the English names of Dutch condition codes were mapped to standard concepts in the Condition domain, because the user restricted the search to that domain. Usagi compared the source code descriptions to concept names and synonyms to find the best match. Because the user had selected Include source terms Usagi also considered the names and synonyms of all source concepts in the vocabulary that map to a particular concept. If Usagi is unable to make a mapping, it will map to the CONCEPT_ID = 0.</p>
<p>It is suggested that someone with experience with coding systems help map source codes to their associated standard vocabulary. That individual will work through code by code in the Overview Table to either accept the mapping Usagi has suggested or choose a new mapping. For example in Figure <a href="ExtractTransformLoad.html#fig:usagiOverview">7.8</a> we see that the Dutch term Hoesten which was translated to the English term Cough. Usagi used Cough and mapped it to the Vocabulary concept of 4158493-C/O - cough. There was a matching score of 0.58 associated to this matched pair (matching scores are typically 0 to 1 with 1 being a confident match), a score of 0.58 signifies that Usagi is not very sure of how well it has mapped this Dutch code to SNOMED. Let us say in this case, we are okay with this mapping, we can approve it by hitting the green Approve button in the bottom right hand portion of the screen.</p>
<p><strong>Searching for a New Mapping</strong></p>
<p>There will be cases where Usagi suggests a map and the user will be left to either try to find a better mapping or set the map to no concept (CONCEPT_ID = 0). In the example given in Figure <a href="ExtractTransformLoad.html#fig:usagiOverview">7.8</a>, we see for the Dutch Term Hoesten, which was translated to Cough. Usagis suggestion was restricted by the concept identified in our automatically derived mapping from UMLS, and the result might not be optimal. In the Search Facility, we could search for other concepts using either the actual term itself or a search box query.</p>
<p>When using the manual search box, one should keep in mind that Usagi uses a fuzzy search, and does not support structured search queries, so for example not supporting Boolean operators like AND and OR.</p>
<p>To continue our example, suppose we used the search term Cough to see if we could find a better mapping. On the right of the Query section of the Search Facility, there is a Filters section, this provides options to trim down the results from the Vocabulary when searching for the search term. In this case we know we want to only find standard concepts, and we allow concepts to be found based on the names and synonyms of source concepts in the vocabulary that map to those standard concepts.</p>
<p>When we apply these search criteria we find 254761-Cough and feel this may be an appropriate Vocabulary concept to map to our Dutch code. In order to do that we can hit the Replace concept button, which you will see in the Selected Source Code section update, followed by the Approve button. There is also an Add concept button, this allows for multiple standardized Vocabulary concepts to map to one source code (e.g.some source codes may bundle multiple diseases together while the standardized vocabulary may not).</p>
<p><strong>Concept information</strong></p>
<p>When looking for appropriate concepts to map to, it is important to consider the social life of a concept. The meaning of a concept might depend partially on its place in the hierarchy, and sometimes there are orphan concepts in the vocabulary with few or no hierarchical relationships, which would be ill-suited as target concepts. Usagi will often report the number of parents and children a concept has, and it also possible to show more information by pressing ALT + C or selecting view &gt; Concept information in the top menu bar.</p>
<div class="figure"><span id="fig:usagiConceptInfo"></span>
<img src="images/ExtractTransformLoad/usagiConceptInfo.png" alt="Usagi concept information panel." width="100%" />
<p class="caption">
Figure 7.9: Usagi concept information panel.
</p>
</div>
<p>Figure <a href="ExtractTransformLoad.html#fig:usagiConceptInfo">7.9</a> shows the concept information panel. It shows general information about a concept, as well as its parents, children, and other source codes that map to the concept. Users can use this panel to navigate the hierarchy and potentially choose a different target concept.</p>
<p>Continue to move through this process, code by code, until all codes have been checked. In the list of source codes at the top of the screen, by selecting the column heading you can sort the codes. Often, we suggest going from the highest frequency codes to the lowest. In the bottom left of the screen you can see the number of codes that have approved mappings, and how many code occurrences that corresponds to.</p>
<p>It is possible to add comments to mappings, which could be used to document why a mapping decision was made.</p>
<p><strong>Best Practices</strong></p>
<ul>
<li>Use someone who has experience with coding schemes.</li>
<li>By clicking on a column name, you can sort the columns in the Overview Table. It may be valuable to sort on Match Score; reviewing codes that Usagi is most confident on first may quickly knock out a significant chunk of codes. Also sorting on Frequency is valuable, spending more effort on frequent codes versus non-frequent is important.</li>
<li>It is okay to map some codes to CONCEPT_ID = 0, some codes may not be worth it to find a good map and others may just lack a proper map.</li>
<li>It is important to consider the context of a concept, specifically its parents and children.</li>
</ul>
<p><strong>Export the Usagi Map Created</strong></p>
<p>Once you have created your map within USAGI, the best way to use it moving forward is to export it and append it to the Vocabulary SOURCE_TO_CONCEPT_MAP table.</p>
<p>To export your mappings, go to File &gt; Export source_to_concept_map. A pop-up will appear asking you which SOURCE_VOCABULARY_ID you would like to use, type in a short identifier. Usagi will use this identifier. as the SOURCE_VOCABULARY_ID which will allow you to identify your specific mapping in the SOURCE_TO_CONCEPT_MAP table.</p>
<p>After selecting the SOURCE_VOCABULARY_ID, you give your export CSV a name and save to location. The export CSV structure is in that of the SOURCE_TO_CONCEPT_MAP table. This mapping could be appended to the OMOP Vocabularys SOURCE_TO_CONCEPT_MAP table. It would also make sense to append a single row to the VOCABULARY table defining the SOURCE_VOCABULARY_ID you defined in the step above. Finally, it is important to note that only mappings with the Approved status will be exported into the CSV file; the mapping needs to be completed in USAGI in order to export it.</p>
<p><strong>Updating an Usagi mapping</strong></p>
<p>Often a mapping is not a one-time effort. As data is updated perhaps new source codes are added, and the vocabulary is updated regularly, perhaps requiring an update of the mapping.</p>
<p>When the set of source codes is updated the following steps can be followed to support the update:</p>
<ol style="list-style-type: decimal">
<li>Import the new source code file</li>
<li>Choose File &gt; Apply previous mapping, and select the old Usagi mapping file</li>
<li>Identify codes that havent inherited approved mappings from the old mapping, and map them as usual.</li>
</ol>
<p>When the vocabulary is updated, follow these steps:</p>
<ol style="list-style-type: decimal">
<li>Download the new vocabulary files from Athena</li>
<li>Rebuild the Usagi index (Help &gt; Rebuild index)</li>
<li>Open the mapping file</li>
<li>Identify codes that map to concepts that in the new vocabulary version no longer are Standard concepts, and find more appropriate target concepts.</li>
</ol>
</div>
</div>
<div id="step-3-implement-the-etl" class="section level2">
<h2><span class="header-section-number">7.4</span> Step 3: Implement the ETL</h2>
<p>Once the design and code mappings are completed, the ETL process can be implemented in a piece of software. When the ETL was being designed we recommended that people who are knowledgeable about the source and CDM work together on the task. Similarly, when the ETL is being implemented it is preferred to use people who have experience with working with data (particularly large data) and experience with implementing ETLs. This may mean working with individuals outside of your immediate group or hiring technical consultants to execute the implementation. It is also important to note that this is not a one-time expense. Moving forward it would be good to have someone or a team who spends at least some dedicated time to maintaining and running the ETL (this will become clearer in Section <a href="ExtractTransformLoad.html#CDMandETLMaintenance">7.7</a>).</p>
<p>Implementation usually varies site to site and it largely depends on many factors including infrastructure, size of the database, the complexity of the ETL, and the technical expertise available. Because it depends on many factors the OHDSI community does not make a formal recommendation on how best to implement an ETL. There have been groups that use simple SQL builders, SAS, C#, Java, and Kettle. All have their advantages and disadvantages, and none are usable if there is nobody at the site who is familiar with the technology.</p>
<p>A few examples of different ETLs (listed in order of complexity):</p>
<ul>
<li>ETL-Synthea - A SQL builder written to convert the Synthea database
<ul>
<li><a href="https://github.com/OHDSI/etl-synthea">https://github.com/OHDSI/etl-synthea</a></li>
</ul></li>
<li>ETL-CDMBuilder - A .NET application designed to transform multiple databases
<ul>
<li><a href="https://github.com/OHDSI/etl-cdmbuilder">https://github.com/OHDSI/etl-cdmbuilder</a></li>
</ul></li>
<li>ETL-LambdaBuilder - A builder using the AWS lambda functionality
<ul>
<li><a href="https://github.com/OHDSI/etl-lambdabuilder">https://github.com/OHDSI/etl-lambdabuilder</a></li>
</ul></li>
</ul>
<p>It should be noted that after several independent attempts, we have given up on developing the ultimate user-friendly ETL tool. It is always the case that tools like that work well for 80% of the ETL, but for the remaining 20% of the ETL some low-level code needs to be written that is specific to a source database</p>
<p>Once the technical individuals are ready to start implementing, the ETL design document should be shared with them. There should be enough information in the documentation for them to get started however it should be expected that the developers have access to the ETL designers to ask questions during their development process. Logic that may be clear to the designers may be less clear to an implementer who might not be familiar with the data and CDM. The implementation phase should remain a team effort. It is considered acceptable practice to go through the process of CDM creation and testing between the implementers and designers, respectively, until both groups are in agreement that all logic has been executed correctly.</p>
</div>
<div id="step-4-quality-control" class="section level2">
<h2><span class="header-section-number">7.5</span> Step 4: Quality control</h2>
<p>For the extract, transform, load process, quality control is iterative. The typical pattern is to write logic -&gt; implement logic -&gt; test logic -&gt; fix/write logic. There are many ways to go about testing a CDM but below are recommend steps that have been developed across the community through years of ETL implementation. </p>
<ul>
<li>Review of the ETL design document, computer code, and code mappings. Any one person can make mistakes, so always at least one other person should review what the what was done.
<ul>
<li>The largest issues in the computer code tend to come from how the source codes in the native data are mapped to Standard Concepts. Mapping can get tricky, especially when it comes to date-specific codes like NDCs. Be sure to double check any area where mappings are done to ensure the correct source vocabularies are translated to the proper concept id.<br />
</li>
</ul></li>
<li>Manually compare all information on a sample of persons in the source and target data.
<ul>
<li>It can be helpful to walk through one persons data, ideally a person with a large number of unique records. Tracing through a single person can highlight issues if the data in the CDM is not how you expect it to look based on the agreed upon logic.</li>
</ul></li>
<li>Compare overall counts in the source and target data.
<ul>
<li>There may be some expected differences in counts depending on how you chose to address certain issues. For instance, some collaborators choose to drop any people with a NULL gender since those people will not be included in analyses anyway. It may also be the case that visits in the CDM are constructed differently than visits or encounters in the native data. Therefore, when comparing overall counts between the source and CDM data be sure to account for and expect these differences.<br />
</li>
</ul></li>
<li>Replicate a study that has already been performed on the source data on the CDM version.
<ul>
<li>This is a good way to understand any major differences between the source data and CDM version, though it is a little more time-intensive.</li>
</ul></li>
<li>Create unit tests meant to replicate a pattern in the source data that should be addressed in the ETL. For example, if your ETL specifies that patients without gender information should be dropped, create a unit test of a person without a gender and assess how the builder handles it.
<ul>
<li>Unit testing is very handy when evaluating the quality and accuracy of an ETL conversion. It usually involves creating a much smaller dataset that mimics the structure of the source data you are converting. Each person or record in the dataset should test a specific piece of logic as written in the ETL document. Using this method, it is easy to trace back issues and to identify failing logic. The small size also enables the computer code to execute very quickly allowing for faster iterations and error identification.</li>
</ul></li>
</ul>
<p>These are high-level ways to approach quality control from an ETL standpoint. For more detail on the data quality efforts going on within OHDSI, please see Chapter <a href="DataQuality.html#DataQuality">16</a>.</p>
</div>
<div id="etl-conventions-and-themis" class="section level2">
<h2><span class="header-section-number">7.6</span> ETL Conventions and THEMIS</h2>
<p>As more groups converted data to the CDM it became apparent that conventions needed to be specified. For example, what should the ETL do in a situation where a person record lacks a birth year? The goal of the CDM is to standardized healthcare data however if every group handles data specific scenarios differently it makes it more difficult to systematically use data across the network.</p>
<p>The OHDSI community started documenting conventions to improve consistency across CDMs. These defined conventions, that the OHDSI community has agreed upon, can be found on the CDM Wiki.<a href="references.html#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a> Each CDM table has its own set of conventions that can be referred to when designing an ETL. For example, persons are allowed to be missing a birth month or day, but if they lack a birth year the person should be dropped. In designing an ETL, refer to the conventions to help make certain design decisions that will be consistent with the community.</p>
<p>While it will never be possible to document all possible data scenarios that exist and what to do when they occur, there is an OHDSI work group trying to document common scenarios. THEMIS<a href="references.html#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a> is made up of individuals in the community who gather conventions, clarify them, share them with the community for comment, and then document finalized conventions in the CDM Wiki. Themis is an ancient Greek Titaness of divine order, fairness, law, natural law, and custom which seemed a good fit for this groups remit. When performing an ETL, if there is a scenario that you are unsure how to handle, THEMIS recommends that a question about the scenario is posed on the OHDSI Forums<a href="references.html#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a>. Most likely if you have a question, others in the community probably have it as well. THEMIS uses these discussions, as well as work group meetings and face-to-face discussions, to help inform what other conventions need to be documented.</p>
</div>
<div id="CDMandETLMaintenance" class="section level2">
<h2><span class="header-section-number">7.7</span> CDM and ETL maintenance</h2>
<p>It is no small effort to design the ETL, create the mappings, implement the ETL, and build out quality control measures. Unfortunately, the effort does not stop there. There is a cycle of ETL maintenance that is a continuous process after the first CDM is built. Some common triggers that require maintenance are: changes in the source data, a bug in the ETL, a new OMOP Vocabulary is released, or the CDM itself has changed or updated. If one of these triggers occur the following might need updating: the ETL documentation, the software programming running the ETL, and test cases and quality controls.</p>
<p>Often a healthcare data source is forever changing. New data might be available (e.g.a new column in the data might exist). Patience scenarios that never existed before suddenly do (e.g.a new patient who has a death record before they were born). Your understanding of the data may improve (e.g.some of the records around inpatient child birth come across as outpatient due to how claims are processed). Not all changes in the source data my trigger a change in the ETL processing of it, however at a bare minimum the changes that break the ETL processing will need to be addressed.</p>
<p>If bugs are found, they should be addressed. However, it is important to keep in mind that not all bugs are created equal. For example, let say in the COST table the column cost was being rounded to a whole digit (e.g.the source data had $3.82 and this became $4.00 in the CDM). If the primary researchers using the data were mostly performing characterizations of patients drug exposures and conditions, a bug such as this is of little importance and can be addressed in the future. If the primary researchers using the data also included health economists, this would be a critical bug that need to be addressed immediately.</p>
<p>The OMOP Vocabulary is also ever changing just as our source data may be. In fact, the Vocabulary can have multiple releases in one given month as vocabularies update. Each CDM is run on a specific version of a Vocabulary and running on a newer improved Vocabulary could result in changes in how sources codes get mapped to in the standardized vocabularies. Often differences between Vocabularies are minor, so building a new CDM every time a new Vocabulary is release is not necessary. However, it is good practice to adopt a new Vocabulary once or twice a year which would require reprocessing the CDM again. It is rare are there changes in a new version of a Vocabulary that would require the ETL code itself to be updated.</p>
<p>The final trigger that could require CDM or ETL maintenance is when the common data model itself updates. As the community grows and new data requirements are found this may lead to additional data being stored in the CDM. This might mean data that you previously were not storing in the CDM might have a location in a new CDM version. Less frequently are changes to existing CDM structure, however it is a possibility. For example, the CDM is moved to adopting DATETIME fields over the original DATE fields would could cause an error in ETL processing. CDM versions are not released often and sites can choose when they migrate.</p>
</div>
<div id="final-thoughts-on-etl" class="section level2">
<h2><span class="header-section-number">7.8</span> Final thoughts on ETL</h2>
<p>The ETL process is a difficult one to master for many reasons, not the least of which the fact that we are all working off unique source data, making it hard to create a one-size-fits-all solution. However, there are some hard won lessons we have learned over the years.</p>
<ul>
<li>The 80/20 rule. If you can avoid it do not spend too much time manually mapping source codes to concepts sets. Ideally, map the source codes that cover the majority of your data. This should be enough to get you started and you can address any remaining codes in the future based on use cases.</li>
<li>Its ok if you lose data that is not of research quality. Often these are the records that would be discarded before starting an analysis anyway, we just remove them during the ETL process instead.</li>
<li>A CDM requires maintenance. Just because you complete an ETL does not mean you do not need to touch it ever again. Your raw data might change, there might be a bug in the code, there may be new vocabulary or an update to the CDM. Plan for an allocate resources to these changes so your ETL is always up-to-date.</li>
<li>For support with getting started with the OHDSI CDM, performing your database conversion, or running the analytics tools, please visit our Implementers Forum<a href="references.html#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a>.</li>
</ul>
</div>
<div id="summary-3" class="section level2">
<h2><span class="header-section-number">7.9</span> Summary</h2>

<div class="rmdsummary">
<ul>
<li><p>There is a generally agreed upon process for how to approach an ETL, including</p>
<ul>
<li>Data experts and CDM experts together design the ETL</li>
<li>People with medical knowledge create the code mappings</li>
<li>A technical person implements the ETL</li>
<li>All are involved in quality control</li>
</ul></li>
<li><p>Tools have been developed by the OHDSI community to facilitate these steps and are freely available for use</p></li>
<li><p>There are many ETL examples and agreed upon conventions you can use as a guide</p></li>
</ul>
</div>


</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="StandardizedVocabularies.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="DataAnalyticsUseCases.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/OHDSI/TheBookOfOhdsi/edit/master/ExtractTransformLoad.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["TheBookOfOhdsi.pdf", "TheBookOfOhdsi.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
