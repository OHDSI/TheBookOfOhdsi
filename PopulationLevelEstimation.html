<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 Population-level estimation | The Book of OHDSI</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.11.1 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 Population-level estimation | The Book of OHDSI" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://ohdsi.github.io/TheBookOfOhdsi/" />
  <meta property="og:image" content="https://ohdsi.github.io/TheBookOfOhdsi/images/Cover/Cover.png" />
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="OHDSI/TheBookOfOhdsi" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 Population-level estimation | The Book of OHDSI" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="twitter:image" content="https://ohdsi.github.io/TheBookOfOhdsi/images/Cover/Cover.png" />

<meta name="author" content="Observational Health Data Science and Informatics" />


<meta name="date" content="2019-06-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon" />
<link rel="prev" href="Characterization.html">
<link rel="next" href="PatientLevelPrediction.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-104086677-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-104086677-2');
</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The Book of OHDSI</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#goals-of-this-book"><i class="fa fa-check"></i>Goals of this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure-of-the-book"><i class="fa fa-check"></i>Structure of the book</a></li>
</ul></li>
<li class="part"><span><b>I The OHDSI Community</b></span></li>
<li class="chapter" data-level="1" data-path="MissionVissionValues.html"><a href="MissionVissionValues.html"><i class="fa fa-check"></i><b>1</b> Mission, vision, values</a><ul>
<li class="chapter" data-level="1.1" data-path="MissionVissionValues.html"><a href="MissionVissionValues.html#our-mission"><i class="fa fa-check"></i><b>1.1</b> Our Mission</a></li>
<li class="chapter" data-level="1.2" data-path="MissionVissionValues.html"><a href="MissionVissionValues.html#our-vision"><i class="fa fa-check"></i><b>1.2</b> Our Vision</a></li>
<li class="chapter" data-level="1.3" data-path="MissionVissionValues.html"><a href="MissionVissionValues.html#our-objectives"><i class="fa fa-check"></i><b>1.3</b> Our Objectives</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Collaborators.html"><a href="Collaborators.html"><i class="fa fa-check"></i><b>2</b> Collaborators</a></li>
<li class="chapter" data-level="3" data-path="OpenScience.html"><a href="OpenScience.html"><i class="fa fa-check"></i><b>3</b> Open Science</a></li>
<li class="chapter" data-level="4" data-path="WhereToBegin.html"><a href="WhereToBegin.html"><i class="fa fa-check"></i><b>4</b> Where to begin</a></li>
<li class="part"><span><b>II Uniform Data Representation</b></span></li>
<li class="chapter" data-level="5" data-path="CommonDataModel.html"><a href="CommonDataModel.html"><i class="fa fa-check"></i><b>5</b> The Common Data Model</a><ul>
<li class="chapter" data-level="5.1" data-path="CommonDataModel.html"><a href="CommonDataModel.html#design-principles"><i class="fa fa-check"></i><b>5.1</b> Design Principles</a></li>
<li class="chapter" data-level="5.2" data-path="CommonDataModel.html"><a href="CommonDataModel.html#data-model-conventions"><i class="fa fa-check"></i><b>5.2</b> Data Model Conventions</a><ul>
<li class="chapter" data-level="5.2.1" data-path="CommonDataModel.html"><a href="CommonDataModel.html#model-conv"><i class="fa fa-check"></i><b>5.2.1</b> General conventions of the model</a></li>
<li class="chapter" data-level="5.2.2" data-path="CommonDataModel.html"><a href="CommonDataModel.html#general-conventions-of-schemas"><i class="fa fa-check"></i><b>5.2.2</b> General conventions of schemas</a></li>
<li class="chapter" data-level="5.2.3" data-path="CommonDataModel.html"><a href="CommonDataModel.html#general-conventions-of-data-tables"><i class="fa fa-check"></i><b>5.2.3</b> General conventions of data tables</a></li>
<li class="chapter" data-level="5.2.4" data-path="CommonDataModel.html"><a href="CommonDataModel.html#general-conventions-of-fields"><i class="fa fa-check"></i><b>5.2.4</b> General conventions of fields</a></li>
<li class="chapter" data-level="5.2.5" data-path="CommonDataModel.html"><a href="CommonDataModel.html#representation-of-content-through-concepts"><i class="fa fa-check"></i><b>5.2.5</b> Representation of content through Concepts</a></li>
<li class="chapter" data-level="5.2.6" data-path="CommonDataModel.html"><a href="CommonDataModel.html#difference-between-concept-ids-and-source-values"><i class="fa fa-check"></i><b>5.2.6</b> Difference between Concept IDs and Source Values</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="CommonDataModel.html"><a href="CommonDataModel.html#omop-cdm-standardized-tables"><i class="fa fa-check"></i><b>5.3</b> OMOP CDM Standardized Tables</a><ul>
<li class="chapter" data-level="5.3.1" data-path="CommonDataModel.html"><a href="CommonDataModel.html#running-example-endometriosis"><i class="fa fa-check"></i><b>5.3.1</b> Running Example: Endometriosis</a></li>
<li class="chapter" data-level="5.3.2" data-path="CommonDataModel.html"><a href="CommonDataModel.html#person"><i class="fa fa-check"></i><b>5.3.2</b> PERSON table</a></li>
<li class="chapter" data-level="5.3.3" data-path="CommonDataModel.html"><a href="CommonDataModel.html#observationPeriod"><i class="fa fa-check"></i><b>5.3.3</b> OBSERVATION_PERIOD table</a></li>
<li class="chapter" data-level="5.3.4" data-path="CommonDataModel.html"><a href="CommonDataModel.html#visitOccurrence"><i class="fa fa-check"></i><b>5.3.4</b> VISIT_OCCURRENCE</a></li>
<li class="chapter" data-level="5.3.5" data-path="CommonDataModel.html"><a href="CommonDataModel.html#conditionOccurrence"><i class="fa fa-check"></i><b>5.3.5</b> CONDITION_OCCURRENCE</a></li>
<li class="chapter" data-level="5.3.6" data-path="CommonDataModel.html"><a href="CommonDataModel.html#drugExposure"><i class="fa fa-check"></i><b>5.3.6</b> DRUG_EXPOSURE</a></li>
<li class="chapter" data-level="5.3.7" data-path="CommonDataModel.html"><a href="CommonDataModel.html#procedureOccurrence"><i class="fa fa-check"></i><b>5.3.7</b> PROCEDURE_OCCURRENCE</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="StandardizedVocabularies.html"><a href="StandardizedVocabularies.html"><i class="fa fa-check"></i><b>6</b> Standardized Vocabularies</a></li>
<li class="chapter" data-level="7" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html"><i class="fa fa-check"></i><b>7</b> Extract Transform Load</a></li>
<li class="part"><span><b>III Data Analytics</b></span></li>
<li class="chapter" data-level="8" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html"><i class="fa fa-check"></i><b>8</b> Data Analytics Use Cases</a><ul>
<li class="chapter" data-level="8.1" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#characterization"><i class="fa fa-check"></i><b>8.1</b> Characterization</a></li>
<li class="chapter" data-level="8.2" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#population-level-estimation"><i class="fa fa-check"></i><b>8.2</b> Population-level estimation</a></li>
<li class="chapter" data-level="8.3" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#patient-level-prediction"><i class="fa fa-check"></i><b>8.3</b> Patient-Level prediction</a></li>
<li class="chapter" data-level="8.4" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#limitations-of-observational-research"><i class="fa fa-check"></i><b>8.4</b> Limitations of observational research</a><ul>
<li class="chapter" data-level="8.4.1" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#missing-data"><i class="fa fa-check"></i><b>8.4.1</b> Missing data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html"><i class="fa fa-check"></i><b>9</b> OHDSI Analytics Tools</a></li>
<li class="chapter" data-level="10" data-path="SqlAndR.html"><a href="SqlAndR.html"><i class="fa fa-check"></i><b>10</b> SQL and R</a><ul>
<li class="chapter" data-level="10.1" data-path="SqlAndR.html"><a href="SqlAndR.html#SqlRender"><i class="fa fa-check"></i><b>10.1</b> SqlRender</a><ul>
<li class="chapter" data-level="10.1.1" data-path="SqlAndR.html"><a href="SqlAndR.html#sql-parameterization"><i class="fa fa-check"></i><b>10.1.1</b> SQL parameterization</a></li>
<li class="chapter" data-level="10.1.2" data-path="SqlAndR.html"><a href="SqlAndR.html#translation-to-other-sql-dialects"><i class="fa fa-check"></i><b>10.1.2</b> Translation to other SQL dialects</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="SqlAndR.html"><a href="SqlAndR.html#DatabaseConnector"><i class="fa fa-check"></i><b>10.2</b> DatabaseConnector</a><ul>
<li class="chapter" data-level="10.2.1" data-path="SqlAndR.html"><a href="SqlAndR.html#creating-a-connection"><i class="fa fa-check"></i><b>10.2.1</b> Creating a connection</a></li>
<li class="chapter" data-level="10.2.2" data-path="SqlAndR.html"><a href="SqlAndR.html#querying"><i class="fa fa-check"></i><b>10.2.2</b> Querying</a></li>
<li class="chapter" data-level="10.2.3" data-path="SqlAndR.html"><a href="SqlAndR.html#querying-using-ffdf-objects"><i class="fa fa-check"></i><b>10.2.3</b> Querying using ffdf objects</a></li>
<li class="chapter" data-level="10.2.4" data-path="SqlAndR.html"><a href="SqlAndR.html#querying-different-platforms-using-the-same-sql"><i class="fa fa-check"></i><b>10.2.4</b> Querying different platforms using the same SQL</a></li>
<li class="chapter" data-level="10.2.5" data-path="SqlAndR.html"><a href="SqlAndR.html#inserting-tables"><i class="fa fa-check"></i><b>10.2.5</b> Inserting tables</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="SqlAndR.html"><a href="SqlAndR.html#QueryTheCdm"><i class="fa fa-check"></i><b>10.3</b> Querying the CDM</a></li>
<li class="chapter" data-level="10.4" data-path="SqlAndR.html"><a href="SqlAndR.html#using-the-vocabulary-when-querying"><i class="fa fa-check"></i><b>10.4</b> Using the vocabulary when querying</a></li>
<li class="chapter" data-level="10.5" data-path="SqlAndR.html"><a href="SqlAndR.html#exercices"><i class="fa fa-check"></i><b>10.5</b> Exercices</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Cohorts.html"><a href="Cohorts.html"><i class="fa fa-check"></i><b>11</b> Building the building blocks: cohorts</a></li>
<li class="chapter" data-level="12" data-path="Characterization.html"><a href="Characterization.html"><i class="fa fa-check"></i><b>12</b> Characterization</a></li>
<li class="chapter" data-level="13" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html"><i class="fa fa-check"></i><b>13</b> Population-level estimation</a><ul>
<li class="chapter" data-level="13.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#study-designs"><i class="fa fa-check"></i><b>13.1</b> Study designs</a><ul>
<li class="chapter" data-level="13.1.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#CohortMethod"><i class="fa fa-check"></i><b>13.1.1</b> Cohort method</a></li>
<li class="chapter" data-level="13.1.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#self-controlled-cohort"><i class="fa fa-check"></i><b>13.1.2</b> Self-controlled cohort</a></li>
<li class="chapter" data-level="13.1.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#case-control"><i class="fa fa-check"></i><b>13.1.3</b> Case-control</a></li>
<li class="chapter" data-level="13.1.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#case-crossover"><i class="fa fa-check"></i><b>13.1.4</b> Case-crossover</a></li>
<li class="chapter" data-level="13.1.5" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#self-controlled-case-series"><i class="fa fa-check"></i><b>13.1.5</b> Self-controlled case series</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#designing-a-hypertension-study"><i class="fa fa-check"></i><b>13.2</b> Designing a hypertension study</a><ul>
<li class="chapter" data-level="13.2.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#problem-definition"><i class="fa fa-check"></i><b>13.2.1</b> Problem definition</a></li>
<li class="chapter" data-level="13.2.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#target-and-comparator"><i class="fa fa-check"></i><b>13.2.2</b> Target and comparator</a></li>
<li class="chapter" data-level="13.2.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#outcome"><i class="fa fa-check"></i><b>13.2.3</b> Outcome</a></li>
<li class="chapter" data-level="13.2.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#time-at-risk"><i class="fa fa-check"></i><b>13.2.4</b> Time-at-risk</a></li>
<li class="chapter" data-level="13.2.5" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#model"><i class="fa fa-check"></i><b>13.2.5</b> Model</a></li>
<li class="chapter" data-level="13.2.6" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#study-summary"><i class="fa fa-check"></i><b>13.2.6</b> Study summary</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#implementation-the-study-using-atlas"><i class="fa fa-check"></i><b>13.3</b> Implementation the study using ATLAS</a><ul>
<li class="chapter" data-level="13.3.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#ComparisonSettings"><i class="fa fa-check"></i><b>13.3.1</b> Comparative cohort settings</a></li>
<li class="chapter" data-level="13.3.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#effect-estimation-analysis-settings"><i class="fa fa-check"></i><b>13.3.2</b> Effect estimation analysis settings</a></li>
<li class="chapter" data-level="13.3.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#evaluationSettings"><i class="fa fa-check"></i><b>13.3.3</b> Evaluation settings</a></li>
<li class="chapter" data-level="13.3.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#running-the-study-package"><i class="fa fa-check"></i><b>13.3.4</b> Running the study package</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#implementation-the-study-using-r"><i class="fa fa-check"></i><b>13.4</b> Implementation the study using R</a><ul>
<li class="chapter" data-level="13.4.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#cohort-instantiation"><i class="fa fa-check"></i><b>13.4.1</b> Cohort instantiation</a></li>
<li class="chapter" data-level="13.4.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#data-extraction"><i class="fa fa-check"></i><b>13.4.2</b> Data extraction</a></li>
<li class="chapter" data-level="13.4.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#defining-the-study-population"><i class="fa fa-check"></i><b>13.4.3</b> Defining the study population</a></li>
<li class="chapter" data-level="13.4.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#propensity-scores"><i class="fa fa-check"></i><b>13.4.4</b> Propensity scores</a></li>
<li class="chapter" data-level="13.4.5" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#outcome-models"><i class="fa fa-check"></i><b>13.4.5</b> Outcome models</a></li>
<li class="chapter" data-level="13.4.6" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#running-multiple-analyses"><i class="fa fa-check"></i><b>13.4.6</b> Running multiple analyses</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#studyOutputs"><i class="fa fa-check"></i><b>13.5</b> Study outputs</a><ul>
<li class="chapter" data-level="13.5.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#propensity-score-and-model"><i class="fa fa-check"></i><b>13.5.1</b> Propensity score and model</a></li>
<li class="chapter" data-level="13.5.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#covariate-balance"><i class="fa fa-check"></i><b>13.5.2</b> Covariate balance</a></li>
<li class="chapter" data-level="13.5.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#follow-up-and-power"><i class="fa fa-check"></i><b>13.5.3</b> Follow up and power</a></li>
<li class="chapter" data-level="13.5.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#kaplan-meier"><i class="fa fa-check"></i><b>13.5.4</b> Kaplan Meier</a></li>
<li class="chapter" data-level="13.5.5" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#effect-size-estimate"><i class="fa fa-check"></i><b>13.5.5</b> Effect size estimate</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#excercises"><i class="fa fa-check"></i><b>13.6</b> Excercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html"><i class="fa fa-check"></i><b>14</b> Patient Level Prediction</a><ul>
<li class="chapter" data-level="14.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#designing-a-hypertension-study-1"><i class="fa fa-check"></i><b>14.1</b> Designing a hypertension study</a><ul>
<li class="chapter" data-level="14.1.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#problem-definition-1"><i class="fa fa-check"></i><b>14.1.1</b> Problem definition</a></li>
<li class="chapter" data-level="14.1.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#study-population-definition"><i class="fa fa-check"></i><b>14.1.2</b> Study population definition</a></li>
<li class="chapter" data-level="14.1.3" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#model-development-settings"><i class="fa fa-check"></i><b>14.1.3</b> Model development settings</a></li>
<li class="chapter" data-level="14.1.4" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#model-evaluation"><i class="fa fa-check"></i><b>14.1.4</b> Model evaluation</a></li>
<li class="chapter" data-level="14.1.5" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#study-summary-1"><i class="fa fa-check"></i><b>14.1.5</b> Study summary</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#implementing-the-study-in-r"><i class="fa fa-check"></i><b>14.2</b> Implementing the study in R</a><ul>
<li class="chapter" data-level="14.2.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#cohort-instantiation-1"><i class="fa fa-check"></i><b>14.2.1</b> Cohort instantiation</a></li>
<li class="chapter" data-level="14.2.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#data-extraction-1"><i class="fa fa-check"></i><b>14.2.2</b> Data extraction</a></li>
<li class="chapter" data-level="14.2.3" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#additional-inclusion-criteria"><i class="fa fa-check"></i><b>14.2.3</b> Additional inclusion criteria</a></li>
<li class="chapter" data-level="14.2.4" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#model-development"><i class="fa fa-check"></i><b>14.2.4</b> Model Development</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#implementing-the-study-in-atlas"><i class="fa fa-check"></i><b>14.3</b> Implementing the study in ATLAS</a></li>
<li class="chapter" data-level="14.4" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#internal-validation"><i class="fa fa-check"></i><b>14.4</b> Internal validation</a><ul>
<li class="chapter" data-level="14.4.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#discrimination"><i class="fa fa-check"></i><b>14.4.1</b> Discrimination</a></li>
<li class="chapter" data-level="14.4.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#calibration"><i class="fa fa-check"></i><b>14.4.2</b> Calibration</a></li>
<li class="chapter" data-level="14.4.3" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#smooth-calibration"><i class="fa fa-check"></i><b>14.4.3</b> Smooth Calibration</a></li>
<li class="chapter" data-level="14.4.4" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#preference-distribution"><i class="fa fa-check"></i><b>14.4.4</b> Preference distribution</a></li>
<li class="chapter" data-level="14.4.5" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#predicted-probability-distribution"><i class="fa fa-check"></i><b>14.4.5</b> Predicted probability distribution</a></li>
<li class="chapter" data-level="14.4.6" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#test-train-similarity"><i class="fa fa-check"></i><b>14.4.6</b> Test-Train similarity</a></li>
<li class="chapter" data-level="14.4.7" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#variable-scatter-plot"><i class="fa fa-check"></i><b>14.4.7</b> Variable scatter plot</a></li>
<li class="chapter" data-level="14.4.8" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#precision-recall"><i class="fa fa-check"></i><b>14.4.8</b> Precision recall</a></li>
<li class="chapter" data-level="14.4.9" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#demographic-summary"><i class="fa fa-check"></i><b>14.4.9</b> Demographic summary</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#external-validation"><i class="fa fa-check"></i><b>14.5</b> External validation</a></li>
<li class="chapter" data-level="14.6" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#journal-paper-generation"><i class="fa fa-check"></i><b>14.6</b> Journal paper generation</a></li>
<li class="chapter" data-level="14.7" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#excercises-1"><i class="fa fa-check"></i><b>14.7</b> Excercises</a></li>
</ul></li>
<li class="part"><span><b>IV Evidence Quality</b></span></li>
<li class="chapter" data-level="15" data-path="EvidenceQuality.html"><a href="EvidenceQuality.html"><i class="fa fa-check"></i><b>15</b> Evidence Quality</a></li>
<li class="chapter" data-level="16" data-path="DataQuality.html"><a href="DataQuality.html"><i class="fa fa-check"></i><b>16</b> Data Quality</a><ul>
<li class="chapter" data-level="16.1" data-path="DataQuality.html"><a href="DataQuality.html#introduction"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="DataQuality.html"><a href="DataQuality.html#achilles-heel-tool"><i class="fa fa-check"></i><b>16.2</b> Achilles Heel tool</a><ul>
<li class="chapter" data-level="16.2.1" data-path="DataQuality.html"><a href="DataQuality.html#precomputed-analyses"><i class="fa fa-check"></i><b>16.2.1</b> Precomputed Analyses</a></li>
<li class="chapter" data-level="16.2.2" data-path="DataQuality.html"><a href="DataQuality.html#example-dq-check"><i class="fa fa-check"></i><b>16.2.2</b> Example DQ check</a></li>
<li class="chapter" data-level="16.2.3" data-path="DataQuality.html"><a href="DataQuality.html#overview-of-existing-dq-heel-checks"><i class="fa fa-check"></i><b>16.2.3</b> Overview of existing DQ Heel checks</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="DataQuality.html"><a href="DataQuality.html#study-specific-checks"><i class="fa fa-check"></i><b>16.3</b> Study-specific checks</a><ul>
<li class="chapter" data-level="16.3.1" data-path="DataQuality.html"><a href="DataQuality.html#outcomes"><i class="fa fa-check"></i><b>16.3.1</b> Outcomes</a></li>
<li class="chapter" data-level="16.3.2" data-path="DataQuality.html"><a href="DataQuality.html#laboratory-data"><i class="fa fa-check"></i><b>16.3.2</b> Laboratory data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="ClinicalValidity.html"><a href="ClinicalValidity.html"><i class="fa fa-check"></i><b>17</b> Clinical Validity</a></li>
<li class="chapter" data-level="18" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html"><i class="fa fa-check"></i><b>18</b> Software Validity</a><ul>
<li class="chapter" data-level="18.1" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#software-development-process"><i class="fa fa-check"></i><b>18.1</b> Software Development Process</a><ul>
<li class="chapter" data-level="18.1.1" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#source-code-management"><i class="fa fa-check"></i><b>18.1.1</b> Source Code Management</a></li>
<li class="chapter" data-level="18.1.2" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#documentation"><i class="fa fa-check"></i><b>18.1.2</b> Documentation</a></li>
<li class="chapter" data-level="18.1.3" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#availability-of-current-and-historical-archive-versions"><i class="fa fa-check"></i><b>18.1.3</b> Availability of Current and Historical Archive Versions</a></li>
<li class="chapter" data-level="18.1.4" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#maintenance-support-and-retirement"><i class="fa fa-check"></i><b>18.1.4</b> Maintenance, Support and Retirement</a></li>
<li class="chapter" data-level="18.1.5" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#qualified-personnel"><i class="fa fa-check"></i><b>18.1.5</b> Qualified Personnel</a></li>
<li class="chapter" data-level="18.1.6" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#physical-and-logical-security"><i class="fa fa-check"></i><b>18.1.6</b> Physical and Logical Security</a></li>
<li class="chapter" data-level="18.1.7" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#disaster-recovery"><i class="fa fa-check"></i><b>18.1.7</b> Disaster Recovery</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#testing"><i class="fa fa-check"></i><b>18.2</b> Testing</a><ul>
<li class="chapter" data-level="18.2.1" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#unit-test"><i class="fa fa-check"></i><b>18.2.1</b> Unit test</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#conclusions"><i class="fa fa-check"></i><b>18.3</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="MethodValidity.html"><a href="MethodValidity.html"><i class="fa fa-check"></i><b>19</b> Method Validity</a><ul>
<li class="chapter" data-level="19.1" data-path="MethodValidity.html"><a href="MethodValidity.html#design-specific-diagnostics"><i class="fa fa-check"></i><b>19.1</b> Design-specific diagnostics</a></li>
<li class="chapter" data-level="19.2" data-path="MethodValidity.html"><a href="MethodValidity.html#diagnostics-for-all-estimation"><i class="fa fa-check"></i><b>19.2</b> Diagnostics for all estimation</a><ul>
<li class="chapter" data-level="19.2.1" data-path="MethodValidity.html"><a href="MethodValidity.html#negative-controls"><i class="fa fa-check"></i><b>19.2.1</b> Negative controls</a></li>
<li class="chapter" data-level="19.2.2" data-path="MethodValidity.html"><a href="MethodValidity.html#positive-controls"><i class="fa fa-check"></i><b>19.2.2</b> Positive controls</a></li>
<li class="chapter" data-level="19.2.3" data-path="MethodValidity.html"><a href="MethodValidity.html#empirical-evaluation"><i class="fa fa-check"></i><b>19.2.3</b> Empirical evaluation</a></li>
<li class="chapter" data-level="19.2.4" data-path="MethodValidity.html"><a href="MethodValidity.html#p-value-calibration"><i class="fa fa-check"></i><b>19.2.4</b> P-value calibration</a></li>
<li class="chapter" data-level="19.2.5" data-path="MethodValidity.html"><a href="MethodValidity.html#confidence-interval-calibration"><i class="fa fa-check"></i><b>19.2.5</b> Confidence interval calibration</a></li>
<li class="chapter" data-level="19.2.6" data-path="MethodValidity.html"><a href="MethodValidity.html#replication-across-sites"><i class="fa fa-check"></i><b>19.2.6</b> Replication across sites</a></li>
<li class="chapter" data-level="19.2.7" data-path="MethodValidity.html"><a href="MethodValidity.html#sensitivity-analyses"><i class="fa fa-check"></i><b>19.2.7</b> Sensitivity analyses</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="MethodValidity.html"><a href="MethodValidity.html#diagnostics-for-all-prediction"><i class="fa fa-check"></i><b>19.3</b> Diagnostics for all prediction</a></li>
<li class="chapter" data-level="19.4" data-path="MethodValidity.html"><a href="MethodValidity.html#method-validation-in-practice"><i class="fa fa-check"></i><b>19.4</b> Method validation in practice</a><ul>
<li class="chapter" data-level="19.4.1" data-path="MethodValidity.html"><a href="MethodValidity.html#selecting-negative-controls"><i class="fa fa-check"></i><b>19.4.1</b> Selecting negative controls</a></li>
<li class="chapter" data-level="19.4.2" data-path="MethodValidity.html"><a href="MethodValidity.html#including-controls"><i class="fa fa-check"></i><b>19.4.2</b> Including controls</a></li>
<li class="chapter" data-level="19.4.3" data-path="MethodValidity.html"><a href="MethodValidity.html#empirical-performance"><i class="fa fa-check"></i><b>19.4.3</b> Empirical performance</a></li>
<li class="chapter" data-level="19.4.4" data-path="MethodValidity.html"><a href="MethodValidity.html#calibrate-p-value"><i class="fa fa-check"></i><b>19.4.4</b> Calibrate p-value</a></li>
<li class="chapter" data-level="19.4.5" data-path="MethodValidity.html"><a href="MethodValidity.html#calibrate-confidence-interval"><i class="fa fa-check"></i><b>19.4.5</b> Calibrate confidence interval</a></li>
<li class="chapter" data-level="19.4.6" data-path="MethodValidity.html"><a href="MethodValidity.html#between-database-heterogeneity"><i class="fa fa-check"></i><b>19.4.6</b> Between-database heterogeneity</a></li>
<li class="chapter" data-level="19.4.7" data-path="MethodValidity.html"><a href="MethodValidity.html#sensitivity-analyses-1"><i class="fa fa-check"></i><b>19.4.7</b> Sensitivity analyses</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="MethodValidity.html"><a href="MethodValidity.html#advanced-ohdsi-methods-benchmark"><i class="fa fa-check"></i><b>19.5</b> Advanced: OHDSI Methods Benchmark</a></li>
<li class="chapter" data-level="19.6" data-path="MethodValidity.html"><a href="MethodValidity.html#exercises"><i class="fa fa-check"></i><b>19.6</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>V OHDSI Studies</b></span></li>
<li class="chapter" data-level="20" data-path="StudySteps.html"><a href="StudySteps.html"><i class="fa fa-check"></i><b>20</b> Study steps</a></li>
<li class="chapter" data-level="21" data-path="NetworkResearch.html"><a href="NetworkResearch.html"><i class="fa fa-check"></i><b>21</b> OHDSI Network Research</a><ul>
<li class="chapter" data-level="21.1" data-path="NetworkResearch.html"><a href="NetworkResearch.html#ohdsi-network-study-examples"><i class="fa fa-check"></i><b>21.1</b> OHDSI Network Study Examples</a><ul>
<li class="chapter" data-level="21.1.1" data-path="NetworkResearch.html"><a href="NetworkResearch.html#endometriosis-study"><i class="fa fa-check"></i><b>21.1.1</b> Endometriosis study</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="NetworkResearch.html"><a href="NetworkResearch.html#excercises-2"><i class="fa fa-check"></i><b>21.2</b> Excercises</a><ul>
<li class="chapter" data-level="21.2.1" data-path="NetworkResearch.html"><a href="NetworkResearch.html#defining-a-cohort"><i class="fa fa-check"></i><b>21.2.1</b> Defining a cohort</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="Glossary.html"><a href="Glossary.html"><i class="fa fa-check"></i><b>A</b> Glossary</a></li>
<li class="chapter" data-level="B" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html"><i class="fa fa-check"></i><b>B</b> Cohort definitions</a><ul>
<li class="chapter" data-level="B.1" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#AceInhibitors"><i class="fa fa-check"></i><b>B.1</b> ACE inhibitors</a></li>
<li class="chapter" data-level="B.2" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#AceInhibitorsMono"><i class="fa fa-check"></i><b>B.2</b> New users of ACE inhibitors as first-line monotherapy for hypertension</a></li>
<li class="chapter" data-level="B.3" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#Ami"><i class="fa fa-check"></i><b>B.3</b> Acute myocardial infarction (AMI)</a></li>
<li class="chapter" data-level="B.4" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#Angioedema"><i class="fa fa-check"></i><b>B.4</b> Angioedema</a></li>
<li class="chapter" data-level="B.5" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#ThiazidesMono"><i class="fa fa-check"></i><b>B.5</b> New users of Thiazide-like diuretics as first-line monotherapy for hypertension</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="NegativeControls.html"><a href="NegativeControls.html"><i class="fa fa-check"></i><b>C</b> Negative controls</a><ul>
<li class="chapter" data-level="C.1" data-path="NegativeControls.html"><a href="NegativeControls.html#AceiThzNsc"><i class="fa fa-check"></i><b>C.1</b> ACEi and THZ</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Book of OHDSI</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="PopulationLevelEstimation" class="section level1">
<h1><span class="header-section-number">Chapter 13</span> Population-level estimation</h1>
<p><em>Chapter leads: Martijn Schuemie, David Madigan, Marc Suchard &amp; Patrick Ryan</em></p>
<p>Observational healthcare data, such as administrative claims and electronic health records, offer opportunities to generate real-world evidence about the effect of treatments that can meaningfully improve the lives of patients. In this chapter we focus on population-level effect estimation, that is, the estimation of average causal effects of medical interventions on specific health outcomes of interest. In what follows, we consider two different estimation tasks:</p>
<ul>
<li><strong>Direct effect estimation</strong>: estimating the effect of an exposure on the risk of an outcome, as compared to no exposure.</li>
<li><strong>Comparative effect estimation</strong>: estimation the effect of one exposure (the target exposure) on the risk of an outcome, as compared to another exposure (the comparator exposure).</li>
</ul>
<p>In both cases, the patient-level causal effect contrasts a factual outcome, i.e., what happened to the exposed patient, with a counterfactual outcome, i.e., what would have happened had the exposure not occurred (direct) or had a different exposure occurred (comparative). Since any one patient reveals only the factual outcome (the fundamental problem of causal inference), the various effect estimation designs employ different analytic devices to shed light on the counterfactual outcomes.</p>
<p>Use-cases for population-level effect estimation include treatment selection, safety surveillance, and comparative effectiveness. Methods can test specific hypotheses one-at-a-time (e.g. ‘signal evaluation’) or explore multiple-hypotheses-at-once (e.g. ‘signal detection’). In all cases, the objective remains the same: to produce a high-quality estimate of the causal effect.</p>
<p>In this chapter we first describe various population-level estimation study designs availalbe in OHDSI’s standardized tools. We then detail the design of an example estimation study, followed by step-by-step guides of how to implement the design using ATLAS and R. Finally, we review the various outputs generated by the study, including study diagnostics and effect size estimates.</p>
<div id="study-designs" class="section level2">
<h2><span class="header-section-number">13.1</span> Study designs</h2>
<p>Several different study designs can be used to estimate treatment effects. The main difference between these is how they construct the (unobserved) counterfactual. Below is a brief discussion of the most commonly used designs, all of which are implemented as R packages in the <a href="https://ohdsi.github.io/MethodsLibrary/">OHDSI Methods Library</a>.</p>
<div id="CohortMethod" class="section level3">
<h3><span class="header-section-number">13.1.1</span> Cohort method</h3>
<div class="figure" style="text-align: center"><span id="fig:cohortMethod"></span>
<img src="images/PopulationLevelEstimation/cohortMethod.png" alt="The new-user cohort design. Subjects observed to initiate the target treatment are compared to those initiating the comparator treatment. To adjust for differences between the two treatment groups several adjustment strategies can be used, such as stratification, matching, or weighting by the propensity score, or by adding baseline characateristcs to the outcome model. The chararacteristics included in the propensity model or outcome model are captured prior to treatment initiation." width="90%" />
<p class="caption">
Figure 13.1: The new-user cohort design. Subjects observed to initiate the target treatment are compared to those initiating the comparator treatment. To adjust for differences between the two treatment groups several adjustment strategies can be used, such as stratification, matching, or weighting by the propensity score, or by adding baseline characateristcs to the outcome model. The chararacteristics included in the propensity model or outcome model are captured prior to treatment initiation.
</p>
</div>
<p>The new-user cohort method attempts to emulate a randomized clinical trial <span class="citation">(Hernan and Robins <a href="#ref-hernan_2016">2016</a>)</span>. Subjects that are observed to initiate one treatment (the target) are compared to subjects initiating another treatment (the comparator) and are followed for a specific amount of time following treatment initiation, for example the time they stay on the treatment. We can specify the questions we wish to answer in a cohort study by making the five choices highlighted in Table <a href="PopulationLevelEstimation.html#tab:cmChoices">13.1</a>.</p>
<table>
<caption><span id="tab:cmChoices">Table 13.1: </span> Main design choices in a comparative cohort design.</caption>
<colgroup>
<col width="24%" />
<col width="75%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Choice</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Target cohort</td>
<td align="left">A cohort representing the target treatment</td>
</tr>
<tr class="even">
<td align="left">Comparator cohort</td>
<td align="left">A cohort representing the comparator treatment</td>
</tr>
<tr class="odd">
<td align="left">Outcome cohort</td>
<td align="left">A cohort representing the outcome of interest</td>
</tr>
<tr class="even">
<td align="left">Time-at-risk</td>
<td align="left">At what time (often relative to the target and comparator cohort start and end dates) do we consider the risk of the outcome?</td>
</tr>
<tr class="odd">
<td align="left">Model</td>
<td align="left">The model used to estimate the effect while adjusting for differences between the target and comparator</td>
</tr>
</tbody>
</table>
<p>The choice of model specifies, among others, the type of model. For example, we could use a logistic regression, which evaluates whether or not the outcome has occurred, and produces an odds ratio. A logistic regression assumes the time-at-risk is of the same length for both target and comparator, or irrelevant. Alternatively, we could choose a Poisson regression which estimates the incidence rate ratio, assuming a constant incidence rate. Often a Cox regression is used which considers time to first outcome to estimate the hazard ratio, assuming proportional hazards.</p>

<div class="rmdimportant">
The new-user cohort method inherently is a method for comparative effect estimation, comparing one treatment to another. It is difficult to use this method to compare a treatment against no treatment, since it is hard to define a group of unexposed people that is comparable with the exposed group. If one wants to use this design for direct effect estimation, the preferred way is to select a comparator treatment for the same indication as the exposure of interest, where the comparator treatment is believed to have no effect on the outcome. Unfortunately, such a comparator might not always be available.
</div>

<p>A key concern is that the patients receiving the target treatment may systematically differ from those receiving the comparator treatment. For example, suppose the target cohort is, on average, 60 years old, whereas the comparator cohort is on average 40 years old. Comparing target to comparator with respect to any age-related health outcome (e.g. stroke) might then show substantial differences. An uninformed investigator might reach the conclusion there is a causal association between the target treatment and stroke as compared to the comparator. More prosaically or commonplace, the investigator might conclude that there exist target patients that experienced stroke that would not have done so had they received the comparator. This conclusion could well be entirely incorrect! Maybe those target patients disproportionately experienced stroke simply because they are older; maybe the target patients that experienced stroke might well have done so even if they had received the comparator. In this context, age is a “confounder”.</p>
<p><strong>Propensity scores</strong></p>
<p>In a randomized trial, a (virtual) coin toss assigns patients to their respective groups. Thus, by design, the probability that a patient receives the target treatment as against the comparator treatment does not relate in any way to patient characteristics such as age. The coin has no knowledge of the patient, and, what’s more, we know with certainty the exact probability that a patient receives the target exposure. As a consequence, and with increasing confidence as the number of patients in the trial increases, the two groups of patients essentially <em>cannot</em> differ systematically with respect to <em>any</em> patient characteristic. This guaranteed balance holds true for characteristics that the trial measured (such as age) as well as characteristics that the trial failed to measure.</p>
<p>For a given patient, the <em>propensity score</em> (PS) is the probability that that patient received the target treatment as against the comparator. <span class="citation">(Rosenbaum and Rubin <a href="#ref-rosenbaum_1983">1983</a>)</span> In a balanced two-arm randomized trial, the propensity score is 0.5 for every patient. In a propensity score-adjusted observational study, we estimate the probability that each patient received the target treatment. This a straightforward predictive modeling application; we fit a model (e.g. a logistic regression) that predicts whether a subject receives the target treatment, and use this model to generate predicted probabilities (the PS) for each subject. Unlike in a standard randomized trial, different patients will have different probabilities of receiving the target treatment. The PS can be used in several ways, for example by matching target subjects to comparator subjects with similar PS, by stratifying the study population based on the PS, or by weighting subjects using Inverse Probability of Treatment Weighting (IPTW) derived from the PS.</p>
<p>For example, suppose we use PS matching, and that Jan has a priori probability of 0.4 of receiving the target treatment and in fact receives the target treatment. If we can find a patient (named Jun) that also had an a priori probability of 0.4 of receiving the target treatment but in fact received the comparator, the comparison of Jan and Jun’s outcomes is like a mini-randomized trial, at least with respect to measured confounders. This comparison will yield an estimate of the Jan-Jun causal contrast that is as good as the one randomization would have produced. Estimation then proceeds as follows: for every patient that received the target, find one or more matched patients that received the comparator but had the same a priori probability of receiving the target. Compare the outcome for the target patient with the outcomes for the comparator patients within each of these matched groups.</p>
<p>Propensity scoring controls for measured confounders. In fact, if treatment assignment is “strongly ignorable” given measured characteristics, propensity scoring will yield an unbiased estimate of the causal effect. “Strongly ignorable” essentially means that there are no unmeasured confounders. Unfortunately this is not a testable assumption. See Chapter <a href="MethodValidity.html#MethodValidity">19</a> on Method Validity for further discussion of this issue.</p>
<p><strong>Variable selection</strong></p>
<p>In the past, PS were computed based on manually selected characteristics, and although the OHDSI tools can support such practices, we prefer the use of large-scale regularized regression using many generic characteristics. <span class="citation">(Tian, Schuemie, and Suchard <a href="#ref-tian_2018">2018</a>)</span> These characteristics include demographics, as well as all diagnoses, drug exposures, measurement, and medical procedures observed prior to and on the day of treatment initiation. A model typically involves 10,000 to 100,000 unique characteristics, which we fit using large-scale regularized regression <span class="citation">(Suchard et al. <a href="#ref-suchard_2013">2013</a>)</span> implemented in the <a href="https://ohdsi.github.io/Cyclops/">Cyclops</a> package. In essence, we let the data appropriately weight the characteristics.</p>

<div class="rmdimportant">
We typically include the day of treatment initiation in the covariate capture window because many relevant data points such as the diagnosis leading to the treatment are recorded on that date. This does require us to explicitly exclude the target and comparator treatment from the set of covariates, because these are the things we are trying to predict.
</div>

<p><strong>Caliper</strong></p>
<p>Since propensity scores fall on a continuum from 0 to 1, exact matching is rarely possible. Instead, the matching process finds patients that match the propensity score of a target patient(s) to within some tolerance known as a “caliper.” Following <span class="citation">Austin (<a href="#ref-austin_2011">2011</a>)</span>, we use a default of caliper of 0.2 standard deviations on the logit scale.</p>
<p><strong>Overlap: preference scores</strong></p>
<p>The propensity method requires that matching patients exist! As such, a key diagnostic shows the distribution of the propensity scores in the two groups. To facilitate interpretation, OHDSI tools plot a transformation of the propensity score called the “preference score” <span class="citation">(Walker et al. <a href="#ref-walker_2013">2013</a>)</span>. The preference score adjusts for the ‘market share’ of the two treatments. For example, if 10% of patients receive the target treatment (and 90% receive the comparator treatment), then patients with a preference score of 0.5 have a 10% probability of receiving the target treatment. Mathematically, the preference score is</p>
<p><span class="math display">\[\ln\left(\frac{F}{1-F}\right)=\ln\left(\frac{S}{1-S}\right)-\ln\left(\frac{P}{1-P}\right)\]</span></p>
<p>Where <span class="math inline">\(F\)</span> is the preference score, <span class="math inline">\(S\)</span> is the propensity score, and <span class="math inline">\(P\)</span> is the proportion of patients receiving the target treatment.</p>
<p><span class="citation">Walker et al. (<a href="#ref-walker_2013">2013</a>)</span> discuss the concept of “empirical equipoise”. They accept drug pairs as emerging from empirical equipoise if at least half of the dispensings of each of the drugs are to patients with a preference score of between 0.3 and 0.7.</p>
<p><strong>Balance</strong></p>
<p>Good practice always checks that the PS adjustment succeeded in creating balanced groups of patients. Figure<a href="PopulationLevelEstimation.html#fig:balance">13.18</a> shows the standard OHDSI output for checking balance. For each patient characteristic, this plots the standardized difference between means between the two exposure groups before and after PS adjustment. Some guidelines recommend an after-adjustment standardized difference upper bound of 0.1 <span class="citation">(Rubin <a href="#ref-rubin_2001">2001</a>)</span>.</p>
</div>
<div id="self-controlled-cohort" class="section level3">
<h3><span class="header-section-number">13.1.2</span> Self-controlled cohort</h3>
<div class="figure" style="text-align: center"><span id="fig:scc"></span>
<img src="images/PopulationLevelEstimation/selfControlledCohort.png" alt="The self-controlled cohort design. The rate of outcomes during exposure to the target is compared to the rate of outcomes in the time pre-exposure." width="90%" />
<p class="caption">
Figure 13.2: The self-controlled cohort design. The rate of outcomes during exposure to the target is compared to the rate of outcomes in the time pre-exposure.
</p>
</div>
<p>The self-controlled cohort (SCC) design <span class="citation">(Ryan, Schuemie, and Madigan <a href="#ref-ryan_2013">2013</a>)</span> compares the rate of outcomes during exposure to the rate of outcomes in the time just prior to the exposure. The four choices shown in Table <a href="PopulationLevelEstimation.html#tab:sccChoices">13.2</a> define a self-controlled cohort question.</p>
<table>
<caption><span id="tab:sccChoices">Table 13.2: </span> Main design choices in a self-controlled cohort design.</caption>
<colgroup>
<col width="24%" />
<col width="75%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Choice</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Target cohort</td>
<td align="left">A cohort representing the treatment</td>
</tr>
<tr class="even">
<td align="left">Outcome cohort</td>
<td align="left">A cohort representing the outcome of interest</td>
</tr>
<tr class="odd">
<td align="left">Time-at-risk</td>
<td align="left">At what time (often relative to the target cohort start and end dates) do we consider the risk of the outcome?</td>
</tr>
<tr class="even">
<td align="left">Control time</td>
<td align="left">The time period used as the control time</td>
</tr>
</tbody>
</table>
<p>Because the same subject that make up the exposed group are also used as the control group, no adjustment for between-person differences need to be made. However, the method is vulnerable to other differences, such as differences between different time periods.</p>
</div>
<div id="case-control" class="section level3">
<h3><span class="header-section-number">13.1.3</span> Case-control</h3>
<div class="figure" style="text-align: center"><span id="fig:caseControl"></span>
<img src="images/PopulationLevelEstimation/caseControl.png" alt="The case-control design. Subjects with the outcome (‘cases’) are compared to subjects without the outcome (‘controls’) in terms of their exposure status. Often, cases and controls are matched on various characteristics such as age and sex." width="90%" />
<p class="caption">
Figure 13.3: The case-control design. Subjects with the outcome (‘cases’) are compared to subjects without the outcome (‘controls’) in terms of their exposure status. Often, cases and controls are matched on various characteristics such as age and sex.
</p>
</div>
<p>Case-control <span class="citation">(Vandenbroucke and Pearce <a href="#ref-vandenbroucke_2012">2012</a>)</span> studies consider the question “are persons with a specific disease outcome exposed more frequently to a specific agent than those without the disease?” Thus, the central idea is to compare “cases”, i.e., subjects that experience the outcome of interest with “controls”, i.e., subjects that did not experience the outcome of interest. The choices in Table <a href="PopulationLevelEstimation.html#tab:ccChoices">13.3</a> define a case-control question.</p>
<table>
<caption><span id="tab:ccChoices">Table 13.3: </span> Main design choices in a case-control design.</caption>
<colgroup>
<col width="24%" />
<col width="75%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Choice</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Outcome cohort</td>
<td align="left">A cohort representing the cases (the outcome of interest)</td>
</tr>
<tr class="even">
<td align="left">Control selection</td>
<td align="left">A strategy for selecting controls and their index date</td>
</tr>
<tr class="odd">
<td align="left">Target cohort</td>
<td align="left">A cohort representing the treatment</td>
</tr>
<tr class="even">
<td align="left">[Nesting cohort]</td>
<td align="left">Optionally, a cohort defining the subpopulation from which cases and controls are drawn</td>
</tr>
<tr class="odd">
<td align="left">Time-at-risk</td>
<td align="left">At what time (often relative to the index date) do we consider exposure status?</td>
</tr>
</tbody>
</table>
<p>Often, one matches controls to cases based on characteristics such as age and sex to make them more comparable. Another widespread practice is to nest the analysis within a specific subgroup of people, for example people that have all been diagnosed with one of the indications of the exposure of interest.</p>
</div>
<div id="case-crossover" class="section level3">
<h3><span class="header-section-number">13.1.4</span> Case-crossover</h3>
<div class="figure" style="text-align: center"><span id="fig:caseCrossover"></span>
<img src="images/PopulationLevelEstimation/caseCrossover.png" alt="The case-crossover design. The time around the outcome is compared to a control date set at a predefined interval prior to the outcome date." width="90%" />
<p class="caption">
Figure 13.4: The case-crossover design. The time around the outcome is compared to a control date set at a predefined interval prior to the outcome date.
</p>
</div>
<p>The case-crossover <span class="citation">(Maclure <a href="#ref-maclure_1991">1991</a>)</span> design evaluates whether the rate of exposure is different at the time of the outcome than at some predefined number of days prior to the outcome. It is trying to determine whether there is something special about the day the outcome occurred. Table <a href="PopulationLevelEstimation.html#tab:ccrChoices">13.4</a> shows the choices that define a case-crossover question:</p>
<table>
<caption><span id="tab:ccrChoices">Table 13.4: </span> Main design choices in a case-crossover design.</caption>
<colgroup>
<col width="24%" />
<col width="75%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Choice</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Outcome cohort</td>
<td align="left">A cohort representing the cases (the outcome of interest)</td>
</tr>
<tr class="even">
<td align="left">Target cohort</td>
<td align="left">A cohort representing the treatment</td>
</tr>
<tr class="odd">
<td align="left">Time-at-risk</td>
<td align="left">At what time (often relative to the index date) do we consider exposure status?</td>
</tr>
<tr class="even">
<td align="left">Control time</td>
<td align="left">The time period used as the control time</td>
</tr>
</tbody>
</table>
<p>Since cases serve as their own control, it is a self-controlled design, and should therefore be robust to confounding due to between-person differences. One concern is that, because the outcome date is always later than the control date, the method will be positively biased if the overall frequency of exposure increases over time (or negatively biased if there is a decrease). To address this, the case-time-control design <span class="citation">(Suissa <a href="#ref-suissa_1995">1995</a>)</span> was developed, which adds matched controls to the case-crossover design to adjust for exposure trends.</p>
</div>
<div id="self-controlled-case-series" class="section level3">
<h3><span class="header-section-number">13.1.5</span> Self-controlled case series</h3>
<div class="figure" style="text-align: center"><span id="fig:selfControlledCaseSeries"></span>
<img src="images/PopulationLevelEstimation/selfControlledCaseSeries.png" alt="The Self-Controlled Case Series design. The rate of outcomes during exposure is compared to the rate of outcomes when not exposed." width="90%" />
<p class="caption">
Figure 13.5: The Self-Controlled Case Series design. The rate of outcomes during exposure is compared to the rate of outcomes when not exposed.
</p>
</div>
<p>The Self-Controlled Case Series (SCCS) design <span class="citation">(Farrington <a href="#ref-farrington_1995">1995</a>,whitaker_2006)</span> compares the rate of outcomes during exposure to the rate of outcomes during all unexposed time, both before, between, and after exposures. It is a Poisson regression that is conditioned on the person. Thus, it seeks to answer the question: “Given that a patient has the outcome, is the outcome more likely during exposed time compared to non-exposed time?”. The choices in Table <a href="PopulationLevelEstimation.html#tab:sccsChoices">13.5</a> define an SCCS question.</p>
<table>
<caption><span id="tab:sccsChoices">Table 13.5: </span> Main design choices in a self-controlled case series design.</caption>
<colgroup>
<col width="24%" />
<col width="75%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Choice</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Target cohort</td>
<td align="left">A cohort representing the treatment</td>
</tr>
<tr class="even">
<td align="left">Outcome cohort</td>
<td align="left">A cohort representing the outcome of interest</td>
</tr>
<tr class="odd">
<td align="left">Time-at-risk</td>
<td align="left">At what time (often relative to the target cohort start and end dates) do we consider the risk of the outcome?</td>
</tr>
<tr class="even">
<td align="left">Model</td>
<td align="left">The model to estimate the effect, including any adjustments for time-varying confounders</td>
</tr>
</tbody>
</table>
<p>Like other self-controlled designs, the SCCS is robust to confounding due to between-person differences, but vulnerable to confounding due to time-varying effects. Several adjustments are possible to attempt to account for these, for example by including age and season. A special variant of the SCCS includes not just the exposure of interest, but all other exposures to drugs recorded in the database <span class="citation">(Simpson et al. <a href="#ref-simpson_2013">2013</a>)</span>, potentially adding thousands of additional variables to the model. L1-regularization using cross-validation to select the regularization hyperparameter is applied to the coefficients of all exposures except the exposure of interest.</p>
<p>One important assumption underlying the SCCS is that the observation period end is independent of the date of the outcome. Because for some outcomes, especially ones that can be fatal such as stroke, this assumption can be violated an extension to the SCCS has been developed that corrects for any such dependency. <span class="citation">(Farrington et al. <a href="#ref-farrington_2011">2011</a>)</span></p>
</div>
</div>
<div id="designing-a-hypertension-study" class="section level2">
<h2><span class="header-section-number">13.2</span> Designing a hypertension study</h2>
<div id="problem-definition" class="section level3">
<h3><span class="header-section-number">13.2.1</span> Problem definition</h3>
<p>ACE inhibitors (ACEi) are widely used in patients with hypertension or ischemic heart disease, especially those with other comorbidities such as congestive heart failure, diabetes mellitus, or chronic kidney disease <span class="citation">(Zaman, Oparil, and Calhoun <a href="#ref-zaman_2002">2002</a>)</span>. Angioedema, a serious and sometimes life-threatening adverse event that usually manifests as swelling of the lips, tongue, mouth, larynx, pharynx, or periorbital region, has been linked to the use of these medications <span class="citation">(Sabroe and Black <a href="#ref-sabroe_1997">1997</a>)</span>. However, limited information is available about the absolute and relative risks for angioedema associated with the use of these medications. Existing evidence is primarily based on investigations of specific cohorts (e.g., predominantly male veterans or Medicaid beneficiaries), whose findings may not be generalizable to other populations, or based on investigations with few events, which provide unstable risk estimates <span class="citation">(Powers et al. <a href="#ref-powers_2012">2012</a>)</span>. Several observational studies compare ACEi to beta-blockers for the risk of angioedema <span class="citation">(Magid et al. <a href="#ref-magid_2010">2010</a>; Toh et al. <a href="#ref-toh_2012">2012</a>)</span>, but beta-blockers are no longer recommend as first-line treatment of hypertension <span class="citation">(Whelton et al. <a href="#ref-whelton_2018">2018</a>)</span>. A viable alternative treatment could be thiazides or thiazide-like diuretics (THZ), which could be just as effective in managing hypertension and its associated risks such as acute myocardial infarction (AMI).</p>
<p>We will apply our population-level estimation framework to observational healthcare data to address the following comparative estimation question:</p>
<blockquote>
<p>What is the risk of angioedema and acute myocaridal infarction in new users of ACE inhibitors compared to new users of thiazide and thiazide-like diuretics?</p>
</blockquote>
<p>Since this is a comparative effect estimation question we will apply the cohort method as described in Section <a href="PopulationLevelEstimation.html#CohortMethod">13.1.1</a>.</p>
</div>
<div id="target-and-comparator" class="section level3">
<h3><span class="header-section-number">13.2.2</span> Target and comparator</h3>
<p>We consider patients new-users if their first observed treatment for hypertension was monotherapy with any active ingredient in either the ACEi or THZ class. We define mono therapy as not starting on any other hypertension drug in the seven days following treatment initiation. We require patients to have at least one year of prior continuous observation in the database before first exposure and a recorded hypertension diagnosis at or in the year preceding treatment initiation.</p>
</div>
<div id="outcome" class="section level3">
<h3><span class="header-section-number">13.2.3</span> Outcome</h3>
<p>We define angioedema as any occurrence of an angioedema diagnose code during an inpatient or ER visit, and require there to be no angioedema diagnosis recorded in the seven days prior. We define AMI as any occurrence of an AMI diagnose code during an inpatient or ER visit, and require there to be no AMI diagnosis record in the 180 days prior.</p>
</div>
<div id="time-at-risk" class="section level3">
<h3><span class="header-section-number">13.2.4</span> Time-at-risk</h3>
<p>We define time-at-risk to start on the day after treatment initiation, and stop when exposure stops, allowing for a 30-day gap between subsequent prescriptions.</p>
</div>
<div id="model" class="section level3">
<h3><span class="header-section-number">13.2.5</span> Model</h3>
<p>We fit a PS model using the default set of covariates, which includes demographics, conditions, drugs, procedures, measurements, observations, and several co-morbidity scores. We exclude ACEi and THZ from the covariates. We perform variable-ratio matching <span class="citation">(Rassen et al. <a href="#ref-rassen_2012">2012</a>)</span> and condition the Cox regression on the matched sets.</p>
</div>
<div id="study-summary" class="section level3">
<h3><span class="header-section-number">13.2.6</span> Study summary</h3>
<table>
<caption><span id="tab:aceChoices">Table 13.6: </span> Main design choices four our comparative cohort study.</caption>
<colgroup>
<col width="24%" />
<col width="75%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Choice</th>
<th align="left">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Target cohort</td>
<td align="left">New users of ACE inhibitors as first-line monotherapy for hypertension.</td>
</tr>
<tr class="even">
<td align="left">Comparator cohort</td>
<td align="left">New users of thiazides or thiazide-like diuretics as first-line monotherapy for hypertension.</td>
</tr>
<tr class="odd">
<td align="left">Outcome cohort</td>
<td align="left">Angioedema or acute myocardial infarction.</td>
</tr>
<tr class="even">
<td align="left">Time-at-risk</td>
<td align="left">Starting the day after treatment initiation, stopping when exposure stops.</td>
</tr>
<tr class="odd">
<td align="left">Model</td>
<td align="left">Cox proportional hazards model using variable ratio matching.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="implementation-the-study-using-atlas" class="section level2">
<h2><span class="header-section-number">13.3</span> Implementation the study using ATLAS</h2>
<p>Here we demonstrate how this study can be implemented using the Estimation tool in ATLAS. Click on <img src="images/PopulationLevelEstimation/estimation.png" /> in the left bar of ATLAS, and create a new estimation study. Make sure to give the study an easy-to-recognize name. you can save the study design at any time by clicking the <img src="images/PopulationLevelEstimation/save.png" /> button.</p>
<p>In the Estimation design tool, there are three sections: Comparisons, Analysis Settings, and Evaluation Settings. We can specify multiple comparisons and multiple analysis settings, and ATLAS will execute all combinations of these as separate analyses. Here we discuss each section:</p>
<div id="ComparisonSettings" class="section level3">
<h3><span class="header-section-number">13.3.1</span> Comparative cohort settings</h3>
<p>A study can have one or more comparisons. Click on ‘Add Comparison’, which will open a new dialog. Click on <img src="images/PopulationLevelEstimation/open.png" /> to the select the target and comparator cohorts. By clicking on “Add Outcome” we can add our two outcome cohorts. We assume the cohorts have already been created in ATLAS as described in Chapter <a href="Cohorts.html#Cohorts">11</a>. The Appendix provides the full definitions of the target (Appendix <a href="CohortDefinitions.html#AceInhibitorsMono">B.2</a>) , comparator (Appendix <a href="CohortDefinitions.html#ThiazidesMono">B.5</a>), and outcome (Appendix <a href="CohortDefinitions.html#Angioedema">B.4</a> and Appendix <a href="CohortDefinitions.html#Ami">B.3</a>) cohorts. When done, the dialog should look like Figure <a href="PopulationLevelEstimation.html#fig:comparisons">13.6</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:comparisons"></span>
<img src="images/PopulationLevelEstimation/comparisons.png" alt="The comparison dialog" width="100%" />
<p class="caption">
Figure 13.6: The comparison dialog
</p>
</div>
<p>Note that we can select multiple outcomes for a target-comparator pair. Each outcome will be treated independently, and will basically result in separate analysis.</p>
<p><strong>Negative control outcomes</strong></p>
<p>We should also include a set of negative control outcomes. These are outcomes that are not believed to be caused by either the target or the comparator, and where therefore the true hazard ratio equals 1. Negative controls are discussed in more detail in Chapter <a href="MethodValidity.html#MethodValidity">19</a>. Here we assume a concept set has already been created and can simply be selected. The negative control concept set should contain a concept per negative control, and not include descendants. Figure <a href="PopulationLevelEstimation.html#fig:ncConceptSet">13.7</a> shows the negative control concept set used for this study.</p>
<div class="figure" style="text-align: center"><span id="fig:ncConceptSet"></span>
<img src="images/PopulationLevelEstimation/ncConceptSet.png" alt="Negative Control concept set." width="100%" />
<p class="caption">
Figure 13.7: Negative Control concept set.
</p>
</div>
<p><strong>Concepts to include</strong></p>
<p>When selecting concept to include, you can specify which covariates you would like to generate, for example to use in your propensity model. When specifying covariates here, all other covariates (aside from those you specified) are left out. We usually want to include all baseline covariates, letting the regularized regression build a model that balances all covariates. You might want to specify particular covariates when you are replicating an existing study that manually picked a small number of covariates. These inclusions can be specified in this comparison section or in the analysis section. The option in the analysis section of whether or not to include descendants will apply also here in the comparison section.</p>
<p><strong>Concepts to exclude</strong></p>
<p>Rather than specifying which concepts to include, we can instead specify concepts to <em>exclude</em>. When we submit a concept set in this field, we use every covariate except for those that we submitted. When using the default set of covariates, which includes all drugs and procedures occurring on the day of treatment initiation, we must exclude the target and comparator treatment, and any concepts that are directly related to these. For example, if the target exposure is an injectable, we should not only exclude the drug, but also the injection procedure from the propensity model. In this example, the covariates we want to exclude are ACEi and THZ. Figure <a href="PopulationLevelEstimation.html#fig:covsToExclude">13.8</a> shows we select a concept set that includes all these concepts.</p>
<div class="figure" style="text-align: center"><span id="fig:covsToExclude"></span>
<img src="images/PopulationLevelEstimation/covsToExclude.png" alt="The concept set defining the concepts to exclude. Note that no descendantsa have been included. We will specify to include these at analysis time in the Analysis settings." width="100%" />
<p class="caption">
Figure 13.8: The concept set defining the concepts to exclude. Note that no descendantsa have been included. We will specify to include these at analysis time in the Analysis settings.
</p>
</div>
<p>Often we want to include or exclude concepts <strong>and their descendants</strong>. We could specify the concept set to include descendant concepts. However, for various reasons it might be more efficient to not include descendant in the concept set, but rather automatically add them by setting the ‘Should descendant concepts be added’ option to <em>yes</em> in the Covariate Settings section of the Analysis settings that will be discussed later.</p>
<p>After selecting the negative controls and covariates to exclude, the lower half of the comparisons dialog should look like Figure <a href="PopulationLevelEstimation.html#fig:comparisons2">13.9</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:comparisons2"></span>
<img src="images/PopulationLevelEstimation/comparisons2.png" alt="The comparison window showing concept sets for negative controls and concepts to exclude." width="100%" />
<p class="caption">
Figure 13.9: The comparison window showing concept sets for negative controls and concepts to exclude.
</p>
</div>
</div>
<div id="effect-estimation-analysis-settings" class="section level3">
<h3><span class="header-section-number">13.3.2</span> Effect estimation analysis settings</h3>
<p>After closing the comparisons dialog you can click on ‘Add Analysis Settings’. In the box labeled ‘Analysis Name’, give the analysis a unique name that is easy to remember and locate in the future. For example, we could set the name to “Propensity score matching”.</p>
<p><strong>Study population</strong></p>
<p>There are a wide range of options to specify the study population; the set of subjects that will enter the analysis. Many of these overlap with options available when designing the target and comparator cohorts in the cohort definition tool. One reason for using the options in Estimation instead of in the cohort definition is re-usability: We can define the target, comparator, and outcome cohorts completely independently, and add dependencies between these at a later point in time. For example, if we wish to remove people who had the outcome before treatment initiation, we could do so in the definitions of the target and comparator cohort, but then we would need to create separate cohorts for every outcome! Instead, we can choose to have people with prior outcomes be removed in the analysis settings, and now we can reuse our target and comparator cohorts for our two outcomes of interest (as well as our negative control outcomes).</p>
<p>The <strong>study start and end dates</strong> can be used to limit the analyses to a specific period. The study end date also truncates risk windows, meaning no outcomes beyond the study end date will be considered. One reason for selecting a study start date might be that one of the drugs being studied is new and did not exist in an earlier time. Adjusting for this can also be done by answering “yes” to the question ‘<strong>Restrict the analysis to the period when both exposures are observed?</strong>’. Another reason to adjust study start and end dates might be that medical practice changed over time (e.g., due to a drug warning) and we are only interested in the time where medicine was practiced a specific way.</p>
<p>The option ‘<strong>Should only the first exposure per subject be included?</strong>’ can be used to restrict to the first exposure per patient. Often this is already done in the cohort definition, as is the case in this example. Similarly, the option ‘<strong>The minimum required continuous observation time prior to index date for a person to be included in the cohort</strong>’ is often already set in the cohort definition, and can therefore be left at 0 here. Having observed time (as defined in the OBSERVATION_PERIOD table) before the index date ensures that there is sufficient information about the patient to calculate a propensity score, and is also often used to ensure the patient is truly a new user, and therefore was not exposed before.</p>
<p>‘<strong>Remove subjects that are in both the target and comparator cohort?</strong>’ defines, together with the option ‘<strong>If a subject is in multiple cohorts, should time-at-risk be censored when the new time-at-risk starts to prevent overlap?</strong>’ what happens when a subject is in both target and comparator cohort. The first setting has three choices:</p>
<ul>
<li>‘<strong>Keep All</strong>’ indicating to keep the subjects in both cohorts. With this option it might be possible to double-count subjects and outcomes.</li>
<li>‘<strong>Keep First</strong>’ indicating to keep the subject in the first cohort that occurred.</li>
<li>‘<strong>Remove All</strong>’ indicating to remove the subject from both cohorts.</li>
</ul>
<p>If the options ‘Keep all’ or ‘keep first’ are selected, we may wish to censor the time when a person is in both cohorts. This is illustrated in Figure <a href="PopulationLevelEstimation.html#fig:tar">13.10</a>. By default, the time-at-risk is defined relative to the cohort start and end date. In this example, the time-at-risk starts one day after cohort entry, and stops at cohort end In this case, without censoring the time-at-risk for the two cohorts overlap. This is especially problematic if we choose to keep all, because any outcome that occurs during this overlap (as shown) will be counted twice. If we choose to censor, the first cohort’s time-at-risk ends when the second cohort’s time-at-risk starts.</p>
<div class="figure" style="text-align: center"><span id="fig:tar"></span>
<img src="images/PopulationLevelEstimation/tar.png" alt="Time-at-risk (TAR) for subjects who are in both cohorts, assuming time-at-risk starts the day after treatment initiation, and stops at exposure end." width="80%" />
<p class="caption">
Figure 13.10: Time-at-risk (TAR) for subjects who are in both cohorts, assuming time-at-risk starts the day after treatment initiation, and stops at exposure end.
</p>
</div>
<p>We can choose to <strong>remove subjects that have the outcome prior to the risk window start</strong>, because often a second outcome occurrence is the continuation of the first one. For instance, when someone develops heart failure, a second occurrence is more likely, and it is likely that the heart failure never fully resolved in between. On the other hand, some outcomes are episodic, and it would be expected for patients to have more than one independent occurrence, like an upper respiratory infection. If do choose to remove people that had the outcome before, we can select <strong>how many days we should look back when identifying prior outcomes</strong>.</p>
<p>Our choices for our example study are shown in Figure <a href="PopulationLevelEstimation.html#fig:studyPopulation">13.11</a>. Because our target and comparator cohort definitions already restrict to the first exposure and require observation time prior to treatment initiation, we do not apply these criteria here.</p>
<div class="figure" style="text-align: center"><span id="fig:studyPopulation"></span>
<img src="images/PopulationLevelEstimation/studyPopulation.png" alt="Study population settings.." width="100%" />
<p class="caption">
Figure 13.11: Study population settings..
</p>
</div>
<p><strong>Covariate settings</strong></p>
<p>Here we specify the covariates to construct. These covariates are typically used in the propensity model, but can also be included in the outcome model. If we <strong>click to view details</strong> of our covariate settings, we can select which sets of covariates to construct. However, the recommendation is to use the default set, which constructs covariates for demographics, all conditions, drugs, procedures, measurements, etc.</p>
<p>We can modify the set of covariates by specifying concepts to <strong>include</strong> and/or <strong>exclude</strong>. These settings are the same as the ones found in Section <a href="PopulationLevelEstimation.html#ComparisonSettings">13.3.1</a> on comparison settings. The reason why they can be found in two places is because sometimes these settings are related to a specific comparison, as is the case here because we wish to exclude the drugs we are comparing, and sometimes the settings are related to a specific analysis, for example when we wish to use the same covariates used in another study we are trying to replicate. When executing an analysis for a specific comparison using specific analysis settings, the OHDSI tools will take the union of these sets.</p>
<p>The choice to <strong>add descendants to include or exclude</strong> affects this union of the two settings. So in this example we specified only the ingredients to exclude when defining the comparisons. Here we set ‘Should descendant concepts be added to the list of excluded concepts?` to ’Yes’ to also add all descendants.</p>
<p>Figure <a href="PopulationLevelEstimation.html#fig:covariateSettings">13.12</a> shows our choices for this study. Note that we have selected to add descendants to the concept to exclude, which we defined in the comparison settings in Figure <a href="PopulationLevelEstimation.html#fig:comparisons2">13.9</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:covariateSettings"></span>
<img src="images/PopulationLevelEstimation/covariateSettings.png" alt="Covariate settings." width="100%" />
<p class="caption">
Figure 13.12: Covariate settings.
</p>
</div>
<p><strong>Time at risk</strong></p>
<p>Time-at-risk is defined relative to the start and end dates of our target and comparator cohorts. In our example, we had set the cohort start date to start on treatment initiation, and cohort end date when exposure stops (for at least 30 days). We set the start of time-at-risk to 1 day after cohort start, so 1 day after treatment initiation. A reason to set the time-at-risk start to be later than the cohort start is because we may want to exclude outcome events that occur on the day of treatment initiation as we do not believe it biologically plausible they can be caused by the drug.</p>
<p>We set the end of the time-at-risk to the cohort end, so when exposure stops. We could choose to set the end date later if for example we believe events closely following treatment end may still be attributable to the exposure. In the extreme we could set the time-at-risk end to a large number of days (e.g. 99999) after the cohort end date, meaning we will effectively follow up subjects until observation end. Such a design is sometimes referred to as an <em>intent-to-treat</em> design.</p>
<p>A patient with 0 days at risk adds no information, so the <strong>minimum days at risk</strong> is normally set at 1 day. If there is a known latency for the side effect, then this may be increased to get a more informative proportion. It can also be used to create a cohort more similar to that of a randomized trial it is being compared to (e.g., all the patients in the randomized trial were observed for at least N days).</p>

<div class="rmdimportant">
A golden rule in designing a cohort study is to never use information that falls after the cohort start date to define the study population, as this may introduce bias. For example, if we require everyone to have at least a year of time-at-risk, we will likely have limited our analyses to those who tolerate the treatment well. This setting should therefore be used with extreme care.
</div>

<div class="figure" style="text-align: center"><span id="fig:timeAtRisk"></span>
<img src="images/PopulationLevelEstimation/timeAtRisk.png" alt="Time-at-risk settings." width="100%" />
<p class="caption">
Figure 13.13: Time-at-risk settings.
</p>
</div>
<p><strong>Propensity score adjustment</strong></p>
<p>We can opt to <strong>trim</strong> the study population, removing people with extreme PS values. We can choose to remove the top and bottom percentage, or we can remove subjects whose preference score <span class="citation">(Walker et al. <a href="#ref-walker_2013">2013</a>)</span> falls outside the range we prespecify. Trimming the cohorts is generally not recommended because it requires discarding observations, which reduces statistical power. It may be desirable to trim in some cases, for example when using IPTW.</p>
<p>In addition to, or instead of trimming, we can choose to <strong>stratify</strong> or <strong>match</strong> on the propensity score. When stratifying we need to specify the <strong>number of strata</strong> and whether to select the strata based on the target, comparator, or entire study population. When matching we need to specify the <strong>maximum number of people from the comparator group to match to each person in the target group</strong>. Typical values are 1 for one-on-one matching, or a large number (e.g. 100) for variable ratio matching. We also need to specify the <strong>caliper</strong>: the maximum allowed difference between propensity scores to allow a match. The caliper can be defined on difference <strong>caliper scales</strong>:</p>
<ul>
<li><strong>The propensity score scale</strong>: the PS itself</li>
<li><strong>The standardized scale</strong>: in standard deviations of the PS distributions</li>
<li><strong>The standardized logit scale</strong>: in standard deviations of the PS distributions after the logit transformation to make the PS more normally distributed.</li>
</ul>
<p>In case of doubt, we suggest using the default values.</p>
<p>Fitting large-scale propensity models can be computationally expensive, so we may want to restrict the data used to fit the model to just a sample of the data. By default the maximum size of the target and comparator cohort is set to 250,000. In most studies this limit will not be reached. It is also unlikely that more data will lead to a better model. Note that although a sample of the data may be used to fit the model, the model will be used to compute PS for the entire population.</p>
<p><strong>Test each covariate for correlation with the target assignment?</strong> If any covariate has an unusually high correlation (either positive or negative), this will throw an error. This avoids lengthy calculation of a propensity model only to discover complete separation. Finding very high univariate correlation allows you to review the covariate to determine why it has high correlation and whether it should be dropped.</p>
<p>Figure <a href="PopulationLevelEstimation.html#fig:psSettings">13.14</a> shows our choices for this study. Note that we select variable ratio matching by setting the maximum number of people to match to 100.</p>
<div class="figure" style="text-align: center"><span id="fig:psSettings"></span>
<img src="images/PopulationLevelEstimation/psSettings.png" alt="Propenstity score adjustment settings." width="100%" />
<p class="caption">
Figure 13.14: Propenstity score adjustment settings.
</p>
</div>
<p><strong>Outcome model settings</strong></p>
<p>First, we need to <strong>specify the statistical model we will use to estimate the risk of outcome between target and comparator cohorts</strong>. We can choose between Cox, Poisson, and logistic regression, as discussed briefly in Section <a href="PopulationLevelEstimation.html#CohortMethod">13.1.1</a>. For our example we choose a Cox proportional hazards model, which considers time to first event with possible censoring. Next, we need to specify <strong>whether the reggression should be condition on the strata</strong>. One way to understand conditioning is to imagine a separate estimate is produced in each strata, and then combined across strata. For one-to-one matching this is likely unnecessary and would just lose power. For stratification or variable ratio matching it is required.</p>
<p>We can also choose to <strong>add all covariates to the outcome model</strong> to adjust the analysis. This can be done in addition or instead of using a propensity model. However, whereas there usually is ample data to fit a propensity model, with many people in both treatment groups, there is typically very little data to fit the outcome model, with only few people having the outcome. We therefore recommend to keep the outcome model as simple as possible and not include additional covariates.</p>
<p>Instead of stratifying or matching on the propensity score we can also choose to <strong>use inverse probability of treatment weighting</strong> (IPTW). If weighting is used it is often recommended to use some for of trimming to avoid extreme weights and therefore unstable estimates.</p>
<p>Figure <a href="PopulationLevelEstimation.html#fig:psSettings">13.14</a> shows our choices for this study. Because we use variable ratio matching, we must condition the regression on the strata (ie. the matched sets).</p>
<div class="figure" style="text-align: center"><span id="fig:outcomeModelSettings"></span>
<img src="images/PopulationLevelEstimation/outcomeModelSettings.png" alt="Outcome model settings." width="100%" />
<p class="caption">
Figure 13.15: Outcome model settings.
</p>
</div>
</div>
<div id="evaluationSettings" class="section level3">
<h3><span class="header-section-number">13.3.3</span> Evaluation settings</h3>
<p>As described in Chapter <a href="MethodValidity.html#MethodValidity">19</a>, negative and positive controls should be included in our study to evaluate the operating characteristics, and perform empirical calibration.</p>
<p><strong>Negative control outcome cohort definition</strong></p>
<p>In Section <a href="PopulationLevelEstimation.html#ComparisonSettings">13.3.1</a> we selected a concept set representing the negative control outcomes. However, we need logic to convert concepts to cohorts to be used as outcomes in our analysis. ATLAS provides standard logic with three choices The first choice is whether to <strong>use all occurrences</strong> or just the <strong>first occurrence</strong> of the concept. The second choice determines <strong>whether occurrences of descendant concepts should be considered</strong>. For example, occurrences of the descendant “ingrown nail of foot” can also be counted as an occurrence of the ancestor “ingrown nail”. The third choice specifies which domains should be considered when looking for the concepts.</p>
<div class="figure" style="text-align: center"><span id="fig:ncSettings"></span>
<img src="images/PopulationLevelEstimation/ncSettings.png" alt="Negative control outcome cohort definition settings." width="100%" />
<p class="caption">
Figure 13.16: Negative control outcome cohort definition settings.
</p>
</div>
<p><strong>Positive control synthesis</strong></p>
<p>In addition to negative controls we can also include positive controls, which are exposure-outcome pairs where a causal effect is believed to exist with known effect size. For various reasons real positive controls are problematic, so instead we rely on synthetic positive controls, derived from negative controls as described in Chapter <a href="MethodValidity.html#MethodValidity">19</a>. Positive control synthesis is an advanced topic that we will skip for now.</p>
</div>
<div id="running-the-study-package" class="section level3">
<h3><span class="header-section-number">13.3.4</span> Running the study package</h3>
<p>Now that we have fully defined our study, we can export it as a fully executable R package. This package contains everything that is needed to execute the study at a site that has data in the CDM. This includes the cohort definitions that can be used to instantiate the target, comparator and outcome cohorts, the negative control concept set and logic to create the negative control outcome cohorts, as well as the R code to execute the analysis. Before generating the package make sure to save your study, then click on the <strong>Utilities</strong> tab. Here we can review the set of analyses that will be performed. As mentioned before, every combination of a comparison and an analysis setting will results in a separate analysis. In our example we have specified two analyses: ACEi versus THZ for AMI, and ACEi versus THZ for angioedema, both using propensity score matching.</p>
<p>We must provide a name for our package, after which we can click on ‘Download’ to download the zip file. The zip file contains an R Studio project with a README file that describes the steps needed to execute the analysis.</p>
</div>
</div>
<div id="implementation-the-study-using-r" class="section level2">
<h2><span class="header-section-number">13.4</span> Implementation the study using R</h2>
<p>Instead of using ATLAS to write the R code that executes the study, we can also write the R code ourselves. One reason we might want to do this is because R offers far greater flexibility than is exposed in ATLAS. If we for example wish to use custom covariates, or a linear outcome model, we will need to write some custom R code, and combine it with the functionality provided by the OHDSI R packages.</p>
<p>For our example study we will rely on the <a href="https://ohdsi.github.io/CohortMethod/">CohortMethod</a> package to execute our study. CohortMethod extracts the necessary data from a database in the CDM and can use a large set of covariates for the propensity model. In the following example we will only consider angioedema as outcome, and leave implementation for AMI and the negative controls as an exercise for the reader.</p>
<div id="cohort-instantiation" class="section level3">
<h3><span class="header-section-number">13.4.1</span> Cohort instantiation</h3>
<p>We first need to instantiate the target and outcome cohorts. Instantiating cohorts is described in Chapter <a href="Cohorts.html#Cohorts">11</a>. The Appendix provides the full definitions of the target (Appendix <a href="CohortDefinitions.html#AceInhibitorsMono">B.2</a>), comparator (Appendix <a href="CohortDefinitions.html#ThiazidesMono">B.5</a>), and outcome (Appendix <a href="CohortDefinitions.html#Angioedema">B.4</a> ) cohorts. We will the ACEi, THZ, and angioedema cohorts have been instantiated in a table called <code>scratch.my_cohorts</code> with cohort definition IDs 1,2, and 3 respectively.</p>
</div>
<div id="data-extraction" class="section level3">
<h3><span class="header-section-number">13.4.2</span> Data extraction</h3>
<p>We first need to tell R how to connect to the server. <a href="https://ohdsi.github.io/CohortMethod/">CohortMethod</a> uses the <a href="https://ohdsi.github.io/DatabaseConnector/"><code>DatabaseConnector</code></a> package, which provides a function called <code>createConnectionDetails</code>. Type <code>?createConnectionDetails</code> for the specific settings required for the various database management systems (DBMS). For example, one might connect to a PostgreSQL database using this code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(CohortMethod)
connDetails &lt;-<span class="st"> </span><span class="kw">createConnectionDetails</span>(<span class="dt">dbms =</span> <span class="st">&quot;postgresql&quot;</span>,
                                       <span class="dt">server =</span> <span class="st">&quot;localhost/ohdsi&quot;</span>,
                                       <span class="dt">user =</span> <span class="st">&quot;joe&quot;</span>,
                                       <span class="dt">password =</span> <span class="st">&quot;supersecret&quot;</span>)

cdmDbSchema &lt;-<span class="st"> &quot;my_cdm_data&quot;</span>
cohortsDbSchema &lt;-<span class="st"> &quot;scratch&quot;</span>
cohortsDbTable &lt;-<span class="st"> &quot;my_cohorts&quot;</span>
cdmVersion &lt;-<span class="st"> &quot;5&quot;</span></code></pre></div>
<p>The last four lines define the <code>cdmDbSchema</code>, <code>cohortsDbSchema</code>, and <code>cohortsDbTable</code> variables, as well as the CDM version. We will use these later to tell R where the data in CDM format live, where the cohorts of interest have been created, and what version CDM is used. Note that for Microsoft SQL Server, database schemas need to specify both the database and the schema, so for example <code>cdmDbSchema &lt;- &quot;my_cdm_data.dbo&quot;</code>.</p>
<p>Now we can tell CohortMethod to extract the cohorts, construct covariates, and extract all necessary data for our analysis:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># target and comparator ingredient concepts:</span>
aceI &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1335471</span>,<span class="dv">1340128</span>,<span class="dv">1341927</span>,<span class="dv">1363749</span>,<span class="dv">1308216</span>,<span class="dv">1310756</span>,<span class="dv">1373225</span>,
          <span class="dv">1331235</span>,<span class="dv">1334456</span>,<span class="dv">1342439</span>)
thz &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1395058</span>,<span class="dv">974166</span>,<span class="dv">978555</span>,<span class="dv">907013</span>)

<span class="co"># Define which types of covariates must be constructed:</span>
cs &lt;-<span class="st"> </span><span class="kw">createDefaultCovariateSettings</span>(<span class="dt">excludedCovariateConceptIds =</span> <span class="kw">c</span>(aceI, 
                                                                     thz),
                                     <span class="dt">addDescendantsToExclude =</span> <span class="ot">TRUE</span>)

<span class="co">#Load data:</span>
cmData &lt;-<span class="st"> </span><span class="kw">getDbCohortMethodData</span>(<span class="dt">connectionDetails =</span> connectionDetails,
                                <span class="dt">cdmDatabaseSchema =</span> cdmDatabaseSchema,
                                <span class="dt">oracleTempSchema =</span> <span class="ot">NULL</span>,
                                <span class="dt">targetId =</span> <span class="dv">1</span>,
                                <span class="dt">comparatorId =</span> <span class="dv">2</span>,
                                <span class="dt">outcomeIds =</span> <span class="dv">3</span>,
                                <span class="dt">studyStartDate =</span> <span class="st">&quot;&quot;</span>,
                                <span class="dt">studyEndDate =</span> <span class="st">&quot;&quot;</span>,
                                <span class="dt">exposureDatabaseSchema =</span> cohortsDbSchema,
                                <span class="dt">exposureTable =</span> cohortsDbTable,
                                <span class="dt">outcomeDatabaseSchema =</span> cohortsDbSchema,
                                <span class="dt">outcomeTable =</span> cohortsDbTable,
                                <span class="dt">cdmVersion =</span> cdmVersion,
                                <span class="dt">firstExposureOnly =</span> <span class="ot">FALSE</span>,
                                <span class="dt">removeDuplicateSubjects =</span> <span class="ot">FALSE</span>,
                                <span class="dt">restrictToCommonPeriod =</span> <span class="ot">FALSE</span>,
                                <span class="dt">washoutPeriod =</span> <span class="dv">0</span>,
                                <span class="dt">covariateSettings =</span> cs)
cmData</code></pre></div>
<pre><code>## CohortMethodData object
## 
## Treatment concept ID: 1
## Comparator concept ID: 2
## Outcome concept ID(s): 3</code></pre>
<p>There are many parameters, but they are all documented in the CohortMethod manual. The <code>createDefaultCovariateSettings</code> function is described in the <code>FeatureExtraction</code> package. In short, we are pointing the function to the table containing our cohorts and specify which cohort definition IDs in that table identify the target, comparator and outcome. We instruct that the default set of covariates should be constructed, including covariates for all conditions, drug exposures, and procedures that were found on or before the index date. As mentioned in Section <a href="PopulationLevelEstimation.html#CohortMethod">13.1.1</a> we must exclude the target and comparator treatments from the set of covariates, and here we achieve this by listing all ingredients in the two classes, and tell FeatureExtraction to also exclude all descendants, thus excluding all drugs that contain these ingredients.</p>
<p>All data about the cohorts, outcomes, and covariates are extracted from the server and stored in the <code>cohortMethodData</code> object. This object uses the package <code>ff</code> to store information in a way that ensures R does not run out of memory, even when the data are large.</p>
<p>We can use the generic <code>summary()</code> function to view some more information of the data we extracted:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(cmData)</code></pre></div>
<pre><code>## CohortMethodData object summary
## 
## Treatment concept ID: 1
## Comparator concept ID: 2
## Outcome concept ID(s): 3
## 
## Treated persons: 67166
## Comparator persons: 35333
## 
## Outcome counts:
##          Event count Person count
## 3               980          891
## 
## Covariates:
## Number of covariates: 58349
## Number of non-zero covariate values: 24484665</code></pre>
<p>Creating the <code>cohortMethodData</code> file can take considerable computing time, and it is probably a good idea to save it for future sessions. Because <code>cohortMethodData</code> uses <code>ff</code>, we cannot use R’s regular save function. Instead, we’ll have to use the <code>saveCohortMethodData()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">saveCohortMethodData</span>(cmData, <span class="st">&quot;AceiVsThzForAngioedema&quot;</span>)</code></pre></div>
<p>We can use the <code>loadCohortMethodData()</code> function to load the data in a future session.</p>
<p><strong>Defining new users</strong></p>
<p>Typically, a new user is defined as first time use of a drug (either target or comparator), and typically a washout period (a minimum number of days prior first use) is used to make sure it is truly first use. When using the CohortMethod package, you can enforce the necessary requirements for new use in three ways:</p>
<ol style="list-style-type: decimal">
<li>When defining the cohorts.</li>
<li>When loading the cohorts using the <code>getDbCohortMethodData</code> function, you can use the <code>firstExposureOnly</code>, <code>removeDuplicateSubjects</code>, <code>restrictToCommonPeriod</code>, and <code>washoutPeriod</code> arguments.</li>
<li>When defining the study population using the <code>createStudyPopulation</code> function (see below) using the <code>firstExposureOnly</code>, <code>removeDuplicateSubjects</code>, <code>restrictToCommonPeriod</code>, and <code>washoutPeriod</code> arguments.</li>
</ol>
<p>The advantage of option 1 is that the input cohorts are already fully defined outside of the CohortMethod package, and for example external cohort characterization tools can be used on the same cohorts used in this analysis. The advantage of options 2 and 3 is that they save you the trouble of limiting to first use yourself, for example allowing you to directly use the <code>drug_era</code> table in the CDM. Option 2 is more efficient than 3, since only data for first use will be fetched, while option 3 is less efficient but allows you to compare the original cohorts to the study population.</p>
</div>
<div id="defining-the-study-population" class="section level3">
<h3><span class="header-section-number">13.4.3</span> Defining the study population</h3>
<p>Typically, the exposure cohorts and outcome cohorts will be defined independently of each other. When we want to produce an effect size estimate, we need to further restrict these cohorts and put them together, for example by removing exposed subjects that had the outcome prior to exposure, and only keeping outcomes that fall within a defined risk window. For this we can use the <code>createStudyPopulation</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">studyPop &lt;-<span class="st"> </span><span class="kw">createStudyPopulation</span>(<span class="dt">cohortMethodData =</span> cmData,
                                  <span class="dt">outcomeId =</span> <span class="dv">3</span>,
                                  <span class="dt">firstExposureOnly =</span> <span class="ot">FALSE</span>,
                                  <span class="dt">restrictToCommonPeriod =</span> <span class="ot">FALSE</span>,
                                  <span class="dt">washoutPeriod =</span> <span class="dv">0</span>,
                                  <span class="dt">removeDuplicateSubjects =</span> <span class="st">&quot;remove all&quot;</span>,
                                  <span class="dt">removeSubjectsWithPriorOutcome =</span> <span class="ot">TRUE</span>,
                                  <span class="dt">minDaysAtRisk =</span> <span class="dv">1</span>,
                                  <span class="dt">riskWindowStart =</span> <span class="dv">1</span>,
                                  <span class="dt">addExposureDaysToStart =</span> <span class="ot">FALSE</span>,
                                  <span class="dt">riskWindowEnd =</span> <span class="dv">0</span>,
                                  <span class="dt">addExposureDaysToEnd =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>Note that we’ve set <code>firstExposureOnly</code> and <code>removeDuplicateSubjects</code> to FALSE, and <code>washoutPeriod</code> to 0 because we already applied those criteria in the cohort definitions. We specify the outcome ID we will use, and that people with outcomes prior to the risk window start date will be removed. The risk window is defined as starting on the day after the cohort start date (<code>riskWindowStart = 1</code> and <code>addExposureDaysToStart = FALSE</code>), and the risk windows ends when the cohort exposure ends (<code>riskWindowEnd = 30</code> and <code>addExposureDaysToEnd = TRUE</code>), which was defined as the end of exposure in the cohort definition. Note that the risk windows are automatically truncated at the end of observation or the study end date. We also remove subjects who have no time at risk. To see how many people are left in the study population we can always use the <code>getAttritionTable</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">getAttritionTable</span>(studyPop)</code></pre></div>
<pre><code>##                    description targetPersons comparatorPersons           ...
## 1             Original cohorts         67212             35379           ...
## 2 Removed subs in both cohorts         67166             35333           ...
## 3             No prior outcome         67061             35238           ...
## 4 Have at least 1 days at risk         66780             35086           ...</code></pre>
</div>
<div id="propensity-scores" class="section level3">
<h3><span class="header-section-number">13.4.4</span> Propensity scores</h3>
<p>We can fit a propensity model using the covariates constructed by the <code>getDbcohortMethodData()</code> function, and compute a PS for each person:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ps &lt;-<span class="st"> </span><span class="kw">createPs</span>(<span class="dt">cohortMethodData =</span> cmData, <span class="dt">population =</span> studyPop)</code></pre></div>
<p>The <code>createPs</code> function uses the <a href="https://ohdsi.github.io/Cyclops/">Cyclops</a> package to fit a large-scale regularized logistic regression. To fit the propensity model, Cyclops needs to know the hyperparameter value which specifies the variance of the prior. By default Cyclops will use cross-validation to estimate the optimal hyperparameter. However, be aware that this can take a really long time. You can use the <code>prior</code> and <code>control</code> parameters of the <code>createPs</code> to specify Cyclops’ behavior, including using multiple CPUs to speed-up the cross-validation.</p>
<p>Here we use the PS to perform variable ratio matching:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">matchedPop &lt;-<span class="st"> </span><span class="kw">matchOnPs</span>(<span class="dt">population =</span> ps, <span class="dt">caliper =</span> <span class="fl">0.2</span>, 
                        <span class="dt">caliperScale =</span> <span class="st">&quot;standardized logit&quot;</span>, <span class="dt">maxRatio =</span> <span class="dv">100</span>)</code></pre></div>
<p>Alternatively, we could have used the PS in the <code>trimByPs</code>, <code>trimByPsToEquipoise</code>, or <code>stratifyByPs</code> functions.</p>
</div>
<div id="outcome-models" class="section level3">
<h3><span class="header-section-number">13.4.5</span> Outcome models</h3>
<p>The outcome model is a model describing which variables are associated with the outcome. Under strict assumptions, the coefficient for the treatment variable can be interpreted as the causal effect. In this case we fit a Cox proportional hazards model, conditioned on the matched sets:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">outcomeModel &lt;-<span class="st"> </span><span class="kw">fitOutcomeModel</span>(<span class="dt">population =</span> matchedPop,
                                <span class="dt">modelType =</span> <span class="st">&quot;cox&quot;</span>,
                                <span class="dt">stratified =</span> <span class="ot">TRUE</span>)
outcomeModel</code></pre></div>
<pre><code>## Model type: cox
## Stratified: TRUE
## Use covariates: FALSE
## Use inverse probability of treatment weighting: FALSE
## Status: OK
## 
##           Estimate lower .95 upper .95   logRr seLogRr
## treatment   4.3203    2.4531    8.0771 1.4633   0.304</code></pre>
</div>
<div id="running-multiple-analyses" class="section level3">
<h3><span class="header-section-number">13.4.6</span> Running multiple analyses</h3>
<p>Here we describe performing the analysis for one target, comparator and outcome, using one set of analysis settings. However, often we want to perform more analyses, for example for multiple outcomes including negative controls. The <a href="https://ohdsi.github.io/CohortMethod/">CohortMethod</a> offers functions for performing such studies efficiently. This is described in the package vignette on running multiple analyses.</p>
</div>
</div>
<div id="studyOutputs" class="section level2">
<h2><span class="header-section-number">13.5</span> Study outputs</h2>
<p>Our estimate is only valid if several assumptions have been met. We use a wide set of diagnostics to evaluate whether this is the case. These are available in the results produced by the R package generated by ATLAS, or can be generated on the fly by specific R functions.</p>
<div id="propensity-score-and-model" class="section level3">
<h3><span class="header-section-number">13.5.1</span> Propensity score and model</h3>
<p>We first need to evaluate whether the target and comparator cohort are to some extend comparable. For this we can compute the Area Under the Receiver Operator Curve (AUC) statistic for the propensity model. An AUC of 1 indicates the treatment assignment was completely predictable based on baseline covariates, and that the two groups are therefore incomparable. We can use the <code>computePsAuc</code> function to compute the AUC, which in our example is 0.79. Using the <code>plotPs</code> function, we can also generate the preference score distribution as shown in Figure <a href="PopulationLevelEstimation.html#fig:ps">13.17</a>. Here we see that for many people the treatment they received was predictable, but there is also a large amount of overlap, indicating that adjustment can be used to make the groups comparable.</p>
<div class="figure" style="text-align: center"><span id="fig:ps"></span>
<img src="images/PopulationLevelEstimation/ps.png" alt="Preference score distribution." width="80%" />
<p class="caption">
Figure 13.17: Preference score distribution.
</p>
</div>
<p>In general it is a good idea to also inspect the propensity model itself, and especially so if the model is very predictive. That way we may discover which variables are most predictive. Table <a href="PopulationLevelEstimation.html#tab:psModel">13.7</a> shows the top predictors in our propensity model. Note that if a variable is too predictive, the CohortMethod package will throw an informative error rather than attempt to fit a model that is already known to be perfectly predictive.</p>
<table>
<caption><span id="tab:psModel">Table 13.7: </span> Top 10 predictors in the propensity model for ACEi and THZ. Positive values mean subjects with the covariate are more likely to receive the target treatment.</caption>
<colgroup>
<col width="7%" />
<col width="92%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">Beta</th>
<th align="left">Covariate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">-1.42</td>
<td align="left">condition_era group during day -30 through 0 days relative to index: Edema</td>
</tr>
<tr class="even">
<td align="right">-1.11</td>
<td align="left">drug_era group during day 0 through 0 days relative to index: Potassium Chloride</td>
</tr>
<tr class="odd">
<td align="right">0.68</td>
<td align="left">age group: 05-09</td>
</tr>
<tr class="even">
<td align="right">0.64</td>
<td align="left">measurement during day -365 through 0 days relative to index: Renin</td>
</tr>
<tr class="odd">
<td align="right">0.63</td>
<td align="left">condition_era group during day -30 through 0 days relative to index: Urticaria</td>
</tr>
<tr class="even">
<td align="right">0.57</td>
<td align="left">condition_era group during day -30 through 0 days relative to index: Proteinuria</td>
</tr>
<tr class="odd">
<td align="right">0.55</td>
<td align="left">drug_era group during day -365 through 0 days relative to index: INSULINS AND ANALOGUES</td>
</tr>
<tr class="even">
<td align="right">-0.54</td>
<td align="left">race = Black or African American</td>
</tr>
<tr class="odd">
<td align="right">0.52</td>
<td align="left">(Intercept)</td>
</tr>
<tr class="even">
<td align="right">0.50</td>
<td align="left">gender = MALE</td>
</tr>
</tbody>
</table>

<div class="rmdimportant">
If a variable is found to be highly predictive, there are two possible conclusions: Either we find that the variable is clearly part of the exposure and should be removed from the model, or else we must conclude that the two populations are truly incomparible, and the analysis must be stopped.
</div>

</div>
<div id="covariate-balance" class="section level3">
<h3><span class="header-section-number">13.5.2</span> Covariate balance</h3>
<p>The goal of using PS is to make the two groups comparable. We must verify whether this is achieved, for example by checked whether the baseline covariates are indeed balanced after adjustment. We can use the <code>computeCovariateBalance</code> and <code>plotCovariateBalanceScatterPlot</code> functions to generate Figure<a href="PopulationLevelEstimation.html#fig:balance">13.18</a>. One rule-of-thumb to use is that no covariate may have an absolute standardized difference of means greater than 0.1 after propensity score adjustment. Here we see that although there was substantial imbalance before matching, after matching we meet this criterion.</p>
<div class="figure" style="text-align: center"><span id="fig:balance"></span>
<img src="images/PopulationLevelEstimation/balance.png" alt="Covariate balance, showing the absolute standardized difference of mean before and after propensity score matching. Each blue dot represents a covariate." width="70%" />
<p class="caption">
Figure 13.18: Covariate balance, showing the absolute standardized difference of mean before and after propensity score matching. Each blue dot represents a covariate.
</p>
</div>
</div>
<div id="follow-up-and-power" class="section level3">
<h3><span class="header-section-number">13.5.3</span> Follow up and power</h3>
<p>Before fitting an outcome model, we might be interested to know whether we have sufficient power to detect a particular effect size. It makes sense to perform these power calculations once the study population has been fully defined, so taking into account loss to the various inclusion and exclusion criteria (such as no prior outcomes), and loss due to matching and/or trimming. We can view the attrition of subjects in our study using the <code>drawAttritionDiagram</code> function as shown in Figure<a href="PopulationLevelEstimation.html#fig:attrition">13.19</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:attrition"></span>
<img src="images/PopulationLevelEstimation/attrition.png" alt="Attrition diagram. The counts shown at the top are those that meet our target and comparator cohort definitions. The counts at the bottom are those that enter our outcome model, in  this case a Cox regression." width="70%" />
<p class="caption">
Figure 13.19: Attrition diagram. The counts shown at the top are those that meet our target and comparator cohort definitions. The counts at the bottom are those that enter our outcome model, in this case a Cox regression.
</p>
</div>
<p>Since the sample size is fixed in retrospective studies (the data has already been collected), and the true effect size is unknown, the CohortMethod package provides the <code>computeMdrr</code> function to compute the minimum detectable relative risk (MDRR) instead. In our example study the MDRR is 1.69.</p>
<p>To gain a better understanding of the amount of follow-up available we can also inspect the distribution of follow-up time. We defined follow-up time as time at risk, so not censored by the occurrence of the outcome. The <code>getFollowUpDistribution</code> can provide a simple overview as shown in Figure <a href="PopulationLevelEstimation.html#fig:followUp">13.20</a>, which suggests the follow-up time for both cohorts is comparable.</p>
<div class="figure" style="text-align: center"><span id="fig:followUp"></span>
<img src="images/PopulationLevelEstimation/followUp.png" alt="Distribution of follow-up time for the target and comparator cohorts." width="80%" />
<p class="caption">
Figure 13.20: Distribution of follow-up time for the target and comparator cohorts.
</p>
</div>
</div>
<div id="kaplan-meier" class="section level3">
<h3><span class="header-section-number">13.5.4</span> Kaplan Meier</h3>
<p>One last check is to review the Kaplan Meier plot, showing the survival over time in both cohorts. Using the <code>plotKaplanMeier</code> function we can create <a href="PopulationLevelEstimation.html#fig:kmPlot">13.21</a>, which we can check for example if our assumption of proportionality of hazards holds.</p>
<div class="figure" style="text-align: center"><span id="fig:kmPlot"></span>
<img src="images/PopulationLevelEstimation/kmPlot.png" alt="Kaplan Meier plot." width="100%" />
<p class="caption">
Figure 13.21: Kaplan Meier plot.
</p>
</div>
</div>
<div id="effect-size-estimate" class="section level3">
<h3><span class="header-section-number">13.5.5</span> Effect size estimate</h3>
<p>We observe a hazard ratio of 4.32 (95% confidence interval: 2.45 - 8.08), which tells us that ACEi appear to increase the risk of angioedema compared to THZ. Our diagnostics, as reviewed earlier, do not show any major concerns, but ultimately the quality of this evidence, and whether we choose to trust it, depends on many factors, as described in Chapter <a href="EvidenceQuality.html#EvidenceQuality">15</a>.</p>
</div>
</div>
<div id="excercises" class="section level2">
<h2><span class="header-section-number">13.6</span> Excercises</h2>
<p>Note: The excercises still have to be defined. The idea is to require readers to define a study that estimates the effect of celecoxib on GI bleed, compared to diclofenac. For this they must use the Eunomia package, which is still under development.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-austin_2011">
<p>Austin, Peter C. 2011. “Optimal Caliper Widths for Propensity-Score Matching When Estimating Differences in Means and Differences in Proportions in Observational Studies.” <em>Pharmaceutical Statistics</em> 10 (2). Wiley Online Library: 150–61.</p>
</div>
<div id="ref-farrington_1995">
<p>Farrington, C. P. 1995. “Relative incidence estimation from case series for vaccine safety evaluation.” <em>Biometrics</em> 51 (1): 228–35.</p>
</div>
<div id="ref-farrington_2011">
<p>Farrington, C. P., Karim Anaya-Izquierdo, Heather J. Whitaker, Mounia N. Hocine, Ian Douglas, and Liam Smeeth. 2011. “Self-Controlled Case Series Analysis with Event-Dependent Observation Periods.” <em>Journal of the American Statistical Association</em> 106 (494). Taylor &amp; Francis: 417–26. doi:<a href="https://doi.org/10.1198/jasa.2011.ap10108">10.1198/jasa.2011.ap10108</a>.</p>
</div>
<div id="ref-hernan_2016">
<p>Hernan, M. A., and J. M. Robins. 2016. “Using Big Data to Emulate a Target Trial When a Randomized Trial Is Not Available.” <em>Am. J. Epidemiol.</em> 183 (8): 758–64.</p>
</div>
<div id="ref-maclure_1991">
<p>Maclure, M. 1991. “The case-crossover design: a method for studying transient effects on the risk of acute events.” <em>Am. J. Epidemiol.</em> 133 (2): 144–53.</p>
</div>
<div id="ref-magid_2010">
<p>Magid, D. J., S. M. Shetterly, K. L. Margolis, H. M. Tavel, P. J. O’Connor, J. V. Selby, and P. M. Ho. 2010. “Comparative effectiveness of angiotensin-converting enzyme inhibitors versus beta-blockers as second-line therapy for hypertension.” <em>Circ Cardiovasc Qual Outcomes</em> 3 (5): 453–58.</p>
</div>
<div id="ref-powers_2012">
<p>Powers, B. J., R. R. Coeytaux, R. J. Dolor, V. Hasselblad, U. D. Patel, W. S. Yancy, R. N. Gray, R. J. Irvine, A. S. Kendrick, and G. D. Sanders. 2012. “Updated report on comparative effectiveness of ACE inhibitors, ARBs, and direct renin inhibitors for patients with essential hypertension: much more data, little new information.” <em>J Gen Intern Med</em> 27 (6): 716–29.</p>
</div>
<div id="ref-rassen_2012">
<p>Rassen, J. A., A. A. Shelat, J. Myers, R. J. Glynn, K. J. Rothman, and S. Schneeweiss. 2012. “One-to-many propensity score matching in cohort studies.” <em>Pharmacoepidemiol Drug Saf</em> 21 Suppl 2 (May): 69–80.</p>
</div>
<div id="ref-rosenbaum_1983">
<p>Rosenbaum, P., and D. Rubin. 1983. “The Central Role of the Propensity Score in Observational Studies for Causal Effects.” <em>Biometrika</em> 70 (April): 41–55. doi:<a href="https://doi.org/10.1093/biomet/70.1.41">10.1093/biomet/70.1.41</a>.</p>
</div>
<div id="ref-rubin_2001">
<p>Rubin, Donald B. 2001. “Using Propensity Scores to Help Design Observational Studies: Application to the Tobacco Litigation.” <em>Health Services and Outcomes Research Methodology</em> 2 (3-4). Springer: 169–88.</p>
</div>
<div id="ref-ryan_2013">
<p>Ryan, P. B., M. J. Schuemie, and D. Madigan. 2013. “Empirical performance of a self-controlled cohort method: lessons for developing a risk identification and analysis system.” <em>Drug Saf</em> 36 Suppl 1 (October): 95–106.</p>
</div>
<div id="ref-sabroe_1997">
<p>Sabroe, R. A., and A. K. Black. 1997. “Angiotensin-converting enzyme (ACE) inhibitors and angio-oedema.” <em>Br. J. Dermatol.</em> 136 (2): 153–58.</p>
</div>
<div id="ref-simpson_2013">
<p>Simpson, S. E., D. Madigan, I. Zorych, M. J. Schuemie, P. B. Ryan, and M. A. Suchard. 2013. “Multiple self-controlled case series for large-scale longitudinal observational databases.” <em>Biometrics</em> 69 (4): 893–902.</p>
</div>
<div id="ref-suchard_2013">
<p>Suchard, M. A., S. E. Simpson, Ivan Zorych, P. B. Ryan, and David Madigan. 2013. “Massive Parallelization of Serial Inference Algorithms for a Complex Generalized Linear Model.” <em>ACM Trans. Model. Comput. Simul.</em> 23 (1). New York, NY, USA: ACM: 10:1–10:17. doi:<a href="https://doi.org/10.1145/2414416.2414791">10.1145/2414416.2414791</a>.</p>
</div>
<div id="ref-suissa_1995">
<p>Suissa, S. 1995. “The case-time-control design.” <em>Epidemiology</em> 6 (3): 248–53.</p>
</div>
<div id="ref-tian_2018">
<p>Tian, Y., M. J. Schuemie, and M. A. Suchard. 2018. “Evaluating large-scale propensity score performance through real-world and synthetic data experiments.” <em>Int J Epidemiol</em> 47 (6): 2005–14.</p>
</div>
<div id="ref-toh_2012">
<p>Toh, S., M. E. Reichman, M. Houstoun, M. Ross Southworth, X. Ding, A. F. Hernandez, M. Levenson, et al. 2012. “Comparative risk for angioedema associated with the use of drugs that target the renin-angiotensin-aldosterone system.” <em>Arch. Intern. Med.</em> 172 (20): 1582–9.</p>
</div>
<div id="ref-vandenbroucke_2012">
<p>Vandenbroucke, J. P., and N. Pearce. 2012. “Case-control studies: basic concepts.” <em>Int J Epidemiol</em> 41 (5): 1480–9.</p>
</div>
<div id="ref-walker_2013">
<p>Walker, Alexander M, Amanda R Patrick, Michael S Lauer, Mark C Hornbrook, Matthew G Marin, Richard Platt, Véronique L Roger, Paul Stang, and Sebastian Schneeweiss. 2013. “A Tool for Assessing the Feasibility of Comparative Effectiveness Research.” <em>Comp Eff Res</em> 3: 11–20.</p>
</div>
<div id="ref-whelton_2018">
<p>Whelton, P. K., R. M. Carey, W. S. Aronow, D. E. Casey, K. J. Collins, C. Dennison Himmelfarb, S. M. DePalma, et al. 2018. “2017 ACC/AHA/AAPA/ABC/ACPM/AGS/APhA/ASH/ASPC/NMA/PCNA Guideline for the Prevention, Detection, Evaluation, and Management of High Blood Pressure in Adults: Executive Summary: A Report of the American College of Cardiology/American Heart Association Task Force on Clinical Practice Guidelines.” <em>Circulation</em> 138 (17): e426–e483.</p>
</div>
<div id="ref-zaman_2002">
<p>Zaman, M. A., S. Oparil, and D. A. Calhoun. 2002. “Drugs targeting the renin-angiotensin-aldosterone system.” <em>Nat Rev Drug Discov</em> 1 (8): 621–36.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Characterization.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="PatientLevelPrediction.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/OHDSI/TheBookOfOhdsi/edit/master/PopulationLevelEstimation.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["TheBookOfOhdsi.pdf", "TheBookOfOhdsi.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
