<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 14 Patient Level Prediction | The Book of OHDSI</title>
  <meta name="description" content="A book about the Observational Health Data Science and Informatics (OHDS). It described the OHDSI community, open standards and open source software." />
  <meta name="generator" content="bookdown 0.12.1 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 14 Patient Level Prediction | The Book of OHDSI" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://ohdsi.github.io/TheBookOfOhdsi/" />
  <meta property="og:image" content="https://ohdsi.github.io/TheBookOfOhdsi/images/Cover/Cover.png" />
  <meta property="og:description" content="A book about the Observational Health Data Science and Informatics (OHDS). It described the OHDSI community, open standards and open source software." />
  <meta name="github-repo" content="OHDSI/TheBookOfOhdsi" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 14 Patient Level Prediction | The Book of OHDSI" />
  
  <meta name="twitter:description" content="A book about the Observational Health Data Science and Informatics (OHDS). It described the OHDSI community, open standards and open source software." />
  <meta name="twitter:image" content="https://ohdsi.github.io/TheBookOfOhdsi/images/Cover/Cover.png" />

<meta name="author" content="Observational Health Data Science and Informatics" />


<meta name="date" content="2019-08-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon" />
<link rel="prev" href="PopulationLevelEstimation.html"/>
<link rel="next" href="EvidenceQuality.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-104086677-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-104086677-2');
</script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">The Book of OHDSI</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#goals-of-this-book"><i class="fa fa-check"></i>Goals of this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure-of-the-book"><i class="fa fa-check"></i>Structure of the book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contributors"><i class="fa fa-check"></i>Contributors</a></li>
</ul></li>
<li class="part"><span><b>I The OHDSI Community</b></span></li>
<li class="chapter" data-level="1" data-path="MissionVisionValues.html"><a href="MissionVisionValues.html"><i class="fa fa-check"></i><b>1</b> Mission, vision, values</a><ul>
<li class="chapter" data-level="1.1" data-path="MissionVisionValues.html"><a href="MissionVisionValues.html#our-mission"><i class="fa fa-check"></i><b>1.1</b> Our Mission</a></li>
<li class="chapter" data-level="1.2" data-path="MissionVisionValues.html"><a href="MissionVisionValues.html#our-vision"><i class="fa fa-check"></i><b>1.2</b> Our Vision</a></li>
<li class="chapter" data-level="1.3" data-path="MissionVisionValues.html"><a href="MissionVisionValues.html#our-objectives"><i class="fa fa-check"></i><b>1.3</b> Our Objectives</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Collaborators.html"><a href="Collaborators.html"><i class="fa fa-check"></i><b>2</b> Collaborators</a></li>
<li class="chapter" data-level="3" data-path="OpenScience.html"><a href="OpenScience.html"><i class="fa fa-check"></i><b>3</b> Open Science</a><ul>
<li class="chapter" data-level="3.1" data-path="OpenScience.html"><a href="OpenScience.html#open-science"><i class="fa fa-check"></i><b>3.1</b> Open Science</a></li>
<li class="chapter" data-level="3.2" data-path="OpenScience.html"><a href="OpenScience.html#open-science-in-action-the-study-a-thon"><i class="fa fa-check"></i><b>3.2</b> Open Science in Action: the Study-a-thon</a></li>
<li class="chapter" data-level="3.3" data-path="OpenScience.html"><a href="OpenScience.html#open-standards"><i class="fa fa-check"></i><b>3.3</b> Open Standards</a></li>
<li class="chapter" data-level="3.4" data-path="OpenScience.html"><a href="OpenScience.html#open-source"><i class="fa fa-check"></i><b>3.4</b> Open Source</a></li>
<li class="chapter" data-level="3.5" data-path="OpenScience.html"><a href="OpenScience.html#open-data"><i class="fa fa-check"></i><b>3.5</b> Open Data</a></li>
<li class="chapter" data-level="3.6" data-path="OpenScience.html"><a href="OpenScience.html#open-discourse"><i class="fa fa-check"></i><b>3.6</b> Open Discourse</a></li>
<li class="chapter" data-level="3.7" data-path="OpenScience.html"><a href="OpenScience.html#ohdsi-and-the-fair-guiding-principles"><i class="fa fa-check"></i><b>3.7</b> OHDSI and the FAIR Guiding Principles</a><ul>
<li class="chapter" data-level="3.7.1" data-path="OpenScience.html"><a href="OpenScience.html#findability"><i class="fa fa-check"></i><b>3.7.1</b> Findability</a></li>
<li class="chapter" data-level="3.7.2" data-path="OpenScience.html"><a href="OpenScience.html#accessibility"><i class="fa fa-check"></i><b>3.7.2</b> Accessibility</a></li>
<li class="chapter" data-level="3.7.3" data-path="OpenScience.html"><a href="OpenScience.html#interoperability"><i class="fa fa-check"></i><b>3.7.3</b> Interoperability</a></li>
<li class="chapter" data-level="3.7.4" data-path="OpenScience.html"><a href="OpenScience.html#reusability"><i class="fa fa-check"></i><b>3.7.4</b> Reusability</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="OpenScience.html"><a href="OpenScience.html#conclusions"><i class="fa fa-check"></i><b>3.8</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="WhereToBegin.html"><a href="WhereToBegin.html"><i class="fa fa-check"></i><b>4</b> Where to begin</a><ul>
<li class="chapter" data-level="4.1" data-path="WhereToBegin.html"><a href="WhereToBegin.html#joining-the-journey"><i class="fa fa-check"></i><b>4.1</b> Joining the Journey</a><ul>
<li class="chapter" data-level="4.1.1" data-path="WhereToBegin.html"><a href="WhereToBegin.html#ohdsi-community-calls"><i class="fa fa-check"></i><b>4.1.1</b> OHDSI Community Calls</a></li>
<li class="chapter" data-level="4.1.2" data-path="WhereToBegin.html"><a href="WhereToBegin.html#ohdsi-workgroups"><i class="fa fa-check"></i><b>4.1.2</b> OHDSI Workgroups</a></li>
<li class="chapter" data-level="4.1.3" data-path="WhereToBegin.html"><a href="WhereToBegin.html#ohdsi-regional-chapters"><i class="fa fa-check"></i><b>4.1.3</b> OHDSI Regional Chapters</a></li>
<li class="chapter" data-level="4.1.4" data-path="WhereToBegin.html"><a href="WhereToBegin.html#ohdsi-research-network"><i class="fa fa-check"></i><b>4.1.4</b> OHDSI Research Network</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="WhereToBegin.html"><a href="WhereToBegin.html#navigating-your-odyssey-in-ohdsi"><i class="fa fa-check"></i><b>4.2</b> Navigating Your Odyssey in OHDSI</a><ul>
<li class="chapter" data-level="4.2.1" data-path="WhereToBegin.html"><a href="WhereToBegin.html#how-to-translate-your-research-question-into-an-ohdsi-framework"><i class="fa fa-check"></i><b>4.2.1</b> How to Translate Your Research Question into an OHDSI Framework</a></li>
<li class="chapter" data-level="4.2.2" data-path="WhereToBegin.html"><a href="WhereToBegin.html#example-of-a-study-in-ohdsi-speak"><i class="fa fa-check"></i><b>4.2.2</b> Example of a Study in OHDSI-speak</a></li>
<li class="chapter" data-level="4.2.3" data-path="WhereToBegin.html"><a href="WhereToBegin.html#more-real-example-questions"><i class="fa fa-check"></i><b>4.2.3</b> More real example questions</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="WhereToBegin.html"><a href="WhereToBegin.html#summary"><i class="fa fa-check"></i><b>4.3</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>II Uniform Data Representation</b></span></li>
<li class="chapter" data-level="5" data-path="CommonDataModel.html"><a href="CommonDataModel.html"><i class="fa fa-check"></i><b>5</b> The Common Data Model</a><ul>
<li class="chapter" data-level="5.1" data-path="CommonDataModel.html"><a href="CommonDataModel.html#design-principles"><i class="fa fa-check"></i><b>5.1</b> Design Principles</a></li>
<li class="chapter" data-level="5.2" data-path="CommonDataModel.html"><a href="CommonDataModel.html#data-model-conventions"><i class="fa fa-check"></i><b>5.2</b> Data Model Conventions</a><ul>
<li class="chapter" data-level="5.2.1" data-path="CommonDataModel.html"><a href="CommonDataModel.html#model-conv"><i class="fa fa-check"></i><b>5.2.1</b> General conventions of the model</a></li>
<li class="chapter" data-level="5.2.2" data-path="CommonDataModel.html"><a href="CommonDataModel.html#general-conventions-of-schemas"><i class="fa fa-check"></i><b>5.2.2</b> General conventions of schemas</a></li>
<li class="chapter" data-level="5.2.3" data-path="CommonDataModel.html"><a href="CommonDataModel.html#general-conventions-of-data-tables"><i class="fa fa-check"></i><b>5.2.3</b> General conventions of data tables</a></li>
<li class="chapter" data-level="5.2.4" data-path="CommonDataModel.html"><a href="CommonDataModel.html#general-conventions-of-domains"><i class="fa fa-check"></i><b>5.2.4</b> General conventions of domains</a></li>
<li class="chapter" data-level="5.2.5" data-path="CommonDataModel.html"><a href="CommonDataModel.html#general-conventions-of-fields"><i class="fa fa-check"></i><b>5.2.5</b> General conventions of fields</a></li>
<li class="chapter" data-level="5.2.6" data-path="CommonDataModel.html"><a href="CommonDataModel.html#representation-of-content-through-concepts"><i class="fa fa-check"></i><b>5.2.6</b> Representation of content through Concepts</a></li>
<li class="chapter" data-level="5.2.7" data-path="CommonDataModel.html"><a href="CommonDataModel.html#concepts-sources"><i class="fa fa-check"></i><b>5.2.7</b> Difference between Concept IDs and Source Values</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="CommonDataModel.html"><a href="CommonDataModel.html#omop-cdm-standardized-tables"><i class="fa fa-check"></i><b>5.3</b> OMOP CDM Standardized Tables</a><ul>
<li class="chapter" data-level="5.3.1" data-path="CommonDataModel.html"><a href="CommonDataModel.html#running-example-endometriosis"><i class="fa fa-check"></i><b>5.3.1</b> Running Example: Endometriosis</a></li>
<li class="chapter" data-level="5.3.2" data-path="CommonDataModel.html"><a href="CommonDataModel.html#person"><i class="fa fa-check"></i><b>5.3.2</b> PERSON table</a></li>
<li class="chapter" data-level="5.3.3" data-path="CommonDataModel.html"><a href="CommonDataModel.html#observationPeriod"><i class="fa fa-check"></i><b>5.3.3</b> OBSERVATION_PERIOD table</a></li>
<li class="chapter" data-level="5.3.4" data-path="CommonDataModel.html"><a href="CommonDataModel.html#visitOccurrence"><i class="fa fa-check"></i><b>5.3.4</b> VISIT_OCCURRENCE</a></li>
<li class="chapter" data-level="5.3.5" data-path="CommonDataModel.html"><a href="CommonDataModel.html#conditionOccurrence"><i class="fa fa-check"></i><b>5.3.5</b> CONDITION_OCCURRENCE</a></li>
<li class="chapter" data-level="5.3.6" data-path="CommonDataModel.html"><a href="CommonDataModel.html#drugExposure"><i class="fa fa-check"></i><b>5.3.6</b> DRUG_EXPOSURE</a></li>
<li class="chapter" data-level="5.3.7" data-path="CommonDataModel.html"><a href="CommonDataModel.html#procedureOccurrence"><i class="fa fa-check"></i><b>5.3.7</b> PROCEDURE_OCCURRENCE</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="CommonDataModel.html"><a href="CommonDataModel.html#additional-information"><i class="fa fa-check"></i><b>5.4</b> Additional Information</a></li>
<li class="chapter" data-level="5.5" data-path="CommonDataModel.html"><a href="CommonDataModel.html#summary-1"><i class="fa fa-check"></i><b>5.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="StandardizedVocabularies.html"><a href="StandardizedVocabularies.html"><i class="fa fa-check"></i><b>6</b> Standardized Vocabularies</a></li>
<li class="chapter" data-level="7" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html"><i class="fa fa-check"></i><b>7</b> Extract Transform Load</a><ul>
<li class="chapter" data-level="7.1" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#introduction"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#step-1-design-the-etl"><i class="fa fa-check"></i><b>7.2</b> Step 1: Design the ETL</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#white-rabbit"><i class="fa fa-check"></i><b>7.2.1</b> White Rabbit</a></li>
<li class="chapter" data-level="7.2.2" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#rabbit-in-a-hat"><i class="fa fa-check"></i><b>7.2.2</b> Rabbit-In-a-Hat</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#step-2-create-the-code-mappings"><i class="fa fa-check"></i><b>7.3</b> Step 2: Create the code mappings</a><ul>
<li class="chapter" data-level="7.3.1" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#usagi"><i class="fa fa-check"></i><b>7.3.1</b> Usagi</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#step-3-implement-the-etl"><i class="fa fa-check"></i><b>7.4</b> Step 3: Implement the ETL</a></li>
<li class="chapter" data-level="7.5" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#step-4-quality-control"><i class="fa fa-check"></i><b>7.5</b> Step 4: Quality control</a></li>
<li class="chapter" data-level="7.6" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#final-thoughts-on-etl"><i class="fa fa-check"></i><b>7.6</b> Final thoughts on ETL</a></li>
<li class="chapter" data-level="7.7" data-path="ExtractTransformLoad.html"><a href="ExtractTransformLoad.html#summary-2"><i class="fa fa-check"></i><b>7.7</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>III Data Analytics</b></span></li>
<li class="chapter" data-level="8" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html"><i class="fa fa-check"></i><b>8</b> Data Analytics Use Cases</a><ul>
<li class="chapter" data-level="8.1" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#characterization"><i class="fa fa-check"></i><b>8.1</b> Characterization</a></li>
<li class="chapter" data-level="8.2" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#population-level-estimation"><i class="fa fa-check"></i><b>8.2</b> Population-level estimation</a></li>
<li class="chapter" data-level="8.3" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#patient-level-prediction"><i class="fa fa-check"></i><b>8.3</b> Patient-Level prediction</a></li>
<li class="chapter" data-level="8.4" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#limitations-of-observational-research"><i class="fa fa-check"></i><b>8.4</b> Limitations of observational research</a><ul>
<li class="chapter" data-level="8.4.1" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#missing-data"><i class="fa fa-check"></i><b>8.4.1</b> Missing data</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="DataAnalyticsUseCases.html"><a href="DataAnalyticsUseCases.html#summary-3"><i class="fa fa-check"></i><b>8.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html"><i class="fa fa-check"></i><b>9</b> OHDSI Analytics Tools</a><ul>
<li class="chapter" data-level="9.1" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#analysisImplementation"><i class="fa fa-check"></i><b>9.1</b> Analysis implementation</a></li>
<li class="chapter" data-level="9.2" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#analysis-strategy"><i class="fa fa-check"></i><b>9.2</b> Analysis strategy</a></li>
<li class="chapter" data-level="9.3" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#atlas"><i class="fa fa-check"></i><b>9.3</b> ATLAS</a><ul>
<li class="chapter" data-level="9.3.1" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#security"><i class="fa fa-check"></i><b>9.3.1</b> Security</a></li>
<li class="chapter" data-level="9.3.2" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#documentation"><i class="fa fa-check"></i><b>9.3.2</b> Documentation</a></li>
<li class="chapter" data-level="9.3.3" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#how-to-install"><i class="fa fa-check"></i><b>9.3.3</b> How to install</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#methods-library"><i class="fa fa-check"></i><b>9.4</b> Methods Library</a><ul>
<li class="chapter" data-level="9.4.1" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#support-for-large-scale-analytics"><i class="fa fa-check"></i><b>9.4.1</b> Support for large-scale analytics</a></li>
<li class="chapter" data-level="9.4.2" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#BigDataSupport"><i class="fa fa-check"></i><b>9.4.2</b> Support for big data</a></li>
<li class="chapter" data-level="9.4.3" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#documentation-1"><i class="fa fa-check"></i><b>9.4.3</b> Documentation</a></li>
<li class="chapter" data-level="9.4.4" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#system-requirements"><i class="fa fa-check"></i><b>9.4.4</b> System requirements</a></li>
<li class="chapter" data-level="9.4.5" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#installR"><i class="fa fa-check"></i><b>9.4.5</b> How to install</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#deployment-strategies"><i class="fa fa-check"></i><b>9.5</b> Deployment strategies</a><ul>
<li class="chapter" data-level="9.5.1" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#broadsea"><i class="fa fa-check"></i><b>9.5.1</b> Broadsea</a></li>
<li class="chapter" data-level="9.5.2" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#amazon-aws"><i class="fa fa-check"></i><b>9.5.2</b> Amazon AWS</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#summary-4"><i class="fa fa-check"></i><b>9.6</b> Summary</a></li>
<li class="chapter" data-level="9.7" data-path="OhdsiAnalyticsTools.html"><a href="OhdsiAnalyticsTools.html#exercises"><i class="fa fa-check"></i><b>9.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="SqlAndR.html"><a href="SqlAndR.html"><i class="fa fa-check"></i><b>10</b> SQL and R</a><ul>
<li class="chapter" data-level="10.1" data-path="SqlAndR.html"><a href="SqlAndR.html#SqlRender"><i class="fa fa-check"></i><b>10.1</b> SqlRender</a><ul>
<li class="chapter" data-level="10.1.1" data-path="SqlAndR.html"><a href="SqlAndR.html#sql-parameterization"><i class="fa fa-check"></i><b>10.1.1</b> SQL parameterization</a></li>
<li class="chapter" data-level="10.1.2" data-path="SqlAndR.html"><a href="SqlAndR.html#translation-to-other-sql-dialects"><i class="fa fa-check"></i><b>10.1.2</b> Translation to other SQL dialects</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="SqlAndR.html"><a href="SqlAndR.html#DatabaseConnector"><i class="fa fa-check"></i><b>10.2</b> DatabaseConnector</a><ul>
<li class="chapter" data-level="10.2.1" data-path="SqlAndR.html"><a href="SqlAndR.html#creating-a-connection"><i class="fa fa-check"></i><b>10.2.1</b> Creating a connection</a></li>
<li class="chapter" data-level="10.2.2" data-path="SqlAndR.html"><a href="SqlAndR.html#querying"><i class="fa fa-check"></i><b>10.2.2</b> Querying</a></li>
<li class="chapter" data-level="10.2.3" data-path="SqlAndR.html"><a href="SqlAndR.html#querying-using-ffdf-objects"><i class="fa fa-check"></i><b>10.2.3</b> Querying using ffdf objects</a></li>
<li class="chapter" data-level="10.2.4" data-path="SqlAndR.html"><a href="SqlAndR.html#querying-different-platforms-using-the-same-sql"><i class="fa fa-check"></i><b>10.2.4</b> Querying different platforms using the same SQL</a></li>
<li class="chapter" data-level="10.2.5" data-path="SqlAndR.html"><a href="SqlAndR.html#inserting-tables"><i class="fa fa-check"></i><b>10.2.5</b> Inserting tables</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="SqlAndR.html"><a href="SqlAndR.html#QueryTheCdm"><i class="fa fa-check"></i><b>10.3</b> Querying the CDM</a></li>
<li class="chapter" data-level="10.4" data-path="SqlAndR.html"><a href="SqlAndR.html#using-the-vocabulary-when-querying"><i class="fa fa-check"></i><b>10.4</b> Using the vocabulary when querying</a></li>
<li class="chapter" data-level="10.5" data-path="SqlAndR.html"><a href="SqlAndR.html#querylibrary"><i class="fa fa-check"></i><b>10.5</b> QueryLibrary</a></li>
<li class="chapter" data-level="10.6" data-path="SqlAndR.html"><a href="SqlAndR.html#designing-a-simple-study"><i class="fa fa-check"></i><b>10.6</b> Designing a simple study</a><ul>
<li class="chapter" data-level="10.6.1" data-path="SqlAndR.html"><a href="SqlAndR.html#problem-definition"><i class="fa fa-check"></i><b>10.6.1</b> Problem definition</a></li>
<li class="chapter" data-level="10.6.2" data-path="SqlAndR.html"><a href="SqlAndR.html#exposure"><i class="fa fa-check"></i><b>10.6.2</b> Exposure</a></li>
<li class="chapter" data-level="10.6.3" data-path="SqlAndR.html"><a href="SqlAndR.html#outcome"><i class="fa fa-check"></i><b>10.6.3</b> Outcome</a></li>
<li class="chapter" data-level="10.6.4" data-path="SqlAndR.html"><a href="SqlAndR.html#time-at-risk"><i class="fa fa-check"></i><b>10.6.4</b> Time-at-risk</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="SqlAndR.html"><a href="SqlAndR.html#implementing-the-study-using-sql-and-r"><i class="fa fa-check"></i><b>10.7</b> Implementing the study using SQL and R</a><ul>
<li class="chapter" data-level="10.7.1" data-path="SqlAndR.html"><a href="SqlAndR.html#exposure-cohort"><i class="fa fa-check"></i><b>10.7.1</b> Exposure cohort</a></li>
<li class="chapter" data-level="10.7.2" data-path="SqlAndR.html"><a href="SqlAndR.html#outcome-cohort"><i class="fa fa-check"></i><b>10.7.2</b> Outcome cohort</a></li>
<li class="chapter" data-level="10.7.3" data-path="SqlAndR.html"><a href="SqlAndR.html#incidence-rate-calculation"><i class="fa fa-check"></i><b>10.7.3</b> Incidence rate calculation</a></li>
<li class="chapter" data-level="10.7.4" data-path="SqlAndR.html"><a href="SqlAndR.html#clean-up"><i class="fa fa-check"></i><b>10.7.4</b> Clean up</a></li>
<li class="chapter" data-level="10.7.5" data-path="SqlAndR.html"><a href="SqlAndR.html#compatibility"><i class="fa fa-check"></i><b>10.7.5</b> Compatibility</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="SqlAndR.html"><a href="SqlAndR.html#summary-5"><i class="fa fa-check"></i><b>10.8</b> Summary</a></li>
<li class="chapter" data-level="10.9" data-path="SqlAndR.html"><a href="SqlAndR.html#exercises-1"><i class="fa fa-check"></i><b>10.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="Cohorts.html"><a href="Cohorts.html"><i class="fa fa-check"></i><b>11</b> Building the building blocks: cohorts</a><ul>
<li class="chapter" data-level="11.1" data-path="Cohorts.html"><a href="Cohorts.html#theory"><i class="fa fa-check"></i><b>11.1</b> Theory</a><ul>
<li class="chapter" data-level="11.1.1" data-path="Cohorts.html"><a href="Cohorts.html#rules-based-cohort-design"><i class="fa fa-check"></i><b>11.1.1</b> Rules-based cohort design</a></li>
<li class="chapter" data-level="11.1.2" data-path="Cohorts.html"><a href="Cohorts.html#probabilistic-cohort-design-using-aphrodite"><i class="fa fa-check"></i><b>11.1.2</b> Probabilistic cohort design using APHRODITE</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="Cohorts.html"><a href="Cohorts.html#phenotype-algorithm-evaluation"><i class="fa fa-check"></i><b>11.2</b> Phenotype Algorithm Evaluation</a></li>
<li class="chapter" data-level="11.3" data-path="Cohorts.html"><a href="Cohorts.html#ohdsi-gold-standard-phenotype-library"><i class="fa fa-check"></i><b>11.3</b> OHDSI Gold Standard Phenotype Library</a></li>
<li class="chapter" data-level="11.4" data-path="Cohorts.html"><a href="Cohorts.html#practice"><i class="fa fa-check"></i><b>11.4</b> Practice</a><ul>
<li class="chapter" data-level="11.4.1" data-path="Cohorts.html"><a href="Cohorts.html#using-atlas"><i class="fa fa-check"></i><b>11.4.1</b> Using ATLAS</a></li>
<li class="chapter" data-level="11.4.2" data-path="Cohorts.html"><a href="Cohorts.html#cohort-building-at-the-database-layer-using-sql"><i class="fa fa-check"></i><b>11.4.2</b> Cohort Building at the Database Layer Using SQL</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="Cohorts.html"><a href="Cohorts.html#summary-6"><i class="fa fa-check"></i><b>11.5</b> Summary</a><ul>
<li class="chapter" data-level="11.5.1" data-path="Cohorts.html"><a href="Cohorts.html#exercises-2"><i class="fa fa-check"></i><b>11.5.1</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Characterization.html"><a href="Characterization.html"><i class="fa fa-check"></i><b>12</b> Characterization</a><ul>
<li class="chapter" data-level="12.1" data-path="Characterization.html"><a href="Characterization.html#database-level-characterization"><i class="fa fa-check"></i><b>12.1</b> Database Level Characterization</a></li>
<li class="chapter" data-level="12.2" data-path="Characterization.html"><a href="Characterization.html#cohort-characterization"><i class="fa fa-check"></i><b>12.2</b> Cohort characterization</a></li>
<li class="chapter" data-level="12.3" data-path="Characterization.html"><a href="Characterization.html#treatment-pathways"><i class="fa fa-check"></i><b>12.3</b> Treatment Pathways</a></li>
<li class="chapter" data-level="12.4" data-path="Characterization.html"><a href="Characterization.html#incidence"><i class="fa fa-check"></i><b>12.4</b> Incidence</a></li>
<li class="chapter" data-level="12.5" data-path="Characterization.html"><a href="Characterization.html#characterizing-hypertensive-persons"><i class="fa fa-check"></i><b>12.5</b> Characterizing hypertensive persons</a></li>
<li class="chapter" data-level="12.6" data-path="Characterization.html"><a href="Characterization.html#database-characterization-in-atlas"><i class="fa fa-check"></i><b>12.6</b> Database characterization in ATLAS</a></li>
<li class="chapter" data-level="12.7" data-path="Characterization.html"><a href="Characterization.html#cohort-characterization-in-atlas"><i class="fa fa-check"></i><b>12.7</b> Cohort characterization in ATLAS</a><ul>
<li class="chapter" data-level="12.7.1" data-path="Characterization.html"><a href="Characterization.html#design"><i class="fa fa-check"></i><b>12.7.1</b> Design</a></li>
<li class="chapter" data-level="12.7.2" data-path="Characterization.html"><a href="Characterization.html#executions"><i class="fa fa-check"></i><b>12.7.2</b> Executions</a></li>
<li class="chapter" data-level="12.7.3" data-path="Characterization.html"><a href="Characterization.html#results"><i class="fa fa-check"></i><b>12.7.3</b> Results</a></li>
<li class="chapter" data-level="12.7.4" data-path="Characterization.html"><a href="Characterization.html#defining-custom-features"><i class="fa fa-check"></i><b>12.7.4</b> Defining custom features</a></li>
</ul></li>
<li class="chapter" data-level="12.8" data-path="Characterization.html"><a href="Characterization.html#cohort-characterization-in-r"><i class="fa fa-check"></i><b>12.8</b> Cohort characterization in R</a><ul>
<li class="chapter" data-level="12.8.1" data-path="Characterization.html"><a href="Characterization.html#cohort-instantiation"><i class="fa fa-check"></i><b>12.8.1</b> Cohort instantiation</a></li>
<li class="chapter" data-level="12.8.2" data-path="Characterization.html"><a href="Characterization.html#data-extraction"><i class="fa fa-check"></i><b>12.8.2</b> Data extraction</a></li>
<li class="chapter" data-level="12.8.3" data-path="Characterization.html"><a href="Characterization.html#using-prespecified-analyses"><i class="fa fa-check"></i><b>12.8.3</b> Using prespecified analyses</a></li>
<li class="chapter" data-level="12.8.4" data-path="Characterization.html"><a href="Characterization.html#creating-aggregated-covariates"><i class="fa fa-check"></i><b>12.8.4</b> Creating aggregated covariates</a></li>
<li class="chapter" data-level="12.8.5" data-path="Characterization.html"><a href="Characterization.html#output-format"><i class="fa fa-check"></i><b>12.8.5</b> Output format</a></li>
<li class="chapter" data-level="12.8.6" data-path="Characterization.html"><a href="Characterization.html#custom-covariates"><i class="fa fa-check"></i><b>12.8.6</b> Custom covariates</a></li>
</ul></li>
<li class="chapter" data-level="12.9" data-path="Characterization.html"><a href="Characterization.html#cohort-pathways-in-atlas"><i class="fa fa-check"></i><b>12.9</b> Cohort pathways in ATLAS</a><ul>
<li class="chapter" data-level="12.9.1" data-path="Characterization.html"><a href="Characterization.html#design-1"><i class="fa fa-check"></i><b>12.9.1</b> Design</a></li>
<li class="chapter" data-level="12.9.2" data-path="Characterization.html"><a href="Characterization.html#executions-1"><i class="fa fa-check"></i><b>12.9.2</b> Executions</a></li>
<li class="chapter" data-level="12.9.3" data-path="Characterization.html"><a href="Characterization.html#viewing-results"><i class="fa fa-check"></i><b>12.9.3</b> Viewing Results</a></li>
</ul></li>
<li class="chapter" data-level="12.10" data-path="Characterization.html"><a href="Characterization.html#incidence-analysis-in-atlas"><i class="fa fa-check"></i><b>12.10</b> Incidence analysis in ATLAS</a><ul>
<li class="chapter" data-level="12.10.1" data-path="Characterization.html"><a href="Characterization.html#design-2"><i class="fa fa-check"></i><b>12.10.1</b> Design</a></li>
<li class="chapter" data-level="12.10.2" data-path="Characterization.html"><a href="Characterization.html#executions-2"><i class="fa fa-check"></i><b>12.10.2</b> Executions</a></li>
<li class="chapter" data-level="12.10.3" data-path="Characterization.html"><a href="Characterization.html#viewing-results-1"><i class="fa fa-check"></i><b>12.10.3</b> Viewing Results</a></li>
</ul></li>
<li class="chapter" data-level="12.11" data-path="Characterization.html"><a href="Characterization.html#summary-7"><i class="fa fa-check"></i><b>12.11</b> Summary</a></li>
<li class="chapter" data-level="12.12" data-path="Characterization.html"><a href="Characterization.html#exercises-3"><i class="fa fa-check"></i><b>12.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html"><i class="fa fa-check"></i><b>13</b> Population-Level Estimation</a><ul>
<li class="chapter" data-level="13.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#CohortMethod"><i class="fa fa-check"></i><b>13.1</b> The cohort method design</a><ul>
<li class="chapter" data-level="13.1.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#propensity-scores"><i class="fa fa-check"></i><b>13.1.1</b> Propensity scores</a></li>
<li class="chapter" data-level="13.1.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#VariableSelection"><i class="fa fa-check"></i><b>13.1.2</b> Variable selection</a></li>
<li class="chapter" data-level="13.1.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#caliper"><i class="fa fa-check"></i><b>13.1.3</b> Caliper</a></li>
<li class="chapter" data-level="13.1.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#overlap-preference-scores"><i class="fa fa-check"></i><b>13.1.4</b> Overlap: preference scores</a></li>
<li class="chapter" data-level="13.1.5" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#balance"><i class="fa fa-check"></i><b>13.1.5</b> Balance</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#the-self-controlled-cohort-design"><i class="fa fa-check"></i><b>13.2</b> The self-controlled cohort design</a></li>
<li class="chapter" data-level="13.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#the-case-control-design"><i class="fa fa-check"></i><b>13.3</b> The case-control design</a></li>
<li class="chapter" data-level="13.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#the-case-crossover-design"><i class="fa fa-check"></i><b>13.4</b> The case-crossover design</a></li>
<li class="chapter" data-level="13.5" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#the-self-controlled-case-series-design"><i class="fa fa-check"></i><b>13.5</b> The self-controlled case series design</a></li>
<li class="chapter" data-level="13.6" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#designing-a-hypertension-study"><i class="fa fa-check"></i><b>13.6</b> Designing a hypertension study</a><ul>
<li class="chapter" data-level="13.6.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#problem-definition-1"><i class="fa fa-check"></i><b>13.6.1</b> Problem definition</a></li>
<li class="chapter" data-level="13.6.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#target-and-comparator"><i class="fa fa-check"></i><b>13.6.2</b> Target and comparator</a></li>
<li class="chapter" data-level="13.6.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#outcome-1"><i class="fa fa-check"></i><b>13.6.3</b> Outcome</a></li>
<li class="chapter" data-level="13.6.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#time-at-risk-1"><i class="fa fa-check"></i><b>13.6.4</b> Time-at-risk</a></li>
<li class="chapter" data-level="13.6.5" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#model"><i class="fa fa-check"></i><b>13.6.5</b> Model</a></li>
<li class="chapter" data-level="13.6.6" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#study-summary"><i class="fa fa-check"></i><b>13.6.6</b> Study summary</a></li>
<li class="chapter" data-level="13.6.7" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#control-questions"><i class="fa fa-check"></i><b>13.6.7</b> Control questions</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#PleAtlas"><i class="fa fa-check"></i><b>13.7</b> Implementing the study using ATLAS</a><ul>
<li class="chapter" data-level="13.7.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#ComparisonSettings"><i class="fa fa-check"></i><b>13.7.1</b> Comparative cohort settings</a></li>
<li class="chapter" data-level="13.7.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#effect-estimation-analysis-settings"><i class="fa fa-check"></i><b>13.7.2</b> Effect estimation analysis settings</a></li>
<li class="chapter" data-level="13.7.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#evaluationSettings"><i class="fa fa-check"></i><b>13.7.3</b> Evaluation settings</a></li>
<li class="chapter" data-level="13.7.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#running-the-study-package"><i class="fa fa-check"></i><b>13.7.4</b> Running the study package</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#pleR"><i class="fa fa-check"></i><b>13.8</b> Implementing the study using R</a><ul>
<li class="chapter" data-level="13.8.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#cohort-instantiation-1"><i class="fa fa-check"></i><b>13.8.1</b> Cohort instantiation</a></li>
<li class="chapter" data-level="13.8.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#data-extraction-1"><i class="fa fa-check"></i><b>13.8.2</b> Data extraction</a></li>
<li class="chapter" data-level="13.8.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#defining-the-study-population"><i class="fa fa-check"></i><b>13.8.3</b> Defining the study population</a></li>
<li class="chapter" data-level="13.8.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#propensity-scores-1"><i class="fa fa-check"></i><b>13.8.4</b> Propensity scores</a></li>
<li class="chapter" data-level="13.8.5" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#outcome-models"><i class="fa fa-check"></i><b>13.8.5</b> Outcome models</a></li>
<li class="chapter" data-level="13.8.6" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#MultipleAnalyses"><i class="fa fa-check"></i><b>13.8.6</b> Running multiple analyses</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#studyOutputs"><i class="fa fa-check"></i><b>13.9</b> Study outputs</a><ul>
<li class="chapter" data-level="13.9.1" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#propensity-scores-and-model"><i class="fa fa-check"></i><b>13.9.1</b> Propensity scores and model</a></li>
<li class="chapter" data-level="13.9.2" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#covariate-balance"><i class="fa fa-check"></i><b>13.9.2</b> Covariate balance</a></li>
<li class="chapter" data-level="13.9.3" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#follow-up-and-power"><i class="fa fa-check"></i><b>13.9.3</b> Follow up and power</a></li>
<li class="chapter" data-level="13.9.4" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#kaplan-meier"><i class="fa fa-check"></i><b>13.9.4</b> Kaplan-Meier</a></li>
<li class="chapter" data-level="13.9.5" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#effect-size-estimate"><i class="fa fa-check"></i><b>13.9.5</b> Effect size estimate</a></li>
</ul></li>
<li class="chapter" data-level="13.10" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#summary-8"><i class="fa fa-check"></i><b>13.10</b> Summary</a></li>
<li class="chapter" data-level="13.11" data-path="PopulationLevelEstimation.html"><a href="PopulationLevelEstimation.html#excercises"><i class="fa fa-check"></i><b>13.11</b> Excercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html"><i class="fa fa-check"></i><b>14</b> Patient Level Prediction</a><ul>
<li class="chapter" data-level="14.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#the-prediction-problem"><i class="fa fa-check"></i><b>14.1</b> The prediction problem</a></li>
<li class="chapter" data-level="14.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#data-extraction-2"><i class="fa fa-check"></i><b>14.2</b> Data extraction</a><ul>
<li class="chapter" data-level="14.2.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#data-extraction-example"><i class="fa fa-check"></i><b>14.2.1</b> Data extraction example</a></li>
<li class="chapter" data-level="14.2.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#missingness"><i class="fa fa-check"></i><b>14.2.2</b> Missingness</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#modelFitting"><i class="fa fa-check"></i><b>14.3</b> Fitting the model</a><ul>
<li class="chapter" data-level="14.3.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#regularized-logistic-regression"><i class="fa fa-check"></i><b>14.3.1</b> Regularized logistic regression</a></li>
<li class="chapter" data-level="14.3.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#gradient-boosting-machines"><i class="fa fa-check"></i><b>14.3.2</b> Gradient boosting machines</a></li>
<li class="chapter" data-level="14.3.3" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#random-forest"><i class="fa fa-check"></i><b>14.3.3</b> Random forest</a></li>
<li class="chapter" data-level="14.3.4" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>14.3.4</b> K-nearest neighbors</a></li>
<li class="chapter" data-level="14.3.5" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#naive-bayes"><i class="fa fa-check"></i><b>14.3.5</b> Naive Bayes</a></li>
<li class="chapter" data-level="14.3.6" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#adaboost"><i class="fa fa-check"></i><b>14.3.6</b> AdaBoost</a></li>
<li class="chapter" data-level="14.3.7" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#decision-tree"><i class="fa fa-check"></i><b>14.3.7</b> Decision Tree</a></li>
<li class="chapter" data-level="14.3.8" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#multilayer-perceptron"><i class="fa fa-check"></i><b>14.3.8</b> Multilayer Perceptron</a></li>
<li class="chapter" data-level="14.3.9" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#deep-learning"><i class="fa fa-check"></i><b>14.3.9</b> Deep Learning</a></li>
<li class="chapter" data-level="14.3.10" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#other-algorithms"><i class="fa fa-check"></i><b>14.3.10</b> Other algorithms</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#evaluating-prediction-models"><i class="fa fa-check"></i><b>14.4</b> Evaluating prediction models</a><ul>
<li class="chapter" data-level="14.4.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#evaluation-types"><i class="fa fa-check"></i><b>14.4.1</b> Evaluation Types</a></li>
<li class="chapter" data-level="14.4.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#performance"><i class="fa fa-check"></i><b>14.4.2</b> Performance Metrics</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#designing-a-patient-level-prediction-study"><i class="fa fa-check"></i><b>14.5</b> Designing a patient-level prediction Study</a><ul>
<li class="chapter" data-level="14.5.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#problem-definition-2"><i class="fa fa-check"></i><b>14.5.1</b> Problem definition</a></li>
<li class="chapter" data-level="14.5.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#study-population-definition"><i class="fa fa-check"></i><b>14.5.2</b> Study population definition</a></li>
<li class="chapter" data-level="14.5.3" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#model-development-settings"><i class="fa fa-check"></i><b>14.5.3</b> Model development settings</a></li>
<li class="chapter" data-level="14.5.4" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#model-evaluation"><i class="fa fa-check"></i><b>14.5.4</b> Model evaluation</a></li>
<li class="chapter" data-level="14.5.5" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#study-summary-1"><i class="fa fa-check"></i><b>14.5.5</b> Study summary</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#implementing-the-study-in-atlas"><i class="fa fa-check"></i><b>14.6</b> Implementing the study in ATLAS</a><ul>
<li class="chapter" data-level="14.6.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#prediction-problem-settings"><i class="fa fa-check"></i><b>14.6.1</b> Prediction Problem Settings</a></li>
<li class="chapter" data-level="14.6.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#analysis-settings"><i class="fa fa-check"></i><b>14.6.2</b> Analysis Settings</a></li>
<li class="chapter" data-level="14.6.3" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#execution-settings"><i class="fa fa-check"></i><b>14.6.3</b> Execution settings</a></li>
<li class="chapter" data-level="14.6.4" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#training-settings"><i class="fa fa-check"></i><b>14.6.4</b> Training settings</a></li>
<li class="chapter" data-level="14.6.5" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#importing-and-exporting-a-study"><i class="fa fa-check"></i><b>14.6.5</b> Importing and exporting a study</a></li>
<li class="chapter" data-level="14.6.6" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#downloading-the-study-package"><i class="fa fa-check"></i><b>14.6.6</b> Downloading the study package</a></li>
<li class="chapter" data-level="14.6.7" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#running-the-study"><i class="fa fa-check"></i><b>14.6.7</b> Running the study</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#implementing-the-study-in-r"><i class="fa fa-check"></i><b>14.7</b> Implementing the study in R</a><ul>
<li class="chapter" data-level="14.7.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#cohort-instantiation-2"><i class="fa fa-check"></i><b>14.7.1</b> Cohort instantiation</a></li>
<li class="chapter" data-level="14.7.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#data-extraction-3"><i class="fa fa-check"></i><b>14.7.2</b> Data extraction</a></li>
<li class="chapter" data-level="14.7.3" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#additional-inclusion-criteria"><i class="fa fa-check"></i><b>14.7.3</b> Additional inclusion criteria</a></li>
<li class="chapter" data-level="14.7.4" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#model-development"><i class="fa fa-check"></i><b>14.7.4</b> Model Development</a></li>
<li class="chapter" data-level="14.7.5" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#internal-validation"><i class="fa fa-check"></i><b>14.7.5</b> Internal Validation</a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#single-model-viewer-app"><i class="fa fa-check"></i><b>14.8</b> Single model viewer app</a></li>
<li class="chapter" data-level="14.9" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#multiple-model-viewer-app"><i class="fa fa-check"></i><b>14.9</b> Multiple model viewer app</a><ul>
<li class="chapter" data-level="14.9.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#viewing-the-model-summary-and-settings"><i class="fa fa-check"></i><b>14.9.1</b> Viewing the model summary and settings</a></li>
<li class="chapter" data-level="14.9.2" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#viewing-model-performance"><i class="fa fa-check"></i><b>14.9.2</b> Viewing model performance</a></li>
<li class="chapter" data-level="14.9.3" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#viewing-the-model"><i class="fa fa-check"></i><b>14.9.3</b> Viewing the model</a></li>
</ul></li>
<li class="chapter" data-level="14.10" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#additional-patient-level-prediction-features"><i class="fa fa-check"></i><b>14.10</b> Additional Patient-level Prediction Features</a><ul>
<li class="chapter" data-level="14.10.1" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#journal-paper-generation"><i class="fa fa-check"></i><b>14.10.1</b> Journal paper generation</a></li>
</ul></li>
<li class="chapter" data-level="14.11" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#summary-9"><i class="fa fa-check"></i><b>14.11</b> Summary</a></li>
<li class="chapter" data-level="14.12" data-path="PatientLevelPrediction.html"><a href="PatientLevelPrediction.html#excercises-1"><i class="fa fa-check"></i><b>14.12</b> Excercises</a></li>
</ul></li>
<li class="part"><span><b>IV Evidence Quality</b></span></li>
<li class="chapter" data-level="15" data-path="EvidenceQuality.html"><a href="EvidenceQuality.html"><i class="fa fa-check"></i><b>15</b> Evidence Quality</a><ul>
<li class="chapter" data-level="15.1" data-path="EvidenceQuality.html"><a href="EvidenceQuality.html#understanding-evidence-quality"><i class="fa fa-check"></i><b>15.1</b> Understanding Evidence Quality</a></li>
<li class="chapter" data-level="15.2" data-path="EvidenceQuality.html"><a href="EvidenceQuality.html#communicating-evidence-quality"><i class="fa fa-check"></i><b>15.2</b> Communicating Evidence Quality</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="DataQuality.html"><a href="DataQuality.html"><i class="fa fa-check"></i><b>16</b> Data Quality</a><ul>
<li class="chapter" data-level="16.1" data-path="DataQuality.html"><a href="DataQuality.html#introduction-1"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="DataQuality.html"><a href="DataQuality.html#achilles-heel-tool"><i class="fa fa-check"></i><b>16.2</b> Achilles Heel tool</a><ul>
<li class="chapter" data-level="16.2.1" data-path="DataQuality.html"><a href="DataQuality.html#precomputed-analyses"><i class="fa fa-check"></i><b>16.2.1</b> Precomputed Analyses</a></li>
<li class="chapter" data-level="16.2.2" data-path="DataQuality.html"><a href="DataQuality.html#example-dq-check"><i class="fa fa-check"></i><b>16.2.2</b> Example DQ check</a></li>
<li class="chapter" data-level="16.2.3" data-path="DataQuality.html"><a href="DataQuality.html#overview-of-existing-dq-heel-checks"><i class="fa fa-check"></i><b>16.2.3</b> Overview of existing DQ Heel checks</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="DataQuality.html"><a href="DataQuality.html#study-specific-checks"><i class="fa fa-check"></i><b>16.3</b> Study-specific checks</a><ul>
<li class="chapter" data-level="16.3.1" data-path="DataQuality.html"><a href="DataQuality.html#outcomes"><i class="fa fa-check"></i><b>16.3.1</b> Outcomes</a></li>
<li class="chapter" data-level="16.3.2" data-path="DataQuality.html"><a href="DataQuality.html#laboratory-data"><i class="fa fa-check"></i><b>16.3.2</b> Laboratory data</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="DataQuality.html"><a href="DataQuality.html#etl-unit-testing"><i class="fa fa-check"></i><b>16.4</b> ETL unit testing</a><ul>
<li class="chapter" data-level="16.4.1" data-path="DataQuality.html"><a href="DataQuality.html#unit-testing-framwork-in-rabbit-in-a-hat"><i class="fa fa-check"></i><b>16.4.1</b> Unit testing framwork in Rabbit-in-a-Hat</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="ClinicalValidity.html"><a href="ClinicalValidity.html"><i class="fa fa-check"></i><b>17</b> Clinical Validity</a></li>
<li class="chapter" data-level="18" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html"><i class="fa fa-check"></i><b>18</b> Software Validity</a><ul>
<li class="chapter" data-level="18.1" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#study-code-validity"><i class="fa fa-check"></i><b>18.1</b> Study code validity</a><ul>
<li class="chapter" data-level="18.1.1" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#automation"><i class="fa fa-check"></i><b>18.1.1</b> Automation as a requirement for reproducibility</a></li>
<li class="chapter" data-level="18.1.2" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#programming-best-practices"><i class="fa fa-check"></i><b>18.1.2</b> Programming best practices</a></li>
<li class="chapter" data-level="18.1.3" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#code-validation"><i class="fa fa-check"></i><b>18.1.3</b> Code validation</a></li>
<li class="chapter" data-level="18.1.4" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#using-the-methods-library"><i class="fa fa-check"></i><b>18.1.4</b> Using the Methods Library</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#methods-library-software-development-process"><i class="fa fa-check"></i><b>18.2</b> Methods Library software development process</a><ul>
<li class="chapter" data-level="18.2.1" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#source-code-management"><i class="fa fa-check"></i><b>18.2.1</b> Source Code Management</a></li>
<li class="chapter" data-level="18.2.2" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#documentation-2"><i class="fa fa-check"></i><b>18.2.2</b> Documentation</a></li>
<li class="chapter" data-level="18.2.3" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#availability-of-current-and-historical-archive-versions"><i class="fa fa-check"></i><b>18.2.3</b> Availability of Current and Historical Archive Versions</a></li>
<li class="chapter" data-level="18.2.4" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#maintenance-support-and-retirement"><i class="fa fa-check"></i><b>18.2.4</b> Maintenance, Support and Retirement</a></li>
<li class="chapter" data-level="18.2.5" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#qualified-personnel"><i class="fa fa-check"></i><b>18.2.5</b> Qualified Personnel</a></li>
<li class="chapter" data-level="18.2.6" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#physical-and-logical-security"><i class="fa fa-check"></i><b>18.2.6</b> Physical and Logical Security</a></li>
<li class="chapter" data-level="18.2.7" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#disaster-recovery"><i class="fa fa-check"></i><b>18.2.7</b> Disaster Recovery</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#methods-library-testing"><i class="fa fa-check"></i><b>18.3</b> Methods Library testing</a><ul>
<li class="chapter" data-level="18.3.1" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#unit-test"><i class="fa fa-check"></i><b>18.3.1</b> Unit test</a></li>
<li class="chapter" data-level="18.3.2" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#simulation"><i class="fa fa-check"></i><b>18.3.2</b> Simulation</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="SoftwareValidity.html"><a href="SoftwareValidity.html#summary-10"><i class="fa fa-check"></i><b>18.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="MethodValidity.html"><a href="MethodValidity.html"><i class="fa fa-check"></i><b>19</b> Method Validity</a><ul>
<li class="chapter" data-level="19.1" data-path="MethodValidity.html"><a href="MethodValidity.html#design-specific-diagnostics"><i class="fa fa-check"></i><b>19.1</b> Design-specific diagnostics</a></li>
<li class="chapter" data-level="19.2" data-path="MethodValidity.html"><a href="MethodValidity.html#diagnostics-for-all-estimation"><i class="fa fa-check"></i><b>19.2</b> Diagnostics for all estimation</a><ul>
<li class="chapter" data-level="19.2.1" data-path="MethodValidity.html"><a href="MethodValidity.html#NegativeControls"><i class="fa fa-check"></i><b>19.2.1</b> Negative controls</a></li>
<li class="chapter" data-level="19.2.2" data-path="MethodValidity.html"><a href="MethodValidity.html#PositiveControls"><i class="fa fa-check"></i><b>19.2.2</b> Positive controls</a></li>
<li class="chapter" data-level="19.2.3" data-path="MethodValidity.html"><a href="MethodValidity.html#metrics"><i class="fa fa-check"></i><b>19.2.3</b> Empirical evaluation</a></li>
<li class="chapter" data-level="19.2.4" data-path="MethodValidity.html"><a href="MethodValidity.html#p-value-calibration"><i class="fa fa-check"></i><b>19.2.4</b> P-value calibration</a></li>
<li class="chapter" data-level="19.2.5" data-path="MethodValidity.html"><a href="MethodValidity.html#confidence-interval-calibration"><i class="fa fa-check"></i><b>19.2.5</b> Confidence interval calibration</a></li>
<li class="chapter" data-level="19.2.6" data-path="MethodValidity.html"><a href="MethodValidity.html#replication-across-sites"><i class="fa fa-check"></i><b>19.2.6</b> Replication across sites</a></li>
<li class="chapter" data-level="19.2.7" data-path="MethodValidity.html"><a href="MethodValidity.html#sensitivity-analyses"><i class="fa fa-check"></i><b>19.2.7</b> Sensitivity analyses</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="MethodValidity.html"><a href="MethodValidity.html#method-validation-in-practice"><i class="fa fa-check"></i><b>19.3</b> Method validation in practice</a><ul>
<li class="chapter" data-level="19.3.1" data-path="MethodValidity.html"><a href="MethodValidity.html#selecting-negative-controls"><i class="fa fa-check"></i><b>19.3.1</b> Selecting negative controls</a></li>
<li class="chapter" data-level="19.3.2" data-path="MethodValidity.html"><a href="MethodValidity.html#including-controls"><i class="fa fa-check"></i><b>19.3.2</b> Including controls</a></li>
<li class="chapter" data-level="19.3.3" data-path="MethodValidity.html"><a href="MethodValidity.html#empirical-performance"><i class="fa fa-check"></i><b>19.3.3</b> Empirical performance</a></li>
<li class="chapter" data-level="19.3.4" data-path="MethodValidity.html"><a href="MethodValidity.html#p-value-calibration-1"><i class="fa fa-check"></i><b>19.3.4</b> P-value calibration</a></li>
<li class="chapter" data-level="19.3.5" data-path="MethodValidity.html"><a href="MethodValidity.html#confidence-interval-calibration-1"><i class="fa fa-check"></i><b>19.3.5</b> Confidence interval calibration</a></li>
<li class="chapter" data-level="19.3.6" data-path="MethodValidity.html"><a href="MethodValidity.html#between-database-heterogeneity"><i class="fa fa-check"></i><b>19.3.6</b> Between-database heterogeneity</a></li>
<li class="chapter" data-level="19.3.7" data-path="MethodValidity.html"><a href="MethodValidity.html#sensitivity-analyses-1"><i class="fa fa-check"></i><b>19.3.7</b> Sensitivity analyses</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="MethodValidity.html"><a href="MethodValidity.html#ohdsi-methods-benchmark"><i class="fa fa-check"></i><b>19.4</b> OHDSI Methods Benchmark</a></li>
<li class="chapter" data-level="19.5" data-path="MethodValidity.html"><a href="MethodValidity.html#summary-11"><i class="fa fa-check"></i><b>19.5</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>V OHDSI Studies</b></span></li>
<li class="chapter" data-level="20" data-path="StudySteps.html"><a href="StudySteps.html"><i class="fa fa-check"></i><b>20</b> Study steps</a></li>
<li class="chapter" data-level="21" data-path="NetworkResearch.html"><a href="NetworkResearch.html"><i class="fa fa-check"></i><b>21</b> OHDSI Network Research</a><ul>
<li class="chapter" data-level="21.1" data-path="NetworkResearch.html"><a href="NetworkResearch.html#what-is-the-ohdsi-research-network"><i class="fa fa-check"></i><b>21.1</b> What is the OHDSI Research Network?</a></li>
<li class="chapter" data-level="21.2" data-path="NetworkResearch.html"><a href="NetworkResearch.html#what-is-an-ohdsi-network-study"><i class="fa fa-check"></i><b>21.2</b> What is an OHDSI Network Study?</a></li>
<li class="chapter" data-level="21.3" data-path="NetworkResearch.html"><a href="NetworkResearch.html#executing-an-ohdsi-network-study"><i class="fa fa-check"></i><b>21.3</b> Executing an OHDSI Network Study</a><ul>
<li class="chapter" data-level="21.3.1" data-path="NetworkResearch.html"><a href="NetworkResearch.html#study-feasibility-and-design"><i class="fa fa-check"></i><b>21.3.1</b> Study Feasibility and Design</a></li>
<li class="chapter" data-level="21.3.2" data-path="NetworkResearch.html"><a href="NetworkResearch.html#study-execution"><i class="fa fa-check"></i><b>21.3.2</b> Study Execution</a></li>
<li class="chapter" data-level="21.3.3" data-path="NetworkResearch.html"><a href="NetworkResearch.html#results-dissemination-and-publication"><i class="fa fa-check"></i><b>21.3.3</b> Results Dissemination and Publication</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="NetworkResearch.html"><a href="NetworkResearch.html#types-of-network-studies"><i class="fa fa-check"></i><b>21.4</b> Types of Network Studies</a></li>
<li class="chapter" data-level="21.5" data-path="NetworkResearch.html"><a href="NetworkResearch.html#forward-looking-using-network-study-automation"><i class="fa fa-check"></i><b>21.5</b> Forward Looking: Using Network Study Automation</a></li>
<li class="chapter" data-level="21.6" data-path="NetworkResearch.html"><a href="NetworkResearch.html#best-practices-for-network-research"><i class="fa fa-check"></i><b>21.6</b> Best Practices for Network Research</a></li>
<li class="chapter" data-level="21.7" data-path="NetworkResearch.html"><a href="NetworkResearch.html#example-legend---hypertension"><i class="fa fa-check"></i><b>21.7</b> Example: LEGEND - Hypertension</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="Glossary.html"><a href="Glossary.html"><i class="fa fa-check"></i><b>A</b> Glossary</a></li>
<li class="chapter" data-level="B" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html"><i class="fa fa-check"></i><b>B</b> Cohort definitions</a><ul>
<li class="chapter" data-level="B.1" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#AceInhibitors"><i class="fa fa-check"></i><b>B.1</b> ACE inhibitors</a></li>
<li class="chapter" data-level="B.2" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#AceInhibitorsMono"><i class="fa fa-check"></i><b>B.2</b> New users of ACE inhibitors monotherapy</a></li>
<li class="chapter" data-level="B.3" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#Ami"><i class="fa fa-check"></i><b>B.3</b> Acute myocardial infarction (AMI)</a></li>
<li class="chapter" data-level="B.4" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#Angioedema"><i class="fa fa-check"></i><b>B.4</b> Angioedema</a></li>
<li class="chapter" data-level="B.5" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#ThiazidesMono"><i class="fa fa-check"></i><b>B.5</b> New users of Thiazide-like diuretics monotherapy</a></li>
<li class="chapter" data-level="B.6" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#HTN1yrFO"><i class="fa fa-check"></i><b>B.6</b> Patients initiating first-line therapy for hypertension</a></li>
<li class="chapter" data-level="B.7" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#HTN3yrFO"><i class="fa fa-check"></i><b>B.7</b> Patients initiating first-line therapy for hypertension with &gt;3 yr follow-up</a></li>
<li class="chapter" data-level="B.8" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#ACEiUse"><i class="fa fa-check"></i><b>B.8</b> ACE inhibitor use</a></li>
<li class="chapter" data-level="B.9" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#ARBUse"><i class="fa fa-check"></i><b>B.9</b> Angiotensin receptor blocker (ARB) use</a></li>
<li class="chapter" data-level="B.10" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#THZUse"><i class="fa fa-check"></i><b>B.10</b> Thiazide or thiazide-like diuretic use</a></li>
<li class="chapter" data-level="B.11" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#dCCBUse"><i class="fa fa-check"></i><b>B.11</b> dihydropyridine Calcium Channel Blocker (dCCB) use</a></li>
<li class="chapter" data-level="B.12" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#ndCCBUse"><i class="fa fa-check"></i><b>B.12</b> non-dihydropyridine Calcium Channel Blocker (ndCCB) use</a></li>
<li class="chapter" data-level="B.13" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#BBUse"><i class="fa fa-check"></i><b>B.13</b> beta blocker use</a></li>
<li class="chapter" data-level="B.14" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#DLoopUse"><i class="fa fa-check"></i><b>B.14</b> Diuretic-loop use</a></li>
<li class="chapter" data-level="B.15" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#DPUse"><i class="fa fa-check"></i><b>B.15</b> Diuretic-potassium sparing use</a></li>
<li class="chapter" data-level="B.16" data-path="CohortDefinitions.html"><a href="CohortDefinitions.html#A1BUse"><i class="fa fa-check"></i><b>B.16</b> alpha-1 blocker use</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="NegativeControlsAppendix.html"><a href="NegativeControlsAppendix.html"><i class="fa fa-check"></i><b>C</b> Negative controls</a><ul>
<li class="chapter" data-level="C.1" data-path="NegativeControlsAppendix.html"><a href="NegativeControlsAppendix.html#AceiThzNsc"><i class="fa fa-check"></i><b>C.1</b> ACEi and THZ</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="SuggestedAnswers.html"><a href="SuggestedAnswers.html"><i class="fa fa-check"></i><b>D</b> Suggested Answers</a><ul>
<li class="chapter" data-level="D.1" data-path="SuggestedAnswers.html"><a href="SuggestedAnswers.html#SqlAndRanswers"><i class="fa fa-check"></i><b>D.1</b> SQL and R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Book of OHDSI</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="PatientLevelPrediction" class="section level1">
<h1><span class="header-section-number">Chapter 14</span> Patient Level Prediction</h1>
<p><em>Chapter leads: Peter Rijnbeek &amp; Jenna Reps</em></p>
<p>Clinical decision making is a complicated task in which the clinician has to infer a diagnosis or treatment pathway based on the available medical history of the patient and the current clinical guidelines. Clinical prediction models have been developed to support this decision-making process and are used in clinical practice in a wide spectrum of specialties. These models predict a diagnostic or prognostic outcome based on a combination of patient characteristics, e.g.demographic information, disease history, treatment history.</p>
<p>The number of publications describing clinical prediction models has increased strongly over the last 10 years. Most currently-used models are estimated using small datasets and consider only a small set of patient characteristics. This low sample size, and thus low statistical power, forces the data analyst to make strong modelling assumptions. The selection of the limited set of patient characteristics is strongly guided by the expert knowledge at hand. This contrasts sharply with the reality of modern medicine wherein patients generate a rich digital trail, which is well beyond the power of any medical practitioner to fully assimilate. Presently, health care is generating a huge amount of patient-specific information stored in Electronic Health Records (EHRs). This includes structured data in the form of diagnose, medication, laboratory test results, and unstructured data contained in clinical narratives. It is unknown how much predictive accuracy can be gained by leveraging the large amount of data originating from the complete EHR of a patient.</p>
<p>Advances in machine learning for large dataset analysis have led to increased interest in applying patient-level prediction on this type of data. However, many published efforts in patient-level prediction do not follow the model development guidelines, fail to perform extensive external validation, or provide insufficient model details which limits the ability of independent researchers to reproduce the models and perform external validation. This makes it hard to fairly evaluate the predictive performance of the models and reduces the likelihood of the model being used appropriately in clinical practice. To improve standards, several papers have been written detailing guidelines for best practices in developing and reporting prediction models. For example, the Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD) statement<a href="references.html#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a> provides clear recommendations for reporting prediction model development and validation and addresses some of the concerns related to transparency.</p>
<p>Massive-scale, patient-specific predictive modeling has become reality due to OHDSI, where the common data model (CDM) allows for uniform and transparent analysis at an unprecedented scale. The databases available in the CDM contain rich data to build highly predictive large-scale models and also provide immediate opportunity to serve large communities of patients who are in most need of improved quality of care. Such models can inform truly personalized medical care leading hopefully to sharply improved patient outcomes.</p>
<p>In this chapter we describe OHDSIs standardized framework for patient-level prediction, <span class="citation">(Reps et al. <a href="#ref-reps2018" role="doc-biblioref">2018</a>)</span> and discuss the <a href="https://ohdsi.github.io/PatientLevelPrediction/">PatientLevelPrediction</a> R package that implements established best practices. We start with providing the necessary theory behind the development and evaluation of patient-level prediction and provide a high-level overview of the implemented machine learning algorithms. We then discuss an example prediction problem and provide step-by-step guidance on its definition and implementation using ATLAS or custom R code. Finally, we review two Shiny apps that allow viewing the study outputs. One app explores a single prediction model, while the other explores many models at once.</p>
<div id="the-prediction-problem" class="section level2">
<h2><span class="header-section-number">14.1</span> The prediction problem</h2>
<p>Figure <a href="PatientLevelPrediction.html#fig:figure1">14.1</a>, illustrates the prediction problem we address. Among a population at risk, we aim to predict which patients at a defined moment in time (t = 0) will experience some outcome during a time-at-risk. Prediction is done using only information about the patients in an observation window prior to that moment in time.</p>
<div class="figure"><span id="fig:figure1"></span>
<img src="images/PatientLevelPrediction/Figure1.png" alt="The prediction problem." width="100%" />
<p class="caption">
Figure 14.1: The prediction problem.
</p>
</div>
<p>As shown in Table <a href="PatientLevelPrediction.html#tab:plpDesign">14.1</a>, to define a prediction problem we have to define t=0 by a target cohort, the outcome we like to predict by an outcome cohort, and the time-at-risk. We define the standard prediction question as:</p>
<blockquote>
<p>Among <em>[target cohort definition]</em>, who will go on to have <em>[outcome cohort definition]</em> within <em>[time-at-risk period]</em>?</p>
</blockquote>
<p>Furthermore, we have to make design choices for the model we like to develop, and determine the observational datasets to perform internal and external validation.</p>
<table>
<caption><span id="tab:plpDesign">Table 14.1: </span> Main design choices in a prediction design.</caption>
<colgroup>
<col width="24%" />
<col width="76%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Choice</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Target cohort</td>
<td align="left">A cohort for whom we wish to predict</td>
</tr>
<tr class="even">
<td align="left">Outcome cohort</td>
<td align="left">A cohort representing the outcome we wish to predict</td>
</tr>
<tr class="odd">
<td align="left">Time-at-risk</td>
<td align="left">For what time relative to t=0 do we want to make the prediction?</td>
</tr>
<tr class="even">
<td align="left">Model</td>
<td align="left">What algorithms using which parameters do we want use, and what predictor variables do we want to include?</td>
</tr>
</tbody>
</table>
<p>This conceptual framework works for all type of prediction problems, for example:</p>
<ul>
<li>Disease onset and progression
<ul>
<li><strong>Structure</strong>: Among patients who are newly diagnosed with <em>[a disease]</em>, who will go on to have <em>[another disease or complication]</em> within <em>[time horizon from diagnosis]</em>?</li>
<li><strong>Example</strong>: Among newly diagnosed atrial fibrillation patients, who will go on to have ischemic stroke in the next three years?</li>
</ul></li>
<li>Treatment choice
<ul>
<li><strong>Structure</strong>: Among patients with <em>[indicated disease]</em> who are treated with either <em>[treatment 1]</em> or <em>[treatment 2]</em>, which patients were treated with <em>[treatment 1]</em>?</li>
<li><strong>Example</strong>: Among patients with atrial fibrillation who took either warfarin or rivaroxaban, which patients gets warfarin? (e.g.for a propensity model)</li>
</ul></li>
<li>Treatment response
<ul>
<li><strong>Structure</strong>: Among new users of <em>[a treatment]</em>, who will experience <em>[some effect]</em> in <em>[time window]</em> ?</li>
<li><strong>Example</strong>: Which patients with diabetes who start on metformin stay on metformin for three years?</li>
</ul></li>
<li>Treatment safety
<ul>
<li><strong>Structure</strong>: Among new users of <em>[a treatment]</em>, who will experience <em>[adverse event]</em> in <em>[time window]</em>?</li>
<li><strong>Example</strong>: Among new users of warfarin, who will have a gastrointestinal bleed in one year?</li>
</ul></li>
<li>Treatment adherence
<ul>
<li><strong>Structure</strong>: Among new users of <em>[a treatment]</em>, who will achieve <em>[adherence metric]</em> at <em>[time window]</em>?</li>
<li><strong>Example</strong>: Which patients with diabetes who start on metformin achieve &gt;=80% proportion of days covered at one year?</li>
</ul></li>
</ul>
</div>
<div id="data-extraction-2" class="section level2">
<h2><span class="header-section-number">14.2</span> Data extraction</h2>
<p>The observational data we use in OHDSI consist of time-stamped records of interactions of the patient with the healthcare system, as well as anonymized patient details such as gender and year of birth, stored in the CDM (Chapter <a href="CommonDataModel.html#CommonDataModel">5</a>). To use this information in a prediction problem, we must convert this data into two datasets:</p>
<ol style="list-style-type: decimal">
<li>A set of <strong>covariates</strong> (also referred to as features or independent variables). These describe the characteristics of the patients. Covariates can include age, gender, presence of specific condition and exposure codes in a patients record, etc.</li>
<li>A set describing the <strong>outcome status</strong> (also referred to as the labels or classes). Did a patient experience the outcome of interest in the time-at-risk?</li>
</ol>
<p>When creating a predictive model we use a process know as supervised learning - a form of machine learning - to infer the relationship between the covariates and the outcome status. Once the model is created, we can apply it to patients where we know their characteristics (their covariates), but do not know their outcome status, to create a prediction.</p>
<p>Converting the data in the CDM to these two datasets requires selecting a set of people, and for these people selecting a specific date. We will refer to this date as the index date. Data prior to (and on) the index date is used to construct the covariates. Covariates are typically constructed using the <a href="https://ohdsi.github.io/FeatureExtraction/">FeatureExtraction</a> package, described in more detail in Chapter <a href="Characterization.html#Characterization">12</a>. Data after (or on) the index date is used to construct the outcome status. The group of people and their index date are defined by the <strong>target cohort</strong>. The outcome status is determined by the <strong>time-at-risk</strong>, which is usually defined relative to the target cohort start and end date, and the <strong>outcome cohort</strong>; If the outcome occurs within the time-at-risk, the outcome status is positive.</p>
<div id="data-extraction-example" class="section level3">
<h3><span class="header-section-number">14.2.1</span> Data extraction example</h3>
<p>Table <a href="PatientLevelPrediction.html#tab:plpExampleCohorts">14.2</a> shows an example COHORT table with two cohorts. The cohort with cohort definition ID 1 is the target cohort (e.g.people recently diagnosed with atrial fibrillation). Cohort definition ID 2 implies the outcome cohort (e.g.stroke).</p>
<table>
<caption><span id="tab:plpExampleCohorts">Table 14.2: </span> Example COHORT table. For simplicity the cohort_end_date has been omitted.</caption>
<thead>
<tr class="header">
<th align="center">cohort_definition_id</th>
<th align="center">subject_id</th>
<th align="center">cohort_start_date</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">2000-06-01</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2001-06-01</td>
</tr>
<tr class="odd">
<td align="center">2</td>
<td align="center">2</td>
<td align="center">2001-07-01</td>
</tr>
</tbody>
</table>
<p>Table <a href="PatientLevelPrediction.html#tab:plpExampleConditions">14.3</a> provides an example CONDITION_OCCURRENCE table. Concept ID <a href="http://athena.ohdsi.org/search-terms/terms/320128">320128</a> refers to Essential hypertension.</p>
<table>
<caption><span id="tab:plpExampleConditions">Table 14.3: </span> Example CONDITION_OCCURRENCE table. For simplicity only three columns are shown.</caption>
<thead>
<tr class="header">
<th align="center">person_id</th>
<th align="center">condition_concept_id</th>
<th align="center">condition_start_date</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">320128</td>
<td align="center">2000-10-01</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">320128</td>
<td align="center">2001-05-01</td>
</tr>
</tbody>
</table>
<p>Based on this example data, and assuming the time at risk is the year following the index date (the target cohort start date), we can construct the covariates and the outcome status. A covariate indicating Essential hypertension in the year prior will have the value 0 (not present) for person ID 1 (the condition occurred <em>after</em> the index date), and the value 1 (present) for person ID 2. Similarly, the outcome status will be 0 for person ID 1 (this person had no entry in the outcome cohort), and 1 for person ID 2 (the outcome occurred within a year following the index date).</p>
</div>
<div id="missingness" class="section level3">
<h3><span class="header-section-number">14.2.2</span> Missingness</h3>
<p>Observational healthcare data rarely reflects whether data is missing. In the prior example, we simply observed the person with ID 1 had no essential hypertension occurrence prior to the index date. This could be because the condition was not present at that time, or because it was not recorded. There is no way to distinguish between the two. For machine learning this does not matter as much as one might think. If a covariate is predictive of the outcome status it will end up in the model, else not. However, we should be aware that our interpretation of covariates should be nuanced: it is not the actual condition that is the predictor, but rather the recording of the condition in the data.</p>
</div>
</div>
<div id="modelFitting" class="section level2">
<h2><span class="header-section-number">14.3</span> Fitting the model</h2>
<p>When fitting a model (using supervised learning) we are trying to establish the relationship between the covariates and the observed outcome status, so that if we do not yet know the outcome status, we can predict it. If we consider the situation where we have two covariates (for example systolic and diastolic blood pressure), then we can represent each patient as a plot in two dimensional space as shown in Figure <a href="PatientLevelPrediction.html#fig:decisionBoundary">14.2</a>. The shape of a data points corresponds to the patients outcome status (e.g.stroke). The idea of supervised learning is to generalize what we see and fill in where there are no current data points. A supervised learning model will try to partition the space via a decision boundary that aims to minimize the cases where the outcome status does not match the models prediction. Different supervised learning techniques lead to different decision boundaries and there are often hyper-parameters that can impact the complexity of the decision boundary.</p>
<div class="figure" style="text-align: center"><span id="fig:decisionBoundary"></span>
<img src="images/PatientLevelPrediction/decisionBoundary.png" alt="Decision boundary." width="80%" />
<p class="caption">
Figure 14.2: Decision boundary.
</p>
</div>
<p>In Figure <a href="PatientLevelPrediction.html#fig:decisionBoundary">14.2</a> we can see three different decision boundaries. The boundaries are used to infer the outcome status of any new data point. If a new data point falls into the shaded area then the model will predict has outcome, otherwise it will predict no outcome. Ideally a decision boundary should perfectly partition the two classes. However, generalizability is an issue, as complex models can overfit the data; boundaries may be fit too closely and may not work for new data. For example, if the data contains noise, with mislabelled or incorrectly positioned data points, we would not want to fit our model to that noise. We may pref to define a decision boundary that does not perfectly discriminate those with known outcome status, to get a model that better predicts for now, previously unseen patients. We want a model that appears to partition the labelled data well but is also as simple as possible. Techniques such as regularization aim to maximize model performance on the data with known outcome status while minimizing complexity. Complexity can also be controlled by picking classifier hyper-parameters such that a simpler decision boundary is used.</p>
<p>Another way to think about supervised learning is finding a function that maps from a patients covariates to their label: <span class="math inline">\(p(outcome\ status = 1|covariates) = f(covariates)\)</span>. Each supervised learning algorithm has a different way to learn the mapping function and the no free lunch theorem states that no one algorithm is always going to outperform the others. The performance of each type of supervised learning algorithm depends on how the labelled data points are distributed in space. Therefore we recommend trying multiple supervised learning techniques with various hyper-parameter settings when developing patient-level prediction models.</p>
<p>The following algorithms are available in the <a href="https://ohdsi.github.io/PatientLevelPrediction/">PatientLevelPrediction</a> package:</p>
<div id="regularized-logistic-regression" class="section level3">
<h3><span class="header-section-number">14.3.1</span> Regularized logistic regression</h3>
<p>LASSO (least absolute shrinkage and selection operator) logistic regression belongs to the family of generalized linear models, where a linear combination of the variables is learned and finally a logistic function maps the linear combination to a value between 0 and 1. The LASSO regularization adds a cost based on model complexity to the objective function when training the model. This cost is the sum of the absolute values of the linear combination of the coefficients. The model automatically performs feature selection by minimizing this cost. We use the <a href="https://ohdsi.github.io/Cyclops/">Cyclops</a> (Cyclic coordinate descent for logistic, Poisson and survival analysis) package to perform large-scale regularized logistic regression.</p>
<table>
<caption><span id="tab:lassoParameters">Table 14.4: </span> Hyper-parameters for the regularized logistic regression.</caption>
<thead>
<tr class="header">
<th align="left">Parameter</th>
<th align="left">Description</th>
<th align="left">Typical values</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Starting variance</td>
<td align="left">The starting variance of the prior distribution.</td>
<td align="left">0.1</td>
</tr>
</tbody>
</table>
<p>Note that the variance is optimized by maximizing the out-of-sample likelihood in a cross-validation, so the starting variance has little impact on the performance of the resulting model. However, picking a starting variance that is too far from the optimal value may lead to long fitting time.</p>
</div>
<div id="gradient-boosting-machines" class="section level3">
<h3><span class="header-section-number">14.3.2</span> Gradient boosting machines</h3>
<p>Gradient boosting machines is a boosting ensemble technique and in our framework it combines multiple decision trees. Boosting works by iteratively adding decision trees but adds more weight to the data-points that are misclassified by prior decision trees in the cost function when training the next tree. We use Extreme Gradient Boosting, which is an efficient implementation of the gradient boosting framework implemented in the xgboost R package available from CRAN.</p>
<table>
<caption><span id="tab:gbmParameters">Table 14.5: </span> Hyper-parameters for gradient boosting machines.</caption>
<thead>
<tr class="header">
<th align="left">Parameter</th>
<th align="left">Description</th>
<th align="left">Typical values</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">mtry</td>
<td align="left">Number of features in each tree</td>
<td align="left">?</td>
</tr>
<tr class="even">
<td align="left">ntree</td>
<td align="left">Number of trees</td>
<td align="left">?</td>
</tr>
<tr class="odd">
<td align="left">maxDepth</td>
<td align="left">Max levels in a tree</td>
<td align="left">?</td>
</tr>
<tr class="even">
<td align="left">minRows</td>
<td align="left">Min data points in a node</td>
<td align="left">?</td>
</tr>
<tr class="odd">
<td align="left">balance</td>
<td align="left">Should class sizes be balanced?</td>
<td align="left">?</td>
</tr>
</tbody>
</table>
</div>
<div id="random-forest" class="section level3">
<h3><span class="header-section-number">14.3.3</span> Random forest</h3>
<p>Random forest is a bagging ensemble technique that combines multiple decision trees. The idea behind bagging is to reduce the likelihood of overfitting, by using weak classifiers, but combining multiple diverse weak classifiers into a strong classifier. Random forest accomplishes this by training multiple decision trees but only using a subset of the variables in each tree and the subset of variables differ between trees. Our packages uses the sklearn implementation of Random Forest in Python.</p>
<table>
<caption><span id="tab:randomForestParameters">Table 14.6: </span> Hyper-parameters for random forests.</caption>
<thead>
<tr class="header">
<th align="left">Parameter</th>
<th align="left">Description</th>
<th align="left">Typical values</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">mtry</td>
<td align="left">Number of features in each tree</td>
<td align="left">?</td>
</tr>
<tr class="even">
<td align="left">ntree</td>
<td align="left">Number of trees</td>
<td align="left">?</td>
</tr>
<tr class="odd">
<td align="left">maxDepth</td>
<td align="left">Max levels in a tree</td>
<td align="left">?</td>
</tr>
<tr class="even">
<td align="left">minRows</td>
<td align="left">Min data points in a node</td>
<td align="left">?</td>
</tr>
<tr class="odd">
<td align="left">balance</td>
<td align="left">Should class sizes be balanced?</td>
<td align="left">?</td>
</tr>
</tbody>
</table>
</div>
<div id="k-nearest-neighbors" class="section level3">
<h3><span class="header-section-number">14.3.4</span> K-nearest neighbors</h3>
<p>K-nearest neighbors (KNN) is an algorithm that uses some distance metric to find the K closest labelled data-points to a new unlabelled data-point. The prediction of the new data-points is then the most prevalent class of the K-nearest labelled data-points. There is a sharing limitation of KNN, as the model requires labelled data to perform the prediction on new data, and it is often not possible to share this data across data sites. We included the <a href="https://github.com/OHDSI/BigKnn">BigKnn</a> package developed in OHDSI which is a large scale KNN classifier.</p>
<table>
<caption><span id="tab:knnParameters">Table 14.7: </span> Hyper-parameters for K-nearest neighbors.</caption>
<thead>
<tr class="header">
<th align="left">Parameter</th>
<th align="left">Description</th>
<th align="left">Typical values</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">k</td>
<td align="left">Number of neighbors</td>
<td align="left">?</td>
</tr>
<tr class="even">
<td align="left">weighted</td>
<td align="left">Weight by inverse frequency?</td>
<td align="left">?</td>
</tr>
</tbody>
</table>
</div>
<div id="naive-bayes" class="section level3">
<h3><span class="header-section-number">14.3.5</span> Naive Bayes</h3>
<p>The Naive Bayes algorithm applies the Bayes theorem with the naive assumption of conditional independence between every pair of features given the value of the class variable. Based on the likelihood the data belongs to a class and the prior distribution of the class, a posterior distribution is obtained. Naive Bayes has no hyper-parameters.</p>
</div>
<div id="adaboost" class="section level3">
<h3><span class="header-section-number">14.3.6</span> AdaBoost</h3>
<p>AdaBoost is a boosting ensemble technique. Boosting works by iteratively adding classifiers but adds more weight to the data-points that are misclassified by prior classifiers in the cost function when training the next classifier. We use the sklearn AdaboostClassifier implementation in Python.</p>
<table>
<caption><span id="tab:adaBoostParameters">Table 14.8: </span> Hyper-parameters for AdaBoost.</caption>
<colgroup>
<col width="25%" />
<col width="33%" />
<col width="41%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Parameter</th>
<th align="left">Description</th>
<th align="left">Typical values</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">nEstimators</td>
<td align="left">The maximum number of estimators at which boosting is terminated</td>
<td align="left">?</td>
</tr>
<tr class="even">
<td align="left">learningRate</td>
<td align="left">Learning rate shrinks the contribution of each classifier by learning_rate. There is a trade-off between learningRate and nEstimators</td>
<td align="left">?</td>
</tr>
</tbody>
</table>
</div>
<div id="decision-tree" class="section level3">
<h3><span class="header-section-number">14.3.7</span> Decision Tree</h3>
<p>A decision tree is a classifier that partitions the variable space using individual tests selected using a greedy approach. It aims to find partitions that have the highest information gain to separate the classes. The decision tree can easily overfit by enabling a large number of partitions (tree depth) and often needs some regularization (e.g., pruning or specifying hyper-parameters that limit the complexity of the model). We use the sklearn DecisionTreeClassifier implementation in Python.</p>
<table>
<caption><span id="tab:decisionTreeParameters">Table 14.9: </span> Hyper-parameters for decision trees.</caption>
<thead>
<tr class="header">
<th align="left">Parameter</th>
<th align="left">Description</th>
<th align="left">Typical values</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">maxDepth</td>
<td align="left">The maximum depth of the tree</td>
<td align="left">?</td>
</tr>
<tr class="even">
<td align="left">minSamplesSplit</td>
<td align="left">?</td>
<td align="left">?</td>
</tr>
<tr class="odd">
<td align="left">minSamplesLeaf</td>
<td align="left">?</td>
<td align="left">?</td>
</tr>
<tr class="even">
<td align="left">minImpuritySplit</td>
<td align="left">?</td>
<td align="left">?</td>
</tr>
<tr class="odd">
<td align="left">classWeight</td>
<td align="left">Balance" or None</td>
<td align="left">?</td>
</tr>
</tbody>
</table>
</div>
<div id="multilayer-perceptron" class="section level3">
<h3><span class="header-section-number">14.3.8</span> Multilayer Perceptron</h3>
<p>Neural networks containing multiple layers of nodes that weight their inputs using a non-linear function. The first layer is the input layer, the last layer is the output layer, and in between are the hidden layers. Neural networks are generally trained using back-propagation, meaning the training input is propagated forward through the network to produce an output, the error between the output and the outcome status is computed, and this error is propagated backwards through the network to update the linear function weights.</p>
<table>
<caption><span id="tab:mpParameters">Table 14.10: </span> Hyper-parameters for Multilayer Perceptrons.</caption>
<thead>
<tr class="header">
<th align="left">Parameter</th>
<th align="left">Description</th>
<th align="left">Typical values</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">size</td>
<td align="left">The number of hidden nodes</td>
<td align="left">?</td>
</tr>
<tr class="even">
<td align="left">alpha</td>
<td align="left">The l2 regularization)</td>
<td align="left">?</td>
</tr>
</tbody>
</table>
</div>
<div id="deep-learning" class="section level3">
<h3><span class="header-section-number">14.3.9</span> Deep Learning</h3>
<p>Deep learning such as deep nets, convolutional neural networks or recurrent neural networks are similar to Multilayer Perceptrons but have multiple hidden layers that aim to learn latent representations useful for prediction. In a separate <a href="https://ohdsi.github.io/PatientLevelPrediction/articles/BuildingDeepLearningModels.html">vignette</a> in the <a href="https://ohdsi.github.io/PatientLevelPrediction/">PatientLevelPrediction</a> package we describe these models and hyper-parameters in more detail.</p>
</div>
<div id="other-algorithms" class="section level3">
<h3><span class="header-section-number">14.3.10</span> Other algorithms</h3>
<p>Other algorithms can be added to the patient-level prediction framework. This is out-of-scope for this chapter. Details can be found in the <a href="https://ohdsi.github.io/PatientLevelPrediction/articles/AddingCustomAlgorithms.html">Adding Custom Patient-Level Prediction Algorithms vignette</a> in the <a href="https://ohdsi.github.io/PatientLevelPrediction/">PatientLevelPrediction</a> package.</p>
</div>
</div>
<div id="evaluating-prediction-models" class="section level2">
<h2><span class="header-section-number">14.4</span> Evaluating prediction models</h2>
<div id="evaluation-types" class="section level3">
<h3><span class="header-section-number">14.4.1</span> Evaluation Types</h3>
<p>We can evaluate a prediction model by measuring the agreement between the models prediction and observed outcome status, which means we need data where the outcome status is known.</p>

<div class="rmdimportant">
For evaluation we must use a different dataset than was used to develop the model, or else we run the risk of favoring models that are over-fitted (see Section <a href="PatientLevelPrediction.html#modelFitting">14.3</a>) and may not perform well for new patients.
</div>

<p>We distinguish between</p>
<ul>
<li><strong>Internal validation</strong>: Using different sets of data extracted from the same database to develop and evaluate the model.</li>
<li><strong>External validation</strong>: Developing the model in one database, and evaluating in another database.</li>
</ul>
<p>There are two ways to perform internal validation:</p>
<ul>
<li>A <strong>holdout set</strong> approach splits the labelled data into two independent sets: a train set and a test set (the hold out set). The train set is used to learn the model and the test set is used to evaluate it. We can simply divide our patients randomly into a train and test set, or we may choose to:
<ul>
<li>Split the data based on time (temporal validation), for example training on data before a specific date, and evaluating on data after that date. This may inform us on whether our model generalizes to different time periods.</li>
<li>Split the data based on geographic location (spatial validation).</li>
</ul></li>
<li><strong>Cross validation</strong> is useful when the data are limited. The data is split into <span class="math inline">\(n\)</span> equally-sized sets, where <span class="math inline">\(n\)</span> needs to be prespecified (e.g.<span class="math inline">\(n=10\)</span>). For each of these sets a model is trained on all data except the data in that set, and used to generate predictions for the held-out set. In this way, all data is used once to evaluate the model-building algorithm. In the patient-level prediction framework we use cross validation to pick the optimal hyper-parameters.</li>
</ul>
<p>Note that some may consider bootstrapping to be another approach to internal validation, which is often used specifically to express the uncertainty around a models prediction, typically as confidence intervals. We currently do not use bootstrapping in the patient-level prediction framework. TODO: maybe elaborate on this.</p>
<p>External validation is when a model trained in one database is validated on a data from another database. This is important as different databases may represent different patient populations, but also perhaps different healthcare systems and different data-capture processes. External validation can therefore inform us on how well a model will perform outside of the settings it was developed in.</p>
</div>
<div id="performance" class="section level3">
<h3><span class="header-section-number">14.4.2</span> Performance Metrics</h3>
<p><strong>Threshold measures</strong></p>
<p>A prediction model assigns a value between 0 and 1 for each patient corresponding to the risk of the patient having the outcome during the time at risk. A value of 0 means 0% risk, a value of 0.5 means 50% risk and a value of 1 means 100% risk. Common metrics such as accuracy, sensitivity, specificity, positive predictive value can be calculated by first specifying a threshold that is used to classify patients as having the outcome or not during the time at risk. For example, given Table <a href="PatientLevelPrediction.html#tab:tabletheorytab">14.11</a>, if we set the threshold as 0.5, the patients 1, 3, 7 and 10 have a predicted risk greater than or equal to the threshold of 0.5 so they would be predicted to have the outcome. All other patients had a predicted risk less than 0.5, so would be predicted to not have the outcome.</p>
<table>
<caption><span id="tab:tabletheorytab">Table 14.11: </span> Example of using a threshold on the predicted probability.</caption>
<colgroup>
<col width="18%" />
<col width="22%" />
<col width="22%" />
<col width="22%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Patient ID</th>
<th align="center">Predicted risk</th>
<th align="center">Predicted class at 0.5 threshold</th>
<th align="center">Has outcome during time-at-risk</th>
<th align="center">Type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">0.8</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">TP</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">0.1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">TN</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">0.7</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">FP</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">TN</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">0.05</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">TN</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">0.1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">TN</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">0.9</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">TP</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">0.2</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">FN</td>
</tr>
<tr class="odd">
<td align="center">9</td>
<td align="center">0.3</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">TN</td>
</tr>
<tr class="even">
<td align="center">10</td>
<td align="center">0.5</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">FP</td>
</tr>
</tbody>
</table>
<p>If a patient is predicted to have the outcome and has the outcome (during the time-at-risk) then this is called as a true positive (TP). If a patient is predicted to have the outcome but does not have the outcomethen this is called a false positive (FP). If a patient is predicted to not have the outcome and does not have the outcome then this is called a true negative (TN). Finally, if a patient is predicted to not have the outcome but does have the outcome then this is called a false negative (FN).</p>
<p>The following threshold based metrics are:</p>
<ul>
<li>accuracy: <span class="math inline">\((TP+TN)/(TP+TN+FP+FN)\)</span></li>
<li>sensitivity: <span class="math inline">\(TP/(TP+FN)\)</span></li>
<li>specificity: <span class="math inline">\(TN/(TN+FP)\)</span></li>
<li>positive predictive value: <span class="math inline">\(TP/(TP+FP)\)</span></li>
</ul>
<p>Note that these values can either decrease or increase if the threshold is lowered. Lowering the threshold of a classifier may increase the denominator, by increasing the number of results returned. If the threshold was previously set too high, the new results may all be true positives, which will increase positive predictive value. If the previous threshold was about right or too low, further lowering the threshold will introduce false positives, decreasing positive predictive value. For sensitivity the denominator does not depend on the classifier threshold (<span class="math inline">\(TP+FN\)</span> is a constant). This means that lowering the classifier threshold may increase sensitivity, by increasing the number of true positive results. It is also possible that lowering the threshold may leave sensitivity unchanged, while the positive predictive value fluctuates.</p>
<p><strong>Discrimination</strong></p>
<p>Discrimination is the ability to assign a higher risk to patients who will experience the outcome during the time at risk. The Receiver Operating Characteristics (ROC) is determined by plotting 1  specificity on the x-axis and sensitivity on the y-axis at all possible thresholds. An example ROC plot is presented later in this chapter in Figure <a href="PatientLevelPrediction.html#fig:shinyROC">14.17</a>. The area under the receiver operating characteristic curve (AUC) gives an overall measure of discrimination where a value of 0.5 corresponds to randomly assigning the risk and a value of 1 means perfect discrimination. In reality, most prediction models obtain AUCs between 0.6-0.8.</p>
<p>For rare outcomes even a model with a high AUC may not be practical, because for every positive above a given threshold there could also be many negatives (i.e.the positive predictive value will be low). Depending on the severity of the outcome and cost (health risk and/or monetary) of some intervention, a high false positive rate may be impractical. When the outcome is rare another measure known as the area under the precision-recall curve (AUPRC) is therefore recommended. The AUPRC is the area under the line generated by plotting the sensitivity on the x-axis (also known as the recall) and the positive predictive value (also known as the precision) on the y-axis.</p>
<p>The AUC provides a way to determine how different the predicted risk distributions are between the patients who experience the outcome during the time at risk and those who do not. If the AUC is high, then the distributions will be mostly disjointed, whereas when there is a lot of overlap, the AUC will be closer to 0.5, see Figure <a href="PatientLevelPrediction.html#fig:figuretheoryroctheory">14.3</a>.</p>
<div class="figure"><span id="fig:figuretheoryroctheory"></span>
<img src="images/PatientLevelPrediction/theory/roctheory.png" alt="How the ROC plots are linked to discrimination. If the two classes have similar distributions of prediced risk, the ROC will be close to the diagonal, with AUC close to 0.5." width="100%" />
<p class="caption">
Figure 14.3: How the ROC plots are linked to discrimination. If the two classes have similar distributions of prediced risk, the ROC will be close to the diagonal, with AUC close to 0.5.
</p>
</div>
<p><strong>Calibration</strong></p>
<p>Calibration is the ability of the model to assign the correct risk. For example, if the model assigned one hundred patients a risk of 10% then ten of the patients should experience the outcome during the time at risk. If the model assigned 100 patients a risk of 80% then eighty of the patients should experience the outcome during the time at risk. The calibration is generally calculated by partitioning the patients into deciles based on the predicted risk and in each group calculating the mean predicted risk and the fraction of the patients who experienced the outcome during the time at risk. We then plot these ten points (predicted risk on the y-axis and observed risk on the x-axis) and see whether they fall on the x = y line, indicating the model is well calibrated. An example calibration plot is presented later in this chapter in Figure <a href="PatientLevelPrediction.html#fig:shinyCal">14.18</a>. We also fit a linear model using the points to calculate the intercept (which should be close to zero) and the gradient (which should be close to one). If the gradient is greater than one then the model is assigning a higher risk than the true risk and if the gradient is less than one the model is assigning a lower risk than the true risk.</p>
</div>
</div>
<div id="designing-a-patient-level-prediction-study" class="section level2">
<h2><span class="header-section-number">14.5</span> Designing a patient-level prediction Study</h2>
<p>In this section we will demonstrate how to design a prediction study. The first step is to clearly define the prediction problem. Interestingly, in many published papers the prediction problem is poorly defined, for example it is unclear how the index date (start of the target cohort) is defined. A poorly defined prediction problem does not allow for external validation by others let alone implementation in clinical practice. In the patient-level prediction framework we enforce proper specification of the prediction problem by requiring the key choices defined in Table <a href="PatientLevelPrediction.html#tab:plpDesign">14.1</a> to be explicitly defined. Here we will walk through this process using a treatment safety type prediction problem as an example.</p>
<div id="problem-definition-2" class="section level3">
<h3><span class="header-section-number">14.5.1</span> Problem definition</h3>
<p>Angioedema is a well known side-effect of ACE inhibitors, and the incidence of angioedema reported in the labeling for ACE inhibitors is in the range of 0.1% to 0.7% <span class="citation">(Byrd, Adam, and Brown <a href="#ref-byrd_2006" role="doc-biblioref">2006</a>)</span>. Monitoring patients for this adverse effect is important, because although angioedema is rare, it may be life-threatening, leading to respiratory arrest and death <span class="citation">(Norman et al. <a href="#ref-norman_2013" role="doc-biblioref">2013</a>)</span>. Further, if angioedema is not initially recognized, it may lead to extensive and expensive workups before it is identified as a cause <span class="citation">(Norman et al. <a href="#ref-norman_2013" role="doc-biblioref">2013</a>; Thompson and Frable <a href="#ref-thompson_1993" role="doc-biblioref">1993</a>)</span>. Other than the higher risk among African-American patients, there are no known predisposing factors for the development of ACE inhibitor related angioedema <span class="citation">(Byrd, Adam, and Brown <a href="#ref-byrd_2006" role="doc-biblioref">2006</a>)</span>. Most reactions occur within the first week or month of initial therapy and often within hours of the initial dose <span class="citation">(Cicardi et al. <a href="#ref-circardi_2004" role="doc-biblioref">2004</a>)</span>. However, some cases may occur years after therapy has begun <span class="citation">(OMara and OMara <a href="#ref-mara_1996" role="doc-biblioref">1996</a>)</span>. No diagnostic test is available that specifically identifies those at risk. If we could identify those at risk, doctors could act, for example by discontinuing the ACE inhibitor in favor of another hypertension drug.</p>
<p>We will apply the patient-level prediction framework to observational healthcare data to address the following patient-level prediction question:</p>
<blockquote>
<p>Among patients who have just started on an ACE inhibitor for the first time, who will experience angioedema in the following year?</p>
</blockquote>
</div>
<div id="study-population-definition" class="section level3">
<h3><span class="header-section-number">14.5.2</span> Study population definition</h3>
<p>The final study population in which we will develop our model is often a subset of the target cohort, because we may for example apply criteria that are dependent on the outcome, or we want to perform sensitivity analyses with sub-populations of the target cohort. For this we have to answer the following questions:</p>
<ul>
<li><p><em>What is the minimum amount of observation time we require before the start of the target cohort?</em> This choice could depend on the available patient time in the training data, but also on the time we expect to be available in the data sources we want to apply the model on in the future. The longer the minimum observation time, the more baseline history time is available for each person to use for feature extraction, but the fewer patients will qualify for analysis. Moreover, there could be clinical reasons to choose a short or longer look-back period. For our example, we will use a 365-day prior history as look-back period (washout period).</p></li>
<li><p><em>Can patients enter the target cohort multiple times?</em> In the target cohort definition, a person may qualify for the cohort multiple times during different spans of time, for example if they had different episodes of a disease or separate periods of exposure to a medical product. The cohort definition does not necessarily apply a restriction to only let the patients enter once, but in the context of a particular patient-level prediction problem we may want to restrict the cohort to the first qualifying episode. In our example, a person can only enter the target cohort once since our criteria was based on first use of an ACE inhibitor.</p></li>
<li><p><em>Do we allow persons to enter the cohort if they experienced the outcome before?</em> Do we allow persons to enter the target cohort if they experienced the outcome before qualifying for the target cohort? Depending on the particular patient-level prediction problem, there may be a desire to predict incident first occurrence of an outcome, in which case patients who have previously experienced the outcome are not at risk for having a first occurrence and therefore should be excluded from the target cohort. In other circumstances, there may be a desire to predict prevalent episodes, whereby patients with prior outcomes can be included in the analysis and the prior outcome itself can be a predictor of future outcomes. For our prediction example, we will choose not to include those with prior angioedema.</p></li>
<li><p><em>How do we define the period in which we will predict our outcome relative to the target cohort start?</em> We have to make two decisions to answer this question. First, does the time-at-risk window start at the date of the start of the target cohort or later? Arguments to make it start later could be that we want to avoid outcomes that were entered late in the record that actually occurred before the start of the target cohort or we want to leave a gap where interventions to prevent the outcome could theoretically be implemented. Second, we need to define the time-at-risk by setting the risk window end, as some specification of days offset relative to the target cohort start or end dates. For our problem we will predict in a time-at-risk window starting 1 day after the start of the target cohort up to 365 days later.</p></li>
<li><p><em>Do we require a minimum amount of time-at-risk?</em> We have to decide if we want to include patients that did not experience the outcome but did leave the database earlier than the end of our time-at-risk period. These patients may experience the outcome when we no longer observe them. For our prediction problem we decide to answer this question with yes, requiring a minimum time-at-risk for that reason. Furthermore, we have to decide if this constraint also applies to persons who experienced the outcome or we will include all persons with the outcome irrespective of their total time at risk. For example, if the outcome is death, then persons with the outcome are likely censored before the full time-at-risk period is complete.</p></li>
</ul>
</div>
<div id="model-development-settings" class="section level3">
<h3><span class="header-section-number">14.5.3</span> Model development settings</h3>
<p>To develop the prediction model we have to decide which algorithm(s) we like to train. We see the selection of the best algorithm for a certain prediction problem as an empirical question, i.e.we prefer to let the data speak for itself and try different approaches to find the best one. There is no algorithm that will work best for all problems (no free lunch). In our framework we have therefore implemented many algorithms as described in Section <a href="PatientLevelPrediction.html#modelFitting">14.3</a>, and allow others to be added. In this example, to keep things simple, we select just one algorithm: Gradient Boosting Machines.</p>
<p>Furthermore, we have to decide on the covariates that we will use to train our model. In our example, we like to add gender, age, all conditions, drugs and drug groups, and visit counts. We will look for these clinical events in the year before and any time prior the index date.</p>
</div>
<div id="model-evaluation" class="section level3">
<h3><span class="header-section-number">14.5.4</span> Model evaluation</h3>
<p>Finally, we have to define how we will evaluate our model. For simplicity, we here choose internal validation. We have to decide how we divide our dataset in a training and test dataset and how we assign patients to these two sets. Here we will use a typical 75% - 25% split. Note that for very large datasets we could use more data for training.</p>
</div>
<div id="study-summary-1" class="section level3">
<h3><span class="header-section-number">14.5.5</span> Study summary</h3>
<p>We have now completely defined our study as shown in Table <a href="PatientLevelPrediction.html#tab:plpSummary">14.12</a>.</p>
<table>
<caption><span id="tab:plpSummary">Table 14.12: </span> Main design choices for our study.</caption>
<colgroup>
<col width="24%" />
<col width="76%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Choice</th>
<th align="left">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Target cohort</td>
<td align="left">Patients who have just started on an ACE inhibitor for the first time. Patients are excluded if they have less than 365 days of prior observation time or have prior angioedema.</td>
</tr>
<tr class="even">
<td align="left">Outcome cohort</td>
<td align="left">Angioedema.</td>
</tr>
<tr class="odd">
<td align="left">Time-at-risk</td>
<td align="left">1 day till 365 days from cohort start. We will require at least 364 days at risk.</td>
</tr>
<tr class="even">
<td align="left">Model</td>
<td align="left">Gradient Boosting Machine with hyper-parameters ntree: 5000, max depth: 4 or 7 or 10 and learning rate: 0.001 or 0.01 or 0.1 or 0.9. Covariates will include gender, age, conditions, drugs, drug groups, and visit count. Data split: 75% train - 25% test, randomly assigned by person.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="implementing-the-study-in-atlas" class="section level2">
<h2><span class="header-section-number">14.6</span> Implementing the study in ATLAS</h2>
<p>The interface for designing a prediction study can be opened by clicking on the <img src="images/PatientLevelPrediction/predictionButton.png" /> button in the left hand side ATLAS menu. Create a new prediction study. Make sure to give the study an easy-to-recognize name. The study design can be saved at any time by clicking the <img src="images/PopulationLevelEstimation/save.png" /> button.</p>
<p>In the Prediction design function, there are four sections: Prediction Problem Settings, Analysis Settings, Execution Settings, and Training Settings. Here we discuss each section:</p>
<div id="prediction-problem-settings" class="section level3">
<h3><span class="header-section-number">14.6.1</span> Prediction Problem Settings</h3>
<p>Here we select the target population cohorts and outcome cohorts for the analysis. A prediction model will be developed for all combinations of the target population cohorts and the outcome cohorts. For example, if we specify two target populations and two outcomes, we have specified four prediction problems.</p>
<p>To select a target population cohort we need to have previously defined it ATLAS. Instantiating cohorts is described in Chapter <a href="Cohorts.html#Cohorts">11</a>. The Appendix provides the full definitions of the target (Appendix <a href="CohortDefinitions.html#AceInhibitors">B.1</a>) and outcome (Appendix <a href="CohortDefinitions.html#Angioedema">B.4</a>) cohorts used in this example. To add a target population to the cohort, click on the Add Target Cohort button. Adding outcome cohorts similarly works by clicking the Add Outcome Cohort button. When done, the dialog should look like Figure <a href="PatientLevelPrediction.html#fig:problemSettings">14.4</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:problemSettings"></span>
<img src="images/PatientLevelPrediction/problemSettings.png" alt="Prediction problem settings." width="100%" />
<p class="caption">
Figure 14.4: Prediction problem settings.
</p>
</div>
</div>
<div id="analysis-settings" class="section level3">
<h3><span class="header-section-number">14.6.2</span> Analysis Settings</h3>
<p>The analysis settings enables selection of the supervised learning algorithms, the covariates and population settings.</p>
<p><strong>Model Settings</strong></p>
<p>We can pick one or more supervised learning algorithms for model development. To add a supervised learning algorithms click on the Add Model Settings button. A dropdown containing all the models currently supported in the ATLAS interface will appear. We can select the supervised learning model we want to include in the study by clicking on the name in the dropdown menu. This will then show a view for that specific model, allowing the selection of the hyper-parameter values. If multiple values are provided, a grid search is performed across all possible combinations of values to select the optimal combination using cross-validation.</p>
<p>For our example we select gradient boosting machines, and set the hyper-parameters as specified in Figure <a href="PatientLevelPrediction.html#fig:gbmSettings">14.5</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:gbmSettings"></span>
<img src="images/PatientLevelPrediction/gbmSettings.png" alt="Gradient boosting machine settings" width="100%" />
<p class="caption">
Figure 14.5: Gradient boosting machine settings
</p>
</div>
<p><strong>Covariate Settings</strong></p>
<p>We have defined a set of standard covariates that can be extracted from the observational data in the CDM format. In the covariate settings view, it is possible to select which of the standard covariates to include. We can define different types of covariate settings, and each model will be created separately with each specified covariate setting.</p>
<p>To add a covariate setting into the study, click on the Add Covariate Settings. This will open the covariate setting view.</p>
<p>The first part of the covariate settings view is the exclude/include option. Covariates are generally constructed for any concept. However, we may want to include or exclude specific concepts, for example if a concept is linked to the target cohort definition. To only include certain concepts, create a concept set in ATLAS and then under the <strong>What concepts do you want to include in baseline covariates in the patient-level prediction model? (Leave blank if you want to include everything)</strong> select the concept set by clicking on <img src="images/PopulationLevelEstimation/open.png" />. We can automatically add all descendant concepts to the concepts in the concept set by answering yes to the question <strong>Should descendant concepts be added to the list of included concepts?</strong> The same process can be repeated for the question <strong>What concepts do you want to exclude in baseline covariates in the patient-level prediction model? (Leave blank if you want to include everything)</strong>, allowing covariates corresponding to the selected concepts to be removed. The final option <strong>A comma delimited list of covariate IDs that should be restricted to</strong> enables us to add a set of covariate IDs (rather than concept IDs) comma separated that will only be included in the model. This option is for advanced users only. Once done, the inclusion and exclusion settings should look like Figure <a href="PatientLevelPrediction.html#fig:covariateSettings1">14.6</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:covariateSettings1"></span>
<img src="images/PatientLevelPrediction/covariateSettings1.png" alt="Covariate inclusion and exclusion settings." width="100%" />
<p class="caption">
Figure 14.6: Covariate inclusion and exclusion settings.
</p>
</div>
<p>The next section enables the selection of non-time bound variables.</p>
<ul>
<li>Gender: a binary variable indicating male or female gender</li>
<li>Age: a continuous variable corresponding to age in years</li>
<li>Age group: binary variables for every 5 years of age (0-4, 5-9, 10-14, , 95+)</li>
<li>Race: a binary variable for each race, 1 means the patient has that race recorded, 0 otherwise</li>
<li>Ethnicity: a binary variable for each ethnicity, 1 means the patient has that ethnicity recorded, 0 otherwise</li>
<li>Index year: a binary variable for each cohort start date year, 1 means that was the patients cohort start date year, 0 otherwise. <strong>It often does not make sense to include index year, since we would like to apply our model to the future</strong>.</li>
<li>Index month - a binary variable for each cohort start date month, 1 means that was the patients cohort start date month, 0 otherwise</li>
<li>Prior observation time: [Not recommended for prediction] a continuous variable corresponding to how long in days the patient was in the database prior to the cohort start date</li>
<li>Post observation time: [Not recommended for prediction] a continuous variable corresponding to how long in days the patient was in the database post cohort start date</li>
<li>Time in cohort: a continuous variable corresponding to how long in days the patient was in the cohort (cohort end date minus cohort start date)</li>
<li>Index year and month: [Not recommended for prediction] a binary variable for each cohort start date year and month combination, 1 means that was the patients cohort start date year and month, 0 otherwise</li>
</ul>
<p>Once done, this section should look like Figure <a href="PatientLevelPrediction.html#fig:covariateSettings2">14.7</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:covariateSettings2"></span>
<img src="images/PatientLevelPrediction/covariateSettings2.png" alt="Select covariates." width="100%" />
<p class="caption">
Figure 14.7: Select covariates.
</p>
</div>
<p>The standard covariates enable three flexible time intervals for the covariates:</p>
<ul>
<li>end days: when to end the time intervals relative to the cohort start date [default is 0]</li>
<li>long term [default -365 days to end days prior to cohort start date]</li>
<li>medium term [default -180 days to end days prior to cohort start date]</li>
<li>short term [default -30 days to end days prior to cohort start date]</li>
</ul>
<p>Once done, this section should look like Figure <a href="PatientLevelPrediction.html#fig:covariateSettings3">14.8</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:covariateSettings3"></span>
<img src="images/PatientLevelPrediction/covariateSettings3.png" alt="Time bound covariates." width="100%" />
<p class="caption">
Figure 14.8: Time bound covariates.
</p>
</div>
<p>The next option is the covariates extracted from the era tables:</p>
<ul>
<li>Condition: Construct covariates for each condition concept ID and time interval selected and if a patient has the concept ID with an era (i.e., the condition starts or ends during the time interval or starts before and ends after the time interval) during the specified time interval prior to the cohort start date in the condition era table, the covariate value is 1, otherwise 0.</li>
<li>Condition group: Construct covariates for each condition concept ID and time interval selected and if a patient has the concept ID <strong>or any descendant concept ID</strong> with an era during the specified time interval prior to the cohort start date in the condition era table, the covariate value is 1, otherwise 0.</li>
<li>Drug: Construct covariates for each drug concept ID and time interval selected and if a patient has the concept ID with an era during the specified time interval prior to the cohort start date in the drug era table, the covariate value is 1, otherwise 0.</li>
<li>Drug group: Construct covariates for each drug concept ID and time interval selected and if a patient has the concept ID <strong>or any descendant concept ID</strong> with an era during the specified time interval prior to the cohort start date in the drug era table, the covariate value is 1, otherwise 0.</li>
</ul>
<p>Overlapping time interval setting means that the drug or condition era should start prior to the cohort start date and end after the cohort start date, so it overlaps with the cohort start date. The <strong>era start</strong> option restricts to finding condition or drug eras that start during the time interval selected.</p>
<p>Once done, this section should look like Figure <a href="PatientLevelPrediction.html#fig:covariateSettings4">14.9</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:covariateSettings4"></span>
<img src="images/PatientLevelPrediction/covariateSettings4.png" alt="Time bound era covariates." width="100%" />
<p class="caption">
Figure 14.9: Time bound era covariates.
</p>
</div>
<p>The next option selects covariates corresponding to concept IDs in each domain for the various time intervals:</p>
<ul>
<li>Condition: Construct covariates for each condition concept ID and time interval selected and if a patient has the concept ID recorded during the specified time interval prior to the cohort start date in the condition occurrence table, the covariate value is 1, otherwise 0.</li>
<li>Condition Primary Inpatient: TODO</li>
<li>Drug: Construct covariates for each drug concept ID and time interval selected and if a patient has the concept ID recorded during the specified time interval prior to the cohort start date in the drug exposure table, the covariate value is 1, otherwise 0.</li>
<li>Procedure: Construct covariates for each procedure concept ID and time interval selected and if a patient has the concept ID recorded during the specified time interval prior to the cohort start date in the procedure occurrence table, the covariate value is 1, otherwise 0.</li>
<li>Measurement: Construct covariates for each measurement concept ID and time interval selected and if a patient has the concept ID recorded during the specified time interval prior to the cohort start date in the measurement table, the covariate value is 1, otherwise 0.</li>
<li>Measurement Value: Construct covariates for each measurement concept ID with a value and time interval selected and if a patient has the concept ID recorded during the specified time interval prior to the cohort start date in the measurement table, the covariate value is the measurement value, otherwise 0.</li>
<li>Measurement range group: TODO</li>
<li>Observation: Construct covariates for each observation concept ID and time interval selected and if a patient has the concept ID recorded during the specified time interval prior to the cohort start date in the observation table, the covariate value is 1, otherwise 0.</li>
<li>Device: Construct covariates for each device concept ID and time interval selected and if a patient has the concept ID recorded during the specified time interval prior to the cohort start date in the device table, the covariate value is 1, otherwise 0.</li>
<li>Visit Count: Construct covariates for each visit and time interval selected and count the number of visits recorded during the time interval as the covariate value</li>
<li>Visit Concept Count: Construct covariates for each visit, domain and time interval selected and count the number of records per domain recorded during the visit type and time interval as the covariate value</li>
</ul>
<p>The distinct count option counts the number of records per domain and time interval [TODO].</p>
<p>Once done, this section should look like Figure <a href="PatientLevelPrediction.html#fig:covariateSettings5">14.10</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:covariateSettings5"></span>
<img src="images/PatientLevelPrediction/covariateSettings5.png" alt="Time bound covariates." width="100%" />
<p class="caption">
Figure 14.10: Time bound covariates.
</p>
</div>
<p>The final option is whether to include commonly used risk scores as covariates. Once done, the risk score settings should look like Figure <a href="PatientLevelPrediction.html#fig:covariateSettings6">14.11</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:covariateSettings6"></span>
<img src="images/PatientLevelPrediction/covariateSettings6.png" alt="Risk score covariate settings." width="100%" />
<p class="caption">
Figure 14.11: Risk score covariate settings.
</p>
</div>
<p><strong>Population Settings</strong></p>
<p>The population settings is where addition inclusion criteria can be applied to the target population and is also where the time-at-risk is defined. To add a population setting into the study, click on the Add Population Settings button. This will open up the population setting view.</p>
<p>The first set of options enable the user to specify the time-at-risk period. This is the time interval where we look to see whether the outcome of interest occurs. If a patient has the outcome during the time-at-risk period then we will classify them as Has outcome, otherwise they are classified as No outcome. <strong>Define the time-at-risk window start, relative to target cohort entry:</strong> defines the start of the time-at-risk, relative to the target cohort start or end date. Similarly, <strong>Define the time-at-risk window end:</strong> defines the end of the time-at-risk.</p>
<p><strong>Minimum lookback period applied to target cohort</strong> specifies the minimum baseline period; the minimum number of days prior to the cohort start date that a patient is continuously observed. The default is 365 days. Expanding the minimum look-back will give a more complete picture of a patient (as they must have been observed for longer) but will filter patients who do not have the minimum number of days prior observation.</p>
<p>If <strong>Should subjects without time at risk be removed?</strong> is set to yes, then a value for <strong>Minimum time at risk:</strong> is also required. This allows removing people who are lost to follow-up (i.e.that have left the database during the time-at-risk period). For example, if the time-at-risk period was 1 day from cohort start until 365 days from cohort start, then the full time-at-risk interval is 364 days (365-1). If we only want to include patients who are observed the whole interval, then we set the minimum time at risk to be 364. If we are happy as long as people are in the time-at-risk for the first 100 days, then we select minimum time at risk to be 100. In this case as the time-at-risk start as 1 day from the cohort start, a patient will be include if they remain in the database for at least 101 days from the cohort start date. If we set Should subjects without time at risk be removed? to No, then this will keep all patients, even those who drop out from the database during the time-at-risk.</p>
<p>The option <strong>Include people with outcomes who are not observed for the whole at risk period?</strong> is related to the previous option. If set to yes, then people who experience the outcome during the time-at-risk are always kept, even if they are not observed for the specified minimum amount of time.</p>
<p>The option <strong>Should only the first exposure per subject be included?</strong> is only useful if our target cohort contains patients multiple times with different cohort start dates. In this situation, picking yes will result in only keeping the earliest target cohort date per patient in the analysis. Otherwise a patient can be in the dataset multiple times.</p>
<p>Setting <strong>Remove patients who have observed the outcome prior to cohort entry?</strong> to yes will remove patients who have the outcome prior to the time-at-risk start date, so the model is for patients who have never experience the outcome before. If no is selected, then patients could have had the outcome prior. Often, having the outcome prior is very predictive of having the outcome during the time-at-risk.</p>
<p>Once done, the population settings dialog should look like Figure <a href="PatientLevelPrediction.html#fig:populationSettings">14.12</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:populationSettings"></span>
<img src="images/PatientLevelPrediction/populationSettings.png" alt="Population settings." width="100%" />
<p class="caption">
Figure 14.12: Population settings.
</p>
</div>
<p>Now that we are finished with the Analysis Settings, the entire dialog should look like Figure <a href="PatientLevelPrediction.html#fig:analysisSettings">14.13</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:analysisSettings"></span>
<img src="images/PatientLevelPrediction/analysisSettings.png" alt="Analysis settings." width="100%" />
<p class="caption">
Figure 14.13: Analysis settings.
</p>
</div>
</div>
<div id="execution-settings" class="section level3">
<h3><span class="header-section-number">14.6.3</span> Execution settings</h3>
<p>There are three options:</p>
<ul>
<li><strong>Perform sampling</strong>: here we choose whether to perform sampling (default = no). If set to yes, another option will appear: <strong>How many patients to use for a subset?</strong>, where the sample size can be specified. Sampling can be an efficient means to determine if a model for a large population (e.g.10 million patients) will be predictive, by creating and testing the model with a sample of patients. For example, if the AUC is close to 0.5 in the sample, we might abandon the model.</li>
<li><strong>Minimum covariate occurrence: If a covariate occurs in a fraction of the target population less than this value, it will be removed:</strong>: here we choose then minimum covariate occurrence (default = 0.001). A minimum threshold value for covariate occurrence is necessary to remove rare events that are not representative of the overall population.</li>
<li><strong>Normalize covariate</strong>: here we choose whether to normalize covariates (default = yes). Normalization of the covariates is usually necessary for successful implementation of a LASSO model.</li>
</ul>
<p>For our example we make the choices shown in Figure <a href="PatientLevelPrediction.html#fig:executionSettings">14.14</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:executionSettings"></span>
<img src="images/PatientLevelPrediction/executionSettings.png" alt="Execution settings." width="100%" />
<p class="caption">
Figure 14.14: Execution settings.
</p>
</div>
</div>
<div id="training-settings" class="section level3">
<h3><span class="header-section-number">14.6.4</span> Training settings</h3>
<p>There are four options:</p>
<ul>
<li><strong>Specify how to split the test/train set:</strong> Select whether to differentiate the train/test data by person (stratified by outcome) or by time (older data to train the model, later data to evaluate the model).</li>
<li><strong>Percentage of the data to be used as the test set (0-100%)</strong>: Select the percentage of data to be used as test data (default = 25%).</li>
<li><strong>The number of folds used in the cross validation</strong>: Select the number of folds for cross-validation used to select the optimal hyper-parameter (default = 3).</li>
<li><strong>The seed used to split the test/train set when using a person type testSplit (optional):</strong>: Select the random seed used to split the train/test set when using a person type test split.</li>
</ul>
<p>For our example we make the choices shown in Figure <a href="PatientLevelPrediction.html#fig:trainingSettings">14.15</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:trainingSettings"></span>
<img src="images/PatientLevelPrediction/trainingSettings.png" alt="Training settings." width="100%" />
<p class="caption">
Figure 14.15: Training settings.
</p>
</div>
</div>
<div id="importing-and-exporting-a-study" class="section level3">
<h3><span class="header-section-number">14.6.5</span> Importing and exporting a study</h3>
<p>To export a study, click on the Export tab under Utilities. ATLAS will produce JSON that can be directly copied and pasted into a file that contains all of the data, such as the study name, cohort definitions, models selected, covariates, settings, needed to run the study.</p>
<p>To import a study, click on the Import tab under Utilities. Paste the contents of a patient-level prediction study JSON into this window, then click on the Import button below the other tab buttons. Note that this will overwrite all previous settings for that study, so this is typically done using a new, empty study design.</p>
</div>
<div id="downloading-the-study-package" class="section level3">
<h3><span class="header-section-number">14.6.6</span> Downloading the study package</h3>
<p>Click on the Review &amp; Download tab under Utilities. In the Download Study Package section, enter a descriptive name for the R package, noting that any illegal characters in R will automatically be removed from the file name by ATLAS. Click on <img src="images/PatientLevelPrediction/download.png" /> to download the R package to a local folder.</p>
</div>
<div id="running-the-study" class="section level3">
<h3><span class="header-section-number">14.6.7</span> Running the study</h3>
<p>To run the R package requires having R, RStudio, and Java installed as described in Section <a href="OhdsiAnalyticsTools.html#installR">9.4.5</a>. Also required is the <a href="https://ohdsi.github.io/PatientLevelPrediction/">PatientLevelPrediction</a> package, which can be installed in R using:</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="PatientLevelPrediction.html#cb96-1"></a><span class="kw">install.packages</span>(<span class="st">&quot;drat&quot;</span>)</span>
<span id="cb96-2"><a href="PatientLevelPrediction.html#cb96-2"></a>drat<span class="op">::</span><span class="kw">addRepo</span>(<span class="st">&quot;OHDSI&quot;</span>)</span>
<span id="cb96-3"><a href="PatientLevelPrediction.html#cb96-3"></a><span class="kw">install.packages</span>(<span class="st">&quot;PatientLevelPrediction&quot;</span>)</span></code></pre></div>
<p>Some of the machine learning algorithms require additional software to be installed. For a full description of how to install the <a href="https://ohdsi.github.io/PatientLevelPrediction/">PatientLevelPrediction</a> package, see the <a href="https://ohdsi.github.io/PatientLevelPrediction/articles/InstallationGuide.html">Patient-Level Prediction Installation Guide vignette</a>.</p>
<p>To use the study R package we recommend using R Studio. If you are running R Studio locally, unzip the file generated by ATLAS, and double click the .Rproj file to open it in R Studio. If you are running R Studio on an R studio server, click <img src="images/PopulationLevelEstimation/upload.png" /> to upload and unzip the file, then click on the .Rproj file to open the project.</p>
<p>TODO: full instructions for running the package should be in the package README, not in the book.</p>
<p>After running the R package analysis we can view the results in an interactive shiny app by running:</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="PatientLevelPrediction.html#cb97-1"></a>PatientLevelPrediction<span class="op">::</span><span class="kw">viewMultiplePlp</span>(outputFolder)</span></code></pre></div>
</div>
</div>
<div id="implementing-the-study-in-r" class="section level2">
<h2><span class="header-section-number">14.7</span> Implementing the study in R</h2>
<p>An alternative to implementing our study design using ATLAS is to write the study code outselves in R. We can make use of the functions provided in the <a href="https://ohdsi.github.io/PatientLevelPrediction/">PatientLevelPrediction</a> package. The package enables data extraction, model building, and model evaluation using data from databases that are translated into the OMOP CDM.</p>
<div id="cohort-instantiation-2" class="section level3">
<h3><span class="header-section-number">14.7.1</span> Cohort instantiation</h3>
<p>We first need to instantiate the target and outcome cohorts. Instantiating cohorts is described in Chapter <a href="Cohorts.html#Cohorts">11</a>. The Appendix provides the full definitions of the target (Appendix <a href="CohortDefinitions.html#AceInhibitors">B.1</a>) and outcome (Appendix <a href="CohortDefinitions.html#Angioedema">B.4</a>) cohorts. In this example we will assume the ACE inhibitors cohort has ID 1, and the angioedema cohort has ID 2.</p>
</div>
<div id="data-extraction-3" class="section level3">
<h3><span class="header-section-number">14.7.2</span> Data extraction</h3>
<p>We first need to tell R how to connect to the server. <a href="https://ohdsi.github.io/PatientLevelPrediction/"><code>PatientLevelPrediction</code></a> uses the <a href="https://ohdsi.github.io/DatabaseConnector/"><code>DatabaseConnector</code></a> package, which provides a function called <code>createConnectionDetails</code>. Type <code>?createConnectionDetails</code> for the specific settings required for the various database management systems (DBMS). For example, one might connect to a PostgreSQL database using this code:</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="PatientLevelPrediction.html#cb98-1"></a><span class="kw">library</span>(PatientLevelPrediction)</span>
<span id="cb98-2"><a href="PatientLevelPrediction.html#cb98-2"></a>connDetails &lt;-<span class="st"> </span><span class="kw">createConnectionDetails</span>(<span class="dt">dbms =</span> <span class="st">&quot;postgresql&quot;</span>,</span>
<span id="cb98-3"><a href="PatientLevelPrediction.html#cb98-3"></a>                                       <span class="dt">server =</span> <span class="st">&quot;localhost/ohdsi&quot;</span>,</span>
<span id="cb98-4"><a href="PatientLevelPrediction.html#cb98-4"></a>                                       <span class="dt">user =</span> <span class="st">&quot;joe&quot;</span>,</span>
<span id="cb98-5"><a href="PatientLevelPrediction.html#cb98-5"></a>                                       <span class="dt">password =</span> <span class="st">&quot;supersecret&quot;</span>)</span>
<span id="cb98-6"><a href="PatientLevelPrediction.html#cb98-6"></a></span>
<span id="cb98-7"><a href="PatientLevelPrediction.html#cb98-7"></a>cdmDbSchema &lt;-<span class="st"> &quot;my_cdm_data&quot;</span></span>
<span id="cb98-8"><a href="PatientLevelPrediction.html#cb98-8"></a>cohortsDbSchema &lt;-<span class="st"> &quot;scratch&quot;</span></span>
<span id="cb98-9"><a href="PatientLevelPrediction.html#cb98-9"></a>cohortsDbTable &lt;-<span class="st"> &quot;my_cohorts&quot;</span></span>
<span id="cb98-10"><a href="PatientLevelPrediction.html#cb98-10"></a>cdmVersion &lt;-<span class="st"> &quot;5&quot;</span></span></code></pre></div>
<p>The last four lines define the <code>cdmDbSchema</code>, <code>cohortsDbSchema</code>, and <code>cohortsDbTable</code> variables, as well as the CDM version. We will use these later to tell R where the data in CDM format live, where the cohorts of interest have been created, and what version CDM is used. Note that for Microsoft SQL Server, database schemas need to specify both the database and the schema, so for example <code>cdmDbSchema &lt;- "my_cdm_data.dbo"</code>.</p>
<p>First it makes sense to verify that the cohort creation has succeeded, by counting the number of cohort entries:</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="PatientLevelPrediction.html#cb99-1"></a>sql &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;SELECT cohort_definition_id, COUNT(*) AS count&quot;</span>,</span>
<span id="cb99-2"><a href="PatientLevelPrediction.html#cb99-2"></a><span class="st">&quot;FROM @cohortsDbSchema.cohortsDbTable&quot;</span>,</span>
<span id="cb99-3"><a href="PatientLevelPrediction.html#cb99-3"></a><span class="st">&quot;GROUP BY cohort_definition_id&quot;</span>)</span>
<span id="cb99-4"><a href="PatientLevelPrediction.html#cb99-4"></a>conn &lt;-<span class="st"> </span><span class="kw">connect</span>(connDetails)</span>
<span id="cb99-5"><a href="PatientLevelPrediction.html#cb99-5"></a><span class="kw">renderTranslateQuerySql</span>(<span class="dt">connection =</span> conn, </span>
<span id="cb99-6"><a href="PatientLevelPrediction.html#cb99-6"></a>                        <span class="dt">sql =</span> sql,</span>
<span id="cb99-7"><a href="PatientLevelPrediction.html#cb99-7"></a>                        <span class="dt">cohortsDbSchema =</span> cohortsDbSchema,</span>
<span id="cb99-8"><a href="PatientLevelPrediction.html#cb99-8"></a>                        <span class="dt">cohortsDbTable =</span> cohortsDbTable)</span></code></pre></div>
<pre><code>##   cohort_definition_id  count
## 1                    1 527616
## 2                    2   3201</code></pre>
<p>Now we can tell <a href="https://ohdsi.github.io/PatientLevelPrediction/">PatientLevelPrediction</a> to extract all necessary data for our analysis. Covariates are extracted using the <a href="https://ohdsi.github.io/FeatureExtraction/"><code>FeatureExtraction</code></a> package. For more detailed information on the FeatureExtraction package see its vignettes. For our example study we decided to use these settings:</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="PatientLevelPrediction.html#cb101-1"></a>covSettings &lt;-<span class="st"> </span><span class="kw">createCovariateSettings</span>(<span class="dt">useDemographicsGender =</span> <span class="ot">TRUE</span>,</span>
<span id="cb101-2"><a href="PatientLevelPrediction.html#cb101-2"></a>                                       <span class="dt">useDemographicsAge =</span> <span class="ot">TRUE</span>,</span>
<span id="cb101-3"><a href="PatientLevelPrediction.html#cb101-3"></a>                                       <span class="dt">useConditionGroupEraLongTerm =</span> <span class="ot">TRUE</span>,</span>
<span id="cb101-4"><a href="PatientLevelPrediction.html#cb101-4"></a>                                       <span class="dt">useConditionGroupEraAnyTimePrior =</span> <span class="ot">TRUE</span>,</span>
<span id="cb101-5"><a href="PatientLevelPrediction.html#cb101-5"></a>                                       <span class="dt">useDrugGroupEraLongTerm =</span> <span class="ot">TRUE</span>,</span>
<span id="cb101-6"><a href="PatientLevelPrediction.html#cb101-6"></a>                                       <span class="dt">useDrugGroupEraAnyTimePrior =</span> <span class="ot">TRUE</span>,</span>
<span id="cb101-7"><a href="PatientLevelPrediction.html#cb101-7"></a>                                       <span class="dt">useVisitConceptCountLongTerm =</span> <span class="ot">TRUE</span>,</span>
<span id="cb101-8"><a href="PatientLevelPrediction.html#cb101-8"></a>                                       <span class="dt">longTermStartDays =</span> <span class="dv">-365</span>,</span>
<span id="cb101-9"><a href="PatientLevelPrediction.html#cb101-9"></a>                                       <span class="dt">endDays =</span> <span class="dv">-1</span>)</span></code></pre></div>
<p>The final step for extracting the data is to run the <code>getPlpData</code> function and input the connection details, the database schema where the cohorts are stored, the cohort definition IDs for the cohort and outcome, and the washout period which is the minimum number of days prior to cohort index date that the person must have been observed to be included into the data, and finally input the previously constructed covariate settings.</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="PatientLevelPrediction.html#cb102-1"></a>plpData &lt;-<span class="st"> </span><span class="kw">getPlpData</span>(<span class="dt">connectionDetails =</span> connDetails,</span>
<span id="cb102-2"><a href="PatientLevelPrediction.html#cb102-2"></a>                      <span class="dt">cdmDatabaseSchema =</span> cdmDbSchema,</span>
<span id="cb102-3"><a href="PatientLevelPrediction.html#cb102-3"></a>                      <span class="dt">cohortDatabaseSchema =</span> cohortsDbSchema,</span>
<span id="cb102-4"><a href="PatientLevelPrediction.html#cb102-4"></a>                      <span class="dt">cohortTable =</span> cohortsDbSchema,</span>
<span id="cb102-5"><a href="PatientLevelPrediction.html#cb102-5"></a>                      <span class="dt">cohortId =</span> <span class="dv">1</span>,</span>
<span id="cb102-6"><a href="PatientLevelPrediction.html#cb102-6"></a>                      <span class="dt">covariateSettings =</span> covariateSettings,</span>
<span id="cb102-7"><a href="PatientLevelPrediction.html#cb102-7"></a>                      <span class="dt">outcomeDatabaseSchema =</span> cohortsDbSchema,</span>
<span id="cb102-8"><a href="PatientLevelPrediction.html#cb102-8"></a>                      <span class="dt">outcomeTable =</span> cohortsDbSchema,</span>
<span id="cb102-9"><a href="PatientLevelPrediction.html#cb102-9"></a>                      <span class="dt">outcomeIds =</span> <span class="dv">2</span>,</span>
<span id="cb102-10"><a href="PatientLevelPrediction.html#cb102-10"></a>                      <span class="dt">sampleSize =</span> <span class="dv">10000</span></span>
<span id="cb102-11"><a href="PatientLevelPrediction.html#cb102-11"></a>)</span></code></pre></div>
<p>There are many additional parameters for the <code>getPlpData</code> function which are all documented in the <a href="https://ohdsi.github.io/PatientLevelPrediction/">PatientLevelPrediction</a> manual. The resulting <code>plpData</code> object uses the package <code>ff</code> to store information in a way that ensures R does not run out of memory, even when the data are large.</p>
<p>Creating the <code>plpData</code> object can take considerable computing time, and it is probably a good idea to save it for future sessions. Because <code>plpData</code> uses <code>ff</code>, we cannot use Rs regular save function. Instead, well have to use the <code>savePlpData</code> function:</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="PatientLevelPrediction.html#cb103-1"></a><span class="kw">savePlpData</span>(plpData, <span class="st">&quot;angio_in_ace_data&quot;</span>)</span></code></pre></div>
<p>We can use the <code>loadPlpData()</code> function to load the data in a future session.</p>
</div>
<div id="additional-inclusion-criteria" class="section level3">
<h3><span class="header-section-number">14.7.3</span> Additional inclusion criteria</h3>
<p>The final study population is obtained by applying additional constraints on the two earlier defined cohorts, e.g., a minimum time at risk can be enforced (<code>requireTimeAtRisk, minTimeAtRisk</code>) and we can specify if this also applies to patients with the outcome (<code>includeAllOutcomes</code>). Here we also specify the start and end of the risk window relative to target cohort start. For example, if we like the risk window to start 30 days after the at-risk cohort start and end a year later we can set <code>riskWindowStart = 30</code> and <code>riskWindowEnd = 365</code>. In some cases the risk window needs to start at the cohort end date. This can be achieved by setting <code>addExposureToStart = TRUE</code> which adds the cohort (exposure) time to the start date.</p>
<p>In the example below all the settings we defined for our study are imposed:</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="PatientLevelPrediction.html#cb104-1"></a>population &lt;-<span class="st"> </span><span class="kw">createStudyPopulation</span>(<span class="dt">plpData =</span> plpData,</span>
<span id="cb104-2"><a href="PatientLevelPrediction.html#cb104-2"></a>                                    <span class="dt">outcomeId =</span> <span class="dv">2</span>,</span>
<span id="cb104-3"><a href="PatientLevelPrediction.html#cb104-3"></a>                                    <span class="dt">washoutPeriod =</span> <span class="dv">364</span>,</span>
<span id="cb104-4"><a href="PatientLevelPrediction.html#cb104-4"></a>                                    <span class="dt">firstExposureOnly =</span> <span class="ot">FALSE</span>,</span>
<span id="cb104-5"><a href="PatientLevelPrediction.html#cb104-5"></a>                                    <span class="dt">removeSubjectsWithPriorOutcome =</span> <span class="ot">TRUE</span>,</span>
<span id="cb104-6"><a href="PatientLevelPrediction.html#cb104-6"></a>                                    <span class="dt">priorOutcomeLookback =</span> <span class="dv">9999</span>,</span>
<span id="cb104-7"><a href="PatientLevelPrediction.html#cb104-7"></a>                                    <span class="dt">riskWindowStart =</span> <span class="dv">1</span>,</span>
<span id="cb104-8"><a href="PatientLevelPrediction.html#cb104-8"></a>                                    <span class="dt">riskWindowEnd =</span> <span class="dv">365</span>,</span>
<span id="cb104-9"><a href="PatientLevelPrediction.html#cb104-9"></a>                                    <span class="dt">addExposureDaysToStart =</span> <span class="ot">FALSE</span>,</span>
<span id="cb104-10"><a href="PatientLevelPrediction.html#cb104-10"></a>                                    <span class="dt">addExposureDaysToEnd =</span> <span class="ot">FALSE</span>,</span>
<span id="cb104-11"><a href="PatientLevelPrediction.html#cb104-11"></a>                                    <span class="dt">minTimeAtRisk =</span> <span class="dv">364</span>,</span>
<span id="cb104-12"><a href="PatientLevelPrediction.html#cb104-12"></a>                                    <span class="dt">requireTimeAtRisk =</span> <span class="ot">TRUE</span>,</span>
<span id="cb104-13"><a href="PatientLevelPrediction.html#cb104-13"></a>                                    <span class="dt">includeAllOutcomes =</span> <span class="ot">TRUE</span>,</span>
<span id="cb104-14"><a href="PatientLevelPrediction.html#cb104-14"></a>                                    <span class="dt">verbosity =</span> <span class="st">&quot;DEBUG&quot;</span></span>
<span id="cb104-15"><a href="PatientLevelPrediction.html#cb104-15"></a>)</span></code></pre></div>
</div>
<div id="model-development" class="section level3">
<h3><span class="header-section-number">14.7.4</span> Model Development</h3>
<p>In the set function of an algorithm the user can specify a list of eligible values for each hyper-parameter. All possible combinations of the hyper-parameters are included in a so-called grid search using cross-validation on the training set. If a user does not specify any value then the default value is used instead.</p>
<p>For example, if we use the following settings for the gradient boosting machine: <code>ntrees = c(100,200), maxDepth = 4</code> the grid search will apply the gradient boosting machine algorithm with <code>ntrees = 100</code> and <code>maxDepth = 4</code> plus the default settings for other hyper-parameters and <code>ntrees = 200</code> and <code>maxDepth = 4</code> plus the default settings for other hyper-parameters. The hyper-parameters that lead to the best cross-validation performance will then be chosen for the final model. For our problem we choose to build a gradient boosting machine with several hyper-parameter values:</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="PatientLevelPrediction.html#cb105-1"></a>gbmModel &lt;-<span class="st"> </span><span class="kw">setGradientBoostingMachine</span>(<span class="dt">ntrees =</span> <span class="dv">5000</span>, </span>
<span id="cb105-2"><a href="PatientLevelPrediction.html#cb105-2"></a>                                       <span class="dt">maxDepth =</span> <span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">7</span>,<span class="dv">10</span>), </span>
<span id="cb105-3"><a href="PatientLevelPrediction.html#cb105-3"></a>                                       <span class="dt">learnRate =</span> <span class="kw">c</span>(<span class="fl">0.001</span>,<span class="fl">0.01</span>,<span class="fl">0.1</span>,<span class="fl">0.9</span>))</span></code></pre></div>
<p>The <code>runPlP</code> function uses the population, <code>plpData</code>, and model settings to train and evaluate the model. We can use the <code>testSplit</code> (person/time) and <code>testFraction</code> parameters to split the data in a 75%-25% split and run the patient-level prediction pipeline:</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="PatientLevelPrediction.html#cb106-1"></a>gbmResults &lt;-<span class="st"> </span><span class="kw">runPlp</span>(<span class="dt">population =</span> population, </span>
<span id="cb106-2"><a href="PatientLevelPrediction.html#cb106-2"></a>                     <span class="dt">plpData =</span> plpData, </span>
<span id="cb106-3"><a href="PatientLevelPrediction.html#cb106-3"></a>                     <span class="dt">modelSettings =</span> gbmModel, </span>
<span id="cb106-4"><a href="PatientLevelPrediction.html#cb106-4"></a>                     <span class="dt">testSplit =</span> <span class="st">&#39;person&#39;</span>,</span>
<span id="cb106-5"><a href="PatientLevelPrediction.html#cb106-5"></a>                     <span class="dt">testFraction =</span> <span class="fl">0.25</span>, </span>
<span id="cb106-6"><a href="PatientLevelPrediction.html#cb106-6"></a>                     <span class="dt">nfold =</span> <span class="dv">2</span>, </span>
<span id="cb106-7"><a href="PatientLevelPrediction.html#cb106-7"></a>                     <span class="dt">splitSeed =</span> <span class="dv">1234</span>)</span></code></pre></div>
<p>Under the hood the package will now use the R xgboost package to fit a a gradient boosting machine model using 75% of the data and will evaluate the model on the remaining 25%. A results data structure is returned containing information about the model, its performance etc.</p>
<p>In the <code>runPlp</code> function there are several parameters to save the <code>plpData</code>, <code>plpResults</code>, <code>plpPlots</code>, <code>evaluation</code>, etc. objects which are all set to <code>TRUE</code> by default.</p>
<p>We can save the model using:</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="PatientLevelPrediction.html#cb107-1"></a><span class="kw">savePlpModel</span>(gbmResults<span class="op">$</span>model, <span class="dt">dirPath =</span> <span class="st">&quot;model&quot;</span>)</span></code></pre></div>
<p>We can load the model using:</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="PatientLevelPrediction.html#cb108-1"></a>plpModel &lt;-<span class="st"> </span><span class="kw">loadPlpModel</span>(<span class="st">&quot;model&quot;</span>)</span></code></pre></div>
<p>You can also save the full results structure using:</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="PatientLevelPrediction.html#cb109-1"></a><span class="kw">savePlpResult</span>(gbmResults, <span class="dt">location =</span> <span class="st">&quot;gbmResults&quot;</span>)</span></code></pre></div>
<p>To load the full results structure use:</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="PatientLevelPrediction.html#cb110-1"></a>gbmResults &lt;-<span class="st"> </span><span class="kw">loadPlpResult</span>(<span class="st">&quot;gbmResults&quot;</span>)</span></code></pre></div>
</div>
<div id="internal-validation" class="section level3">
<h3><span class="header-section-number">14.7.5</span> Internal Validation</h3>
<p>Once we execute the study, the <code>runPlp</code> function returns the trained model and the evaluation of the model on the train/test sets. You can interactively view the results by running: <code>viewPlp(runPlp = gbmResults)</code>. This will open a Shiny App in which we can view all performance measures created by the framework, including interactive plots, as shown in Figure <a href="PatientLevelPrediction.html#fig:shinySummary">14.16</a>.</p>
<p>To generate and save all the evaluation plots to a folder run the following code:</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="PatientLevelPrediction.html#cb111-1"></a><span class="kw">plotPlp</span>(gbmResults, <span class="st">&quot;plots&quot;</span>)</span></code></pre></div>
<p>The plots are described in more detail in Section <a href="PatientLevelPrediction.html#performance">14.4.2</a>.</p>
<div id="external-validation" class="section level4">
<h4><span class="header-section-number">14.7.5.1</span> External validation</h4>
<p>We recommend to always perform external validation, i.e.apply the final model on as much new datasets as feasible and evaluate its performance. Here we assume the data extraction has already been performed on a second database and stored in the <code>newData</code> folder. We load the model we previously fitted from the <code>model</code> folder:</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="PatientLevelPrediction.html#cb112-1"></a><span class="co"># load the trained model</span></span>
<span id="cb112-2"><a href="PatientLevelPrediction.html#cb112-2"></a>plpModel &lt;-<span class="st"> </span><span class="kw">loadPlpModel</span>(<span class="st">&quot;model&quot;</span>)</span>
<span id="cb112-3"><a href="PatientLevelPrediction.html#cb112-3"></a></span>
<span id="cb112-4"><a href="PatientLevelPrediction.html#cb112-4"></a><span class="co">#load the new plpData and create the population</span></span>
<span id="cb112-5"><a href="PatientLevelPrediction.html#cb112-5"></a>plpData &lt;-<span class="st"> </span><span class="kw">loadPlpData</span>(<span class="st">&quot;newData&quot;</span>)</span>
<span id="cb112-6"><a href="PatientLevelPrediction.html#cb112-6"></a></span>
<span id="cb112-7"><a href="PatientLevelPrediction.html#cb112-7"></a>population &lt;-<span class="st"> </span><span class="kw">createStudyPopulation</span>(<span class="dt">plpData =</span> plpData,</span>
<span id="cb112-8"><a href="PatientLevelPrediction.html#cb112-8"></a>                                    <span class="dt">outcomeId =</span> <span class="dv">2</span>,</span>
<span id="cb112-9"><a href="PatientLevelPrediction.html#cb112-9"></a>                                    <span class="dt">washoutPeriod =</span> <span class="dv">364</span>,</span>
<span id="cb112-10"><a href="PatientLevelPrediction.html#cb112-10"></a>                                    <span class="dt">firstExposureOnly =</span> <span class="ot">FALSE</span>,</span>
<span id="cb112-11"><a href="PatientLevelPrediction.html#cb112-11"></a>                                    <span class="dt">removeSubjectsWithPriorOutcome =</span> <span class="ot">TRUE</span>,</span>
<span id="cb112-12"><a href="PatientLevelPrediction.html#cb112-12"></a>                                    <span class="dt">priorOutcomeLookback =</span> <span class="dv">9999</span>,</span>
<span id="cb112-13"><a href="PatientLevelPrediction.html#cb112-13"></a>                                    <span class="dt">riskWindowStart =</span> <span class="dv">1</span>,</span>
<span id="cb112-14"><a href="PatientLevelPrediction.html#cb112-14"></a>                                    <span class="dt">riskWindowEnd =</span> <span class="dv">365</span>,</span>
<span id="cb112-15"><a href="PatientLevelPrediction.html#cb112-15"></a>                                    <span class="dt">addExposureDaysToStart =</span> <span class="ot">FALSE</span>,</span>
<span id="cb112-16"><a href="PatientLevelPrediction.html#cb112-16"></a>                                    <span class="dt">addExposureDaysToEnd =</span> <span class="ot">FALSE</span>,</span>
<span id="cb112-17"><a href="PatientLevelPrediction.html#cb112-17"></a>                                    <span class="dt">minTimeAtRisk =</span> <span class="dv">364</span>,</span>
<span id="cb112-18"><a href="PatientLevelPrediction.html#cb112-18"></a>                                    <span class="dt">requireTimeAtRisk =</span> <span class="ot">TRUE</span>,</span>
<span id="cb112-19"><a href="PatientLevelPrediction.html#cb112-19"></a>                                    <span class="dt">includeAllOutcomes =</span> <span class="ot">TRUE</span></span>
<span id="cb112-20"><a href="PatientLevelPrediction.html#cb112-20"></a>)</span>
<span id="cb112-21"><a href="PatientLevelPrediction.html#cb112-21"></a></span>
<span id="cb112-22"><a href="PatientLevelPrediction.html#cb112-22"></a><span class="co"># apply the trained model on the new data</span></span>
<span id="cb112-23"><a href="PatientLevelPrediction.html#cb112-23"></a>validationResults &lt;-<span class="st"> </span><span class="kw">applyModel</span>(population, plpData, plpModel)</span></code></pre></div>
<p>To make things easier we also provide the <code>externalValidatePlp</code> function for performing external validation that also extracts the required data. Assuming we ran <code>result &lt;- runPlp(...)</code> then we can extract the data required for the model and evaluated it on new data. Assuming the validation cohorts are in the table <code>mainschema.dob.cohort</code> with IDs 1 and 2 and the CDM data is in the schema <code>cdmschema.dob</code>:</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="PatientLevelPrediction.html#cb113-1"></a>valResult &lt;-<span class="st"> </span><span class="kw">externalValidatePlp</span>(</span>
<span id="cb113-2"><a href="PatientLevelPrediction.html#cb113-2"></a>    <span class="dt">plpResult =</span> result, </span>
<span id="cb113-3"><a href="PatientLevelPrediction.html#cb113-3"></a>    <span class="dt">connectionDetails =</span> connectionDetails,</span>
<span id="cb113-4"><a href="PatientLevelPrediction.html#cb113-4"></a>    <span class="dt">validationSchemaTarget =</span> <span class="st">&#39;mainschema.dob&#39;</span>,</span>
<span id="cb113-5"><a href="PatientLevelPrediction.html#cb113-5"></a>    <span class="dt">validationSchemaOutcome =</span> <span class="st">&#39;mainschema.dob&#39;</span>,</span>
<span id="cb113-6"><a href="PatientLevelPrediction.html#cb113-6"></a>    <span class="dt">validationSchemaCdm =</span> <span class="st">&#39;cdmschema.dbo&#39;</span>,</span>
<span id="cb113-7"><a href="PatientLevelPrediction.html#cb113-7"></a>    <span class="dt">databaseNames =</span> <span class="st">&#39;new database&#39;</span>,</span>
<span id="cb113-8"><a href="PatientLevelPrediction.html#cb113-8"></a>    <span class="dt">validationTableTarget =</span> <span class="st">&#39;cohort&#39;</span>,</span>
<span id="cb113-9"><a href="PatientLevelPrediction.html#cb113-9"></a>    <span class="dt">validationTableOutcome =</span> <span class="st">&#39;cohort&#39;</span>,</span>
<span id="cb113-10"><a href="PatientLevelPrediction.html#cb113-10"></a>    <span class="dt">validationIdTarget =</span> <span class="dv">1</span>,</span>
<span id="cb113-11"><a href="PatientLevelPrediction.html#cb113-11"></a>    <span class="dt">validationIdOutcome =</span> <span class="dv">2</span></span>
<span id="cb113-12"><a href="PatientLevelPrediction.html#cb113-12"></a>)</span></code></pre></div>
<p>If we have multiple databases to validate the model on then we can run:</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="PatientLevelPrediction.html#cb114-1"></a>valResults &lt;-<span class="st"> </span><span class="kw">externalValidatePlp</span>(</span>
<span id="cb114-2"><a href="PatientLevelPrediction.html#cb114-2"></a>    <span class="dt">plpResult =</span> result, </span>
<span id="cb114-3"><a href="PatientLevelPrediction.html#cb114-3"></a>    <span class="dt">connectionDetails =</span> connectionDetails,</span>
<span id="cb114-4"><a href="PatientLevelPrediction.html#cb114-4"></a>    <span class="dt">validationSchemaTarget =</span> <span class="kw">list</span>(<span class="st">&#39;mainschema.dob&#39;</span>,</span>
<span id="cb114-5"><a href="PatientLevelPrediction.html#cb114-5"></a>                                <span class="st">&#39;difschema.dob&#39;</span>, </span>
<span id="cb114-6"><a href="PatientLevelPrediction.html#cb114-6"></a>                                <span class="st">&#39;anotherschema.dob&#39;</span>),</span>
<span id="cb114-7"><a href="PatientLevelPrediction.html#cb114-7"></a>    <span class="dt">validationSchemaOutcome =</span> <span class="kw">list</span>(<span class="st">&#39;mainschema.dob&#39;</span>,</span>
<span id="cb114-8"><a href="PatientLevelPrediction.html#cb114-8"></a>                                 <span class="st">&#39;difschema.dob&#39;</span>, </span>
<span id="cb114-9"><a href="PatientLevelPrediction.html#cb114-9"></a>                                 <span class="st">&#39;anotherschema.dob&#39;</span>),</span>
<span id="cb114-10"><a href="PatientLevelPrediction.html#cb114-10"></a>    <span class="dt">validationSchemaCdm =</span> <span class="kw">list</span>(<span class="st">&#39;cdms1chema.dbo&#39;</span>,</span>
<span id="cb114-11"><a href="PatientLevelPrediction.html#cb114-11"></a>                             <span class="st">&#39;cdm2schema.dbo&#39;</span>,</span>
<span id="cb114-12"><a href="PatientLevelPrediction.html#cb114-12"></a>                             <span class="st">&#39;cdm3schema.dbo&#39;</span>),</span>
<span id="cb114-13"><a href="PatientLevelPrediction.html#cb114-13"></a>    <span class="dt">databaseNames =</span> <span class="kw">list</span>(<span class="st">&#39;new database 1&#39;</span>,</span>
<span id="cb114-14"><a href="PatientLevelPrediction.html#cb114-14"></a>                       <span class="st">&#39;new database 2&#39;</span>,</span>
<span id="cb114-15"><a href="PatientLevelPrediction.html#cb114-15"></a>                       <span class="st">&#39;new database 3&#39;</span>),</span>
<span id="cb114-16"><a href="PatientLevelPrediction.html#cb114-16"></a>    <span class="dt">validationTableTarget =</span> <span class="kw">list</span>(<span class="st">&#39;cohort1&#39;</span>,</span>
<span id="cb114-17"><a href="PatientLevelPrediction.html#cb114-17"></a>                               <span class="st">&#39;cohort2&#39;</span>,</span>
<span id="cb114-18"><a href="PatientLevelPrediction.html#cb114-18"></a>                               <span class="st">&#39;cohort3&#39;</span>),</span>
<span id="cb114-19"><a href="PatientLevelPrediction.html#cb114-19"></a>    <span class="dt">validationTableOutcome =</span> <span class="kw">list</span>(<span class="st">&#39;cohort1&#39;</span>,</span>
<span id="cb114-20"><a href="PatientLevelPrediction.html#cb114-20"></a>                                <span class="st">&#39;cohort2&#39;</span>,</span>
<span id="cb114-21"><a href="PatientLevelPrediction.html#cb114-21"></a>                                <span class="st">&#39;cohort3&#39;</span>),</span>
<span id="cb114-22"><a href="PatientLevelPrediction.html#cb114-22"></a>    <span class="dt">validationIdTarget =</span> <span class="kw">list</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">5</span>),</span>
<span id="cb114-23"><a href="PatientLevelPrediction.html#cb114-23"></a>    <span class="dt">validationIdOutcome =</span> <span class="kw">list</span>(<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">6</span>)</span>
<span id="cb114-24"><a href="PatientLevelPrediction.html#cb114-24"></a>)</span></code></pre></div>
</div>
</div>
</div>
<div id="single-model-viewer-app" class="section level2">
<h2><span class="header-section-number">14.8</span> Single model viewer app</h2>
<p>Exploring the performance of a prediction model is easiest with the <code>viewPlp</code> function. This requires a results object as the input. If developing models in R we can use the result of <code>runPLp</code> as the input. If using the ATLAS-generated study package, then we need to load one of the models (in this example we will load Analysis_1):</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="PatientLevelPrediction.html#cb115-1"></a>plpResult &lt;-<span class="st"> </span><span class="kw">loadPlpResult</span>(<span class="kw">file.path</span>(outputFolder, </span>
<span id="cb115-2"><a href="PatientLevelPrediction.html#cb115-2"></a>                                     <span class="st">&#39;Analysis_1&#39;</span>, </span>
<span id="cb115-3"><a href="PatientLevelPrediction.html#cb115-3"></a>                                     <span class="st">&#39;plpResult&#39;</span>))</span></code></pre></div>
<p>Here Analysis_1 corresponds to the analysis we specified earlier.</p>
<p>We can then launch the shiny app by running:</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="PatientLevelPrediction.html#cb116-1"></a><span class="kw">viewPlp</span>(plpResult)</span></code></pre></div>
<p>The Shiny app opens with a summary of the performance metrics on the test and train sets, see Figure <a href="PatientLevelPrediction.html#fig:shinySummary">14.16</a>. The results show that the AUC on the train set was 0.78 and this dropped to 0.74 on the test set. The test set AUC is the more accurate measure. Overall, the model appears to be able to discriminate those who will develop the outcome in new users of ACE inhibitors but it slightly overfit as the performance on the train set is higher than the test set. The ROC plot is presented in Figure <a href="PatientLevelPrediction.html#fig:shinyROC">14.17</a>.</p>
<div class="figure"><span id="fig:shinySummary"></span>
<img src="images/PatientLevelPrediction/shinysummary.png" alt="Summary evaluation statistics in the Shiny app." width="100%" />
<p class="caption">
Figure 14.16: Summary evaluation statistics in the Shiny app.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:shinyROC"></span>
<img src="images/PatientLevelPrediction/shiny/singleShiny/singleShinyRoc.png" alt="The ROC plot." width="100%" />
<p class="caption">
Figure 14.17: The ROC plot.
</p>
</div>
<p>The calibration plot in Figure <a href="PatientLevelPrediction.html#fig:shinyCal">14.18</a> shows that generally the observed risk matches the predicted risk as the dots are around the diagonal line. The demographic calibration plot in Figure <a href="PatientLevelPrediction.html#fig:shinyDemo">14.19</a> however shows that the model is not well calibrated for the younger patients, as the blue line (the predicted risk) differs from the red line (the observed risk) for those aged below 40. This may indicate we need to remove the under 40s from the target population (as the observed risk for the younger patients is nearly zero).</p>
<div class="figure" style="text-align: center"><span id="fig:shinyCal"></span>
<img src="images/PatientLevelPrediction/shiny/singleShiny/singleShinyCal.png" alt="The calibration of the model" width="100%" />
<p class="caption">
Figure 14.18: The calibration of the model
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:shinyDemo"></span>
<img src="images/PatientLevelPrediction/shiny/singleShiny/singleShinyDemo.png" alt="The demographic calibration of the model" width="100%" />
<p class="caption">
Figure 14.19: The demographic calibration of the model
</p>
</div>
<p>Finally, the attrition plot shows the loss of patients from the labelled data based on inclusion/exclusion criteria, see Figure <a href="PatientLevelPrediction.html#fig:shinyAtt">14.20</a>. The plot shows that we lost a large portion of the target population due to them not being observed for the whole time at risk (1 year follow up). Interestingly, not as many patients with the outcome lacked the complete time at risk.</p>
<div class="figure" style="text-align: center"><span id="fig:shinyAtt"></span>
<img src="images/PatientLevelPrediction/shiny/singleShiny/singleShinyAtt.png" alt="The attrition plot for the prediction problem" width="100%" />
<p class="caption">
Figure 14.20: The attrition plot for the prediction problem
</p>
</div>
</div>
<div id="multiple-model-viewer-app" class="section level2">
<h2><span class="header-section-number">14.9</span> Multiple model viewer app</h2>
<p>The study package as generated by ATLAS allows generating and evaluating many different prediction models, for different prediction problems. Therefore, specifically for the output generated by the study package an additional Shiny app has been developed for viewing multiple models. To start this app, run <code>viewMultiplePlp(outputFolder)</code> where <code>outputFolder</code> is the path containing the analysis results as specified when running the <code>execute</code> command (and should for example contain a sub-folder named Analysis_1).</p>
<div id="viewing-the-model-summary-and-settings" class="section level3">
<h3><span class="header-section-number">14.9.1</span> Viewing the model summary and settings</h3>
<p>The interactive shiny app will start at the summary page as shown in Figure <a href="PatientLevelPrediction.html#fig:multiShinySummary">14.21</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:multiShinySummary"></span>
<img src="images/PatientLevelPrediction/shiny/shinyFilter.png" alt="The shiny summary page containing key hold out set performance metrics for each model trained" width="100%" />
<p class="caption">
Figure 14.21: The shiny summary page containing key hold out set performance metrics for each model trained
</p>
</div>
<p>This summary page table contains:</p>
<ul>
<li>basic information about the model (e.g., database information, classifier type, time at risk settings, target population and outcome names)</li>
<li>hold out target population count and incidence of outcome</li>
<li>discrimination metrics: AUC, AUPRC</li>
</ul>
<p>To the left of the table is the filter option, where we can specify the development/validation databases to focus on, the type of model, the time at risk settings of interest and/or the cohorts of interest. For example, to pick the models corresponding to the target population New users of ACE inhibitors as first line monotherapy for hypertension, select this in the <em>Target Cohort</em> option.</p>
<p>To explore a model click on the corresponding row, a selected row will be highlighted. With a row selected, we can now explore the model settings used when developing the model by clicking on the <em>Model Settings</em> tab:</p>
<div class="figure" style="text-align: center"><span id="fig:shinyModel"></span>
<img src="images/PatientLevelPrediction/shiny/shinyModel.png" alt="To view the model settings used when developing the model." width="100%" />
<p class="caption">
Figure 14.22: To view the model settings used when developing the model.
</p>
</div>
<p>Similarly, we can explore the population and covariate settings used to generate the model in the other tabs.</p>
</div>
<div id="viewing-model-performance" class="section level3">
<h3><span class="header-section-number">14.9.2</span> Viewing model performance</h3>
<p>Once a model row had been selected we can also view the model performance. Click on <img src="images/PatientLevelPrediction/performance.png" /> to open the threshold performance summary shown in Figure <a href="PatientLevelPrediction.html#fig:shinyPerformanceSum">14.23</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:shinyPerformanceSum"></span>
<img src="images/PatientLevelPrediction/shiny/shinyPerformanceSum.png" alt="The summary performance measures at a set threshold." width="100%" />
<p class="caption">
Figure 14.23: The summary performance measures at a set threshold.
</p>
</div>
<p>This summary view shows the selected prediction question in the standard format, a threshold selector and a dashboard containing key threshold based metrics such as positive predictive value (PPV), negative predictive value (NPV), sensitivity and specificity (see Section <a href="PatientLevelPrediction.html#performance">14.4.2</a>). In Figure <a href="PatientLevelPrediction.html#fig:shinyPerformanceSum">14.23</a> we see that at a threshold of 0.00482 the sensitivity is 83.4% (83.4% of patients with the outcome in the following year have a risk greater than or equal to 0.00482) and the PPV is 1.2% (1.2% of patients with a risk greater than or equal to 0.00482 have the outcome in the following year). As the incidence of the outcome within the year is 0.741%, identifying patients with a risk greater than or equal to 0.00482 would find a subgroup of patients that have nearly double the risk of the population average risk. We can adjust the threshold using the slider to view the performance at other values.</p>
<p>To look at the overall discrimination of the model click on the Discrimination tab to view the ROC plot, precision-recall plot, and distribution plots. The line on the plots corresponds to the selected threshold point. Figure <a href="PatientLevelPrediction.html#fig:shinyPerformanceDisc">14.24</a> show the ROC and precision-recall plots. The ROC plot shows the model was able to discriminate between those who will have the outcome within the year and those who will not. However, the performance looks less impressive when we see the precision-recall plot, as the low incidence of the outcome means there is a high false positive rate.</p>
<div class="figure" style="text-align: center"><span id="fig:shinyPerformanceDisc"></span>
<img src="images/PatientLevelPrediction/shiny/shinyPerformanceDisc.png" alt="The ROC and precision-recall plots used to access the overal discrimination ability of the model." width="100%" />
<p class="caption">
Figure 14.24: The ROC and precision-recall plots used to access the overal discrimination ability of the model.
</p>
</div>
<p>Figure <a href="PatientLevelPrediction.html#fig:shinyPerformanceDist">14.25</a> shows the prediction and preference score distributions.</p>
<div class="figure" style="text-align: center"><span id="fig:shinyPerformanceDist"></span>
<img src="images/PatientLevelPrediction/shiny/shinyPerformanceDist.png" alt="The predicted risk distribtion for those with and without the outcome. The more these overlap the worse the discrimination" width="100%" />
<p class="caption">
Figure 14.25: The predicted risk distribtion for those with and without the outcome. The more these overlap the worse the discrimination
</p>
</div>
<p>Finally, we can also inspect the calibration of the model by clicking on the Calibration tab. This displays the calibration plot and the demographic calibration shown in Figure <a href="PatientLevelPrediction.html#fig:shinyPerformanceCal">14.26</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:shinyPerformanceCal"></span>
<img src="images/PatientLevelPrediction/shiny/shinyPerformanceCal.png" alt="The risk stratified calibration and demographic calibration" width="100%" />
<p class="caption">
Figure 14.26: The risk stratified calibration and demographic calibration
</p>
</div>
<p>We see that the average predicted risk appears to match the observed fraction who experienced the outcome within a year, so the model is well calibrated. Interestingly, the demographic calibration shows that the blue line is higher than the red line for young patients, so we are predicting a higher risk for young age groups. Conversely, for the patients above 80 the model is predicting a lower risk than the observed risk. This may prompt us to develop separate models for the younger or older patients.</p>
</div>
<div id="viewing-the-model" class="section level3">
<h3><span class="header-section-number">14.9.3</span> Viewing the model</h3>
<p>To inspect the final model, select the <img src="images/PatientLevelPrediction/modelButton.png" /> option from the left hand menu. This will open a view containing plots for each variable in the model, shown in Figure <a href="PatientLevelPrediction.html#fig:shinyModelPlots">14.27</a>, and a table summarizing all the candidate covariates, shown in Figure <a href="PatientLevelPrediction.html#fig:shinyModelTable">14.28</a>. The variable plots are separated into binary variables and continuous variables. The x-axis is the prevalence/mean in patients without the outcome and the y-axis is the prevalence/mean in patients with the outcome. Therefore, any variables dot falling above the diagonal is more common in patients with the outcome and any variables dot falling below the diagonal is less common in patients with the outcome.</p>
<div class="figure" style="text-align: center"><span id="fig:shinyModelPlots"></span>
<img src="images/PatientLevelPrediction/shiny/shinyModelPlots.png" alt="Model summary plots. Each dot corresponds to a variable included in the model." width="100%" />
<p class="caption">
Figure 14.27: Model summary plots. Each dot corresponds to a variable included in the model.
</p>
</div>
<p>The table in Figure <a href="PatientLevelPrediction.html#fig:shinyModelTable">14.28</a> displays the name, value (coefficient if using a general linear model, or variable importance otherwise) for all the candidate covariates, outcome mean (the mean value for those who have the outcome) and non-outcome mean (the mean value for those who do not have the outcome).</p>
<div class="figure" style="text-align: center"><span id="fig:shinyModelTable"></span>
<img src="images/PatientLevelPrediction/shiny/shinyModelTable.png" alt="Model details table." width="100%" />
<p class="caption">
Figure 14.28: Model details table.
</p>
</div>

<div class="rmdimportant">
Predictive models are not causal models, and predictors should not be mistaken for causes. There is no guarantee that modifying any of the variables in Figure <a href="PatientLevelPrediction.html#fig:shinyModelTable">14.28</a> will have an effect on the risk of the outcome.
</div>

</div>
</div>
<div id="additional-patient-level-prediction-features" class="section level2">
<h2><span class="header-section-number">14.10</span> Additional Patient-level Prediction Features</h2>
<div id="journal-paper-generation" class="section level3">
<h3><span class="header-section-number">14.10.1</span> Journal paper generation</h3>
<p>We have added functionality to automatically generate a word document we can use as start of a journal paper. It contains many of the generated study details and results. If we have performed external validation these results will can be added as well. Optionally, we can add a Table 1 that contains data on many covariates for the target population. We can create the draft journal paper by running this function:</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="PatientLevelPrediction.html#cb117-1"></a> <span class="kw">createPlpJournalDocument</span>(<span class="dt">plpResult =</span> <span class="op">&lt;</span>your plp results<span class="op">&gt;</span>,</span>
<span id="cb117-2"><a href="PatientLevelPrediction.html#cb117-2"></a>             <span class="dt">plpValidation =</span> <span class="op">&lt;</span>your validation results<span class="op">&gt;</span>,</span>
<span id="cb117-3"><a href="PatientLevelPrediction.html#cb117-3"></a>             <span class="dt">plpData =</span> <span class="op">&lt;</span>your plp data<span class="op">&gt;</span>,</span>
<span id="cb117-4"><a href="PatientLevelPrediction.html#cb117-4"></a>             <span class="dt">targetName =</span> <span class="st">&quot;&lt;target population&gt;&quot;</span>,</span>
<span id="cb117-5"><a href="PatientLevelPrediction.html#cb117-5"></a>             <span class="dt">outcomeName =</span> <span class="st">&quot;&lt;outcome&gt;&quot;</span>,</span>
<span id="cb117-6"><a href="PatientLevelPrediction.html#cb117-6"></a>             <span class="dt">table1 =</span> F,</span>
<span id="cb117-7"><a href="PatientLevelPrediction.html#cb117-7"></a>             <span class="dt">connectionDetails =</span> <span class="ot">NULL</span>,</span>
<span id="cb117-8"><a href="PatientLevelPrediction.html#cb117-8"></a>             <span class="dt">includeTrain =</span> <span class="ot">FALSE</span>,</span>
<span id="cb117-9"><a href="PatientLevelPrediction.html#cb117-9"></a>             <span class="dt">includeTest =</span> <span class="ot">TRUE</span>,</span>
<span id="cb117-10"><a href="PatientLevelPrediction.html#cb117-10"></a>             <span class="dt">includePredictionPicture =</span> <span class="ot">TRUE</span>,</span>
<span id="cb117-11"><a href="PatientLevelPrediction.html#cb117-11"></a>             <span class="dt">includeAttritionPlot =</span> <span class="ot">TRUE</span>,</span>
<span id="cb117-12"><a href="PatientLevelPrediction.html#cb117-12"></a>             <span class="dt">outputLocation =</span> <span class="st">&quot;&lt;your location&gt;&quot;</span>)</span></code></pre></div>
<p>For more details see the help page of the function.</p>
</div>
</div>
<div id="summary-9" class="section level2">
<h2><span class="header-section-number">14.11</span> Summary</h2>

<div class="rmdsummary">
<ul>
<li>ToDo</li>
</ul>
</div>

</div>
<div id="excercises-1" class="section level2">
<h2><span class="header-section-number">14.12</span> Excercises</h2>
<p>ToDo</p>

</div>
</div>



<h3>References</h3>
<div id="refs" class="references">
<div id="ref-byrd_2006">
<p>Byrd, J. B., A. Adam, and N. J. Brown. 2006. Angiotensin-converting enzyme inhibitor-associated angioedema. <em>Immunol Allergy Clin North Am</em> 26 (4): 72537.</p>
</div>
<div id="ref-circardi_2004">
<p>Cicardi, M., L. C. Zingale, L. Bergamaschini, and A. Agostoni. 2004. Angioedema associated with angiotensin-converting enzyme inhibitor use: outcome after switching to a different treatment. <em>Arch. Intern. Med.</em> 164 (8): 91013.</p>
</div>
<div id="ref-norman_2013">
<p>Norman, J. L., W. L. Holmes, W. A. Bell, and S. W. Finks. 2013. Life-threatening ACE inhibitor-induced angioedema after eleven years on lisinopril. <em>J Pharm Pract</em> 26 (4): 38288.</p>
</div>
<div id="ref-mara_1996">
<p>OMara, N. B., and E. M. OMara. 1996. Delayed onset of angioedema with angiotensin-converting enzyme inhibitors: case report and review of the literature. <em>Pharmacotherapy</em> 16 (4): 67579.</p>
</div>
<div id="ref-reps2018">
<p>Reps, J. M., M. J. Schuemie, M. A. Suchard, P. B. Ryan, and P. R. Rijnbeek. 2018. Design and implementation of a standardized framework to generate and evaluate patient-level prediction models using observational healthcare data. <em>Journal of the American Medical Informatics Association</em> 25 (8): 96975. <a href="https://doi.org/10.1093/jamia/ocy032">https://doi.org/10.1093/jamia/ocy032</a>.</p>
</div>
<div id="ref-thompson_1993">
<p>Thompson, T., and M. A. Frable. 1993. Drug-induced, life-threatening angioedema revisited. <em>Laryngoscope</em> 103 (1 Pt 1): 1012.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="PopulationLevelEstimation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="EvidenceQuality.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/OHDSI/TheBookOfOhdsi/edit/master/PatientLevelPrediction.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["TheBookOfOhdsi.pdf", "TheBookOfOhdsi.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
